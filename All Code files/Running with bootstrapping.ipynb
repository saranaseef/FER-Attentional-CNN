{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd3d9a73",
   "metadata": {
    "id": "bd3d9a73"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02242576",
   "metadata": {
    "id": "02242576"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43dd9797",
   "metadata": {
    "id": "43dd9797"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import numpy  as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f8c828b",
   "metadata": {
    "id": "1f8c828b"
   },
   "outputs": [],
   "source": [
    "import data_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89e8ba04",
   "metadata": {
    "id": "89e8ba04"
   },
   "outputs": [],
   "source": [
    "from data_loaders import Plain_Dataset, eval_data_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb5819be",
   "metadata": {
    "id": "bb5819be"
   },
   "outputs": [],
   "source": [
    "from deep_emotion import Deep_Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bc644f4",
   "metadata": {
    "id": "2bc644f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11070). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de3ccf0e",
   "metadata": {
    "id": "de3ccf0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(\"cuda:0\") if torch.cuda.is_available() else print(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cNo8zgeVtl-p",
   "metadata": {
    "id": "cNo8zgeVtl-p"
   },
   "outputs": [],
   "source": [
    "def calculate_uncertainty(logits):\n",
    "    probabilities = F.softmax(logits, dim=1)\n",
    "    uncertainty = -torch.sum(probabilities * torch.log(probabilities), dim=1)\n",
    "    return uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "569d52e7",
   "metadata": {
    "id": "569d52e7"
   },
   "outputs": [],
   "source": [
    "def Train(epochs, train_loader, val_loader, criterion, optimizer, device):\n",
    "    print(\"===================================Start Training===================================\")\n",
    "    for e in range(epochs):\n",
    "        train_loss = 0\n",
    "        validation_loss = 0\n",
    "        train_correct = 0\n",
    "        val_correct = 0\n",
    "\n",
    "        # Train the model  #\n",
    "        net.train()\n",
    "        for data, labels in train_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(data)\n",
    "\n",
    "            uncertainty = calculate_uncertainty(outputs)\n",
    "\n",
    "            weights = 1.0 / (1.0 + uncertainty)\n",
    "\n",
    "            weights = len(labels) * weights / weights.sum()\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            weighted_loss = (loss * weights).mean()\n",
    "\n",
    "            weighted_loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += weighted_loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        #validate the model#\n",
    "        net.eval()\n",
    "        for data, labels in val_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            val_outputs = net(data)\n",
    "\n",
    "            val_uncertainty = calculate_uncertainty(val_outputs)\n",
    "            val_weights = 1.0 / (1.0 + val_uncertainty)\n",
    "            val_weights = len(labels) * val_weights / val_weights.sum()\n",
    "\n",
    "            val_loss = criterion(val_outputs, labels)\n",
    "            val_weighted_loss = (val_loss * val_weights).mean()\n",
    "\n",
    "            validation_loss += val_weighted_loss.item()\n",
    "            _, val_preds = torch.max(val_outputs, 1)\n",
    "            val_correct += torch.sum(val_preds == labels.data)\n",
    "\n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        train_acc = train_correct.double() / len(train_loader.dataset)\n",
    "        validation_loss = validation_loss / len(val_loader.dataset)\n",
    "        val_acc = val_correct.double() / len(val_loader.dataset)\n",
    "\n",
    "        print('Epoch: {} \\tTraining Loss: {:.8f} \\tValidation Loss {:.8f} \\tTraining Accuracy {:.3f}% \\tValidation Accuracy {:.3f}%'\n",
    "              .format(e + 1, train_loss, validation_loss, train_acc * 100, val_acc * 100))\n",
    "\n",
    "    torch.save(net.state_dict(), 'deep_emotion-{}-{}-{}.pt'.format(epochs, batchsize, lr))\n",
    "    print(\"===================================Training Finished===================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d2eb0c2",
   "metadata": {
    "id": "9d2eb0c2"
   },
   "outputs": [],
   "source": [
    "epochs = 2500\n",
    "lr = 0.001\n",
    "batchsize = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c158709",
   "metadata": {
    "id": "5c158709"
   },
   "outputs": [],
   "source": [
    "net = Deep_Emotion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d971543d",
   "metadata": {
    "id": "d971543d",
    "outputId": "b5dbfa36-8633-4868-b738-927604d8737b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Deep_Emotion(\n",
       "  (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (dropout1): Dropout(p=0.25, inplace=False)\n",
       "  (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (dropout2): Dropout(p=0.25, inplace=False)\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (dropout3): Dropout(p=0.25, inplace=False)\n",
       "  (conv4): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (dropout4): Dropout(p=0.25, inplace=False)\n",
       "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (norm): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=810, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=8, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       "  (localization): Sequential(\n",
       "    (0): Conv2d(3, 15, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(15, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (fc_loc): Sequential(\n",
       "    (0): Linear(in_features=640, out_features=32, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=32, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "850faf9a",
   "metadata": {
    "id": "850faf9a"
   },
   "outputs": [],
   "source": [
    "transformation= transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "241dc650",
   "metadata": {
    "id": "241dc650"
   },
   "outputs": [],
   "source": [
    "traincsv_file = \"data2\" + \"/\"+\"train.csv\"\n",
    "validationcsv_file = \"data2\" + \"/\"+\"val.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5d7e3fa",
   "metadata": {
    "id": "a5d7e3fa"
   },
   "outputs": [],
   "source": [
    "train_img_dir = \"data2\"+\"/\"+\"train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae1f1e2c",
   "metadata": {
    "id": "ae1f1e2c"
   },
   "outputs": [],
   "source": [
    "validation_img_dir = \"data2\"+\"/\"+\"val/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5c7d2ce",
   "metadata": {
    "id": "d5c7d2ce"
   },
   "outputs": [],
   "source": [
    "train_dataset= Plain_Dataset(csv_file=traincsv_file, img_dir = train_img_dir, datatype = 'train', transform = transformation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "420e6896",
   "metadata": {
    "id": "420e6896"
   },
   "outputs": [],
   "source": [
    "validation_dataset= Plain_Dataset(csv_file=validationcsv_file, img_dir = validation_img_dir, datatype = 'val', transform = transformation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f858271e",
   "metadata": {
    "id": "f858271e"
   },
   "outputs": [],
   "source": [
    "train_loader= DataLoader(train_dataset,batch_size=batchsize,shuffle = True,num_workers=0)\n",
    "val_loader=   DataLoader(validation_dataset,batch_size=batchsize,shuffle = True,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c332d22f",
   "metadata": {
    "id": "c332d22f"
   },
   "outputs": [],
   "source": [
    "criterion= nn.CrossEntropyLoss()\n",
    "optmizer= optim.Adam(net.parameters(),lr= 0.00001, weight_decay = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f1c8b99",
   "metadata": {
    "id": "9f1c8b99",
    "outputId": "1c2b4bea-6f20-4bbf-cf9f-dc375d511035",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================Start Training===================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef/.local/lib/python3.8/site-packages/torch/nn/functional.py:4358: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "/home/youssef/.local/lib/python3.8/site-packages/torch/nn/functional.py:4296: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.00812111 \tValidation Loss 0.00873023 \tTraining Accuracy 14.291% \tValidation Accuracy 31.199%\n",
      "Epoch: 2 \tTraining Loss: 0.00804337 \tValidation Loss 0.00864552 \tTraining Accuracy 20.069% \tValidation Accuracy 36.335%\n",
      "Epoch: 3 \tTraining Loss: 0.00799947 \tValidation Loss 0.00860064 \tTraining Accuracy 20.261% \tValidation Accuracy 36.194%\n",
      "Epoch: 4 \tTraining Loss: 0.00798121 \tValidation Loss 0.00856548 \tTraining Accuracy 20.410% \tValidation Accuracy 35.596%\n",
      "Epoch: 5 \tTraining Loss: 0.00797219 \tValidation Loss 0.00854010 \tTraining Accuracy 20.571% \tValidation Accuracy 36.265%\n",
      "Epoch: 6 \tTraining Loss: 0.00796291 \tValidation Loss 0.00851149 \tTraining Accuracy 20.871% \tValidation Accuracy 35.420%\n",
      "Epoch: 7 \tTraining Loss: 0.00795433 \tValidation Loss 0.00850998 \tTraining Accuracy 21.198% \tValidation Accuracy 35.561%\n",
      "Epoch: 8 \tTraining Loss: 0.00794618 \tValidation Loss 0.00847139 \tTraining Accuracy 21.286% \tValidation Accuracy 35.737%\n",
      "Epoch: 9 \tTraining Loss: 0.00793682 \tValidation Loss 0.00846486 \tTraining Accuracy 22.061% \tValidation Accuracy 35.491%\n",
      "Epoch: 10 \tTraining Loss: 0.00792835 \tValidation Loss 0.00844206 \tTraining Accuracy 22.762% \tValidation Accuracy 35.772%\n",
      "Epoch: 11 \tTraining Loss: 0.00792114 \tValidation Loss 0.00843304 \tTraining Accuracy 23.136% \tValidation Accuracy 35.244%\n",
      "Epoch: 12 \tTraining Loss: 0.00791220 \tValidation Loss 0.00841141 \tTraining Accuracy 23.517% \tValidation Accuracy 36.335%\n",
      "Epoch: 13 \tTraining Loss: 0.00790511 \tValidation Loss 0.00839070 \tTraining Accuracy 23.847% \tValidation Accuracy 36.265%\n",
      "Epoch: 14 \tTraining Loss: 0.00789400 \tValidation Loss 0.00839435 \tTraining Accuracy 24.352% \tValidation Accuracy 35.913%\n",
      "Epoch: 15 \tTraining Loss: 0.00788132 \tValidation Loss 0.00835382 \tTraining Accuracy 24.844% \tValidation Accuracy 35.596%\n",
      "Epoch: 16 \tTraining Loss: 0.00787331 \tValidation Loss 0.00835591 \tTraining Accuracy 25.168% \tValidation Accuracy 36.229%\n",
      "Epoch: 17 \tTraining Loss: 0.00786359 \tValidation Loss 0.00835632 \tTraining Accuracy 25.333% \tValidation Accuracy 35.491%\n",
      "Epoch: 18 \tTraining Loss: 0.00785226 \tValidation Loss 0.00834005 \tTraining Accuracy 25.852% \tValidation Accuracy 36.229%\n",
      "Epoch: 19 \tTraining Loss: 0.00784217 \tValidation Loss 0.00833107 \tTraining Accuracy 26.253% \tValidation Accuracy 36.440%\n",
      "Epoch: 20 \tTraining Loss: 0.00783202 \tValidation Loss 0.00831374 \tTraining Accuracy 26.307% \tValidation Accuracy 36.370%\n",
      "Epoch: 21 \tTraining Loss: 0.00782760 \tValidation Loss 0.00829827 \tTraining Accuracy 26.462% \tValidation Accuracy 35.772%\n",
      "Epoch: 22 \tTraining Loss: 0.00781527 \tValidation Loss 0.00827336 \tTraining Accuracy 27.068% \tValidation Accuracy 37.425%\n",
      "Epoch: 23 \tTraining Loss: 0.00781012 \tValidation Loss 0.00825664 \tTraining Accuracy 27.075% \tValidation Accuracy 37.249%\n",
      "Epoch: 24 \tTraining Loss: 0.00780082 \tValidation Loss 0.00824705 \tTraining Accuracy 27.503% \tValidation Accuracy 38.058%\n",
      "Epoch: 25 \tTraining Loss: 0.00779356 \tValidation Loss 0.00823691 \tTraining Accuracy 27.520% \tValidation Accuracy 37.425%\n",
      "Epoch: 26 \tTraining Loss: 0.00778072 \tValidation Loss 0.00818487 \tTraining Accuracy 27.853% \tValidation Accuracy 37.425%\n",
      "Epoch: 27 \tTraining Loss: 0.00777848 \tValidation Loss 0.00819433 \tTraining Accuracy 28.049% \tValidation Accuracy 39.254%\n",
      "Epoch: 28 \tTraining Loss: 0.00777413 \tValidation Loss 0.00817380 \tTraining Accuracy 28.190% \tValidation Accuracy 39.254%\n",
      "Epoch: 29 \tTraining Loss: 0.00776511 \tValidation Loss 0.00816528 \tTraining Accuracy 28.382% \tValidation Accuracy 38.094%\n",
      "Epoch: 30 \tTraining Loss: 0.00776216 \tValidation Loss 0.00814303 \tTraining Accuracy 28.440% \tValidation Accuracy 40.767%\n",
      "Epoch: 31 \tTraining Loss: 0.00775675 \tValidation Loss 0.00813284 \tTraining Accuracy 28.675% \tValidation Accuracy 40.098%\n",
      "Epoch: 32 \tTraining Loss: 0.00775105 \tValidation Loss 0.00810516 \tTraining Accuracy 28.847% \tValidation Accuracy 40.134%\n",
      "Epoch: 33 \tTraining Loss: 0.00774580 \tValidation Loss 0.00811691 \tTraining Accuracy 28.847% \tValidation Accuracy 41.013%\n",
      "Epoch: 34 \tTraining Loss: 0.00774337 \tValidation Loss 0.00812015 \tTraining Accuracy 28.996% \tValidation Accuracy 39.676%\n",
      "Epoch: 35 \tTraining Loss: 0.00773863 \tValidation Loss 0.00811823 \tTraining Accuracy 29.002% \tValidation Accuracy 40.732%\n",
      "Epoch: 36 \tTraining Loss: 0.00773635 \tValidation Loss 0.00808360 \tTraining Accuracy 29.086% \tValidation Accuracy 41.752%\n",
      "Epoch: 37 \tTraining Loss: 0.00773031 \tValidation Loss 0.00808493 \tTraining Accuracy 29.403% \tValidation Accuracy 42.244%\n",
      "Epoch: 38 \tTraining Loss: 0.00772779 \tValidation Loss 0.00808110 \tTraining Accuracy 29.255% \tValidation Accuracy 41.576%\n",
      "Epoch: 39 \tTraining Loss: 0.00772227 \tValidation Loss 0.00803145 \tTraining Accuracy 29.400% \tValidation Accuracy 42.490%\n",
      "Epoch: 40 \tTraining Loss: 0.00771975 \tValidation Loss 0.00804592 \tTraining Accuracy 29.373% \tValidation Accuracy 43.335%\n",
      "Epoch: 41 \tTraining Loss: 0.00771960 \tValidation Loss 0.00801812 \tTraining Accuracy 29.541% \tValidation Accuracy 43.440%\n",
      "Epoch: 42 \tTraining Loss: 0.00771392 \tValidation Loss 0.00803976 \tTraining Accuracy 29.707% \tValidation Accuracy 44.179%\n",
      "Epoch: 43 \tTraining Loss: 0.00771028 \tValidation Loss 0.00803019 \tTraining Accuracy 29.771% \tValidation Accuracy 43.510%\n",
      "Epoch: 44 \tTraining Loss: 0.00770582 \tValidation Loss 0.00804249 \tTraining Accuracy 29.915% \tValidation Accuracy 44.108%\n",
      "Epoch: 45 \tTraining Loss: 0.00770089 \tValidation Loss 0.00803641 \tTraining Accuracy 30.067% \tValidation Accuracy 44.355%\n",
      "Epoch: 46 \tTraining Loss: 0.00769659 \tValidation Loss 0.00804551 \tTraining Accuracy 30.215% \tValidation Accuracy 44.355%\n",
      "Epoch: 47 \tTraining Loss: 0.00769830 \tValidation Loss 0.00805431 \tTraining Accuracy 29.929% \tValidation Accuracy 44.249%\n",
      "Epoch: 48 \tTraining Loss: 0.00768526 \tValidation Loss 0.00806048 \tTraining Accuracy 30.296% \tValidation Accuracy 45.445%\n",
      "Epoch: 49 \tTraining Loss: 0.00767822 \tValidation Loss 0.00805087 \tTraining Accuracy 30.539% \tValidation Accuracy 44.953%\n",
      "Epoch: 50 \tTraining Loss: 0.00767248 \tValidation Loss 0.00805274 \tTraining Accuracy 30.808% \tValidation Accuracy 44.671%\n",
      "Epoch: 51 \tTraining Loss: 0.00766547 \tValidation Loss 0.00805692 \tTraining Accuracy 30.960% \tValidation Accuracy 44.706%\n",
      "Epoch: 52 \tTraining Loss: 0.00765813 \tValidation Loss 0.00803165 \tTraining Accuracy 31.179% \tValidation Accuracy 45.656%\n",
      "Epoch: 53 \tTraining Loss: 0.00765610 \tValidation Loss 0.00798735 \tTraining Accuracy 31.257% \tValidation Accuracy 45.832%\n",
      "Epoch: 54 \tTraining Loss: 0.00765278 \tValidation Loss 0.00800921 \tTraining Accuracy 31.203% \tValidation Accuracy 45.973%\n",
      "Epoch: 55 \tTraining Loss: 0.00764940 \tValidation Loss 0.00800606 \tTraining Accuracy 31.385% \tValidation Accuracy 45.445%\n",
      "Epoch: 56 \tTraining Loss: 0.00765137 \tValidation Loss 0.00798223 \tTraining Accuracy 31.334% \tValidation Accuracy 46.254%\n",
      "Epoch: 57 \tTraining Loss: 0.00764238 \tValidation Loss 0.00800111 \tTraining Accuracy 31.452% \tValidation Accuracy 46.535%\n",
      "Epoch: 58 \tTraining Loss: 0.00764533 \tValidation Loss 0.00800769 \tTraining Accuracy 31.203% \tValidation Accuracy 45.973%\n",
      "Epoch: 59 \tTraining Loss: 0.00764171 \tValidation Loss 0.00801061 \tTraining Accuracy 31.314% \tValidation Accuracy 45.797%\n",
      "Epoch: 60 \tTraining Loss: 0.00763939 \tValidation Loss 0.00798174 \tTraining Accuracy 31.489% \tValidation Accuracy 46.395%\n",
      "Epoch: 61 \tTraining Loss: 0.00763153 \tValidation Loss 0.00801224 \tTraining Accuracy 31.533% \tValidation Accuracy 46.078%\n",
      "Epoch: 62 \tTraining Loss: 0.00763114 \tValidation Loss 0.00798307 \tTraining Accuracy 31.604% \tValidation Accuracy 47.098%\n",
      "Epoch: 63 \tTraining Loss: 0.00762716 \tValidation Loss 0.00797136 \tTraining Accuracy 31.732% \tValidation Accuracy 46.359%\n",
      "Epoch: 64 \tTraining Loss: 0.00762418 \tValidation Loss 0.00795123 \tTraining Accuracy 31.698% \tValidation Accuracy 47.309%\n",
      "Epoch: 65 \tTraining Loss: 0.00761904 \tValidation Loss 0.00797192 \tTraining Accuracy 32.011% \tValidation Accuracy 46.922%\n",
      "Epoch: 66 \tTraining Loss: 0.00761252 \tValidation Loss 0.00798876 \tTraining Accuracy 32.230% \tValidation Accuracy 46.500%\n",
      "Epoch: 67 \tTraining Loss: 0.00760948 \tValidation Loss 0.00799493 \tTraining Accuracy 32.392% \tValidation Accuracy 47.028%\n",
      "Epoch: 68 \tTraining Loss: 0.00761416 \tValidation Loss 0.00799928 \tTraining Accuracy 32.183% \tValidation Accuracy 46.782%\n",
      "Epoch: 69 \tTraining Loss: 0.00760666 \tValidation Loss 0.00795364 \tTraining Accuracy 32.358% \tValidation Accuracy 48.435%\n",
      "Epoch: 70 \tTraining Loss: 0.00760723 \tValidation Loss 0.00795790 \tTraining Accuracy 32.210% \tValidation Accuracy 46.887%\n",
      "Epoch: 71 \tTraining Loss: 0.00759826 \tValidation Loss 0.00792425 \tTraining Accuracy 32.614% \tValidation Accuracy 47.133%\n",
      "Epoch: 72 \tTraining Loss: 0.00759626 \tValidation Loss 0.00797358 \tTraining Accuracy 32.557% \tValidation Accuracy 47.274%\n",
      "Epoch: 73 \tTraining Loss: 0.00759835 \tValidation Loss 0.00793693 \tTraining Accuracy 32.645% \tValidation Accuracy 46.887%\n",
      "Epoch: 74 \tTraining Loss: 0.00759715 \tValidation Loss 0.00795816 \tTraining Accuracy 32.685% \tValidation Accuracy 47.626%\n",
      "Epoch: 75 \tTraining Loss: 0.00759355 \tValidation Loss 0.00796325 \tTraining Accuracy 32.497% \tValidation Accuracy 47.344%\n",
      "Epoch: 76 \tTraining Loss: 0.00758404 \tValidation Loss 0.00796204 \tTraining Accuracy 32.877% \tValidation Accuracy 47.591%\n",
      "Epoch: 77 \tTraining Loss: 0.00758002 \tValidation Loss 0.00797179 \tTraining Accuracy 33.167% \tValidation Accuracy 47.239%\n",
      "Epoch: 78 \tTraining Loss: 0.00758094 \tValidation Loss 0.00797554 \tTraining Accuracy 33.123% \tValidation Accuracy 47.520%\n",
      "Epoch: 79 \tTraining Loss: 0.00758064 \tValidation Loss 0.00794664 \tTraining Accuracy 33.117% \tValidation Accuracy 47.661%\n",
      "Epoch: 80 \tTraining Loss: 0.00756925 \tValidation Loss 0.00797135 \tTraining Accuracy 33.352% \tValidation Accuracy 47.520%\n",
      "Epoch: 81 \tTraining Loss: 0.00756936 \tValidation Loss 0.00794502 \tTraining Accuracy 33.470% \tValidation Accuracy 47.133%\n",
      "Epoch: 82 \tTraining Loss: 0.00756702 \tValidation Loss 0.00798030 \tTraining Accuracy 33.541% \tValidation Accuracy 48.400%\n",
      "Epoch: 83 \tTraining Loss: 0.00755518 \tValidation Loss 0.00799154 \tTraining Accuracy 33.760% \tValidation Accuracy 46.606%\n",
      "Epoch: 84 \tTraining Loss: 0.00754974 \tValidation Loss 0.00794856 \tTraining Accuracy 34.033% \tValidation Accuracy 47.661%\n",
      "Epoch: 85 \tTraining Loss: 0.00754926 \tValidation Loss 0.00796315 \tTraining Accuracy 34.050% \tValidation Accuracy 48.294%\n",
      "Epoch: 86 \tTraining Loss: 0.00754559 \tValidation Loss 0.00798489 \tTraining Accuracy 34.121% \tValidation Accuracy 47.802%\n",
      "Epoch: 87 \tTraining Loss: 0.00754323 \tValidation Loss 0.00797343 \tTraining Accuracy 34.252% \tValidation Accuracy 47.028%\n",
      "Epoch: 88 \tTraining Loss: 0.00753546 \tValidation Loss 0.00798663 \tTraining Accuracy 34.582% \tValidation Accuracy 46.887%\n",
      "Epoch: 89 \tTraining Loss: 0.00753673 \tValidation Loss 0.00797140 \tTraining Accuracy 34.475% \tValidation Accuracy 47.028%\n",
      "Epoch: 90 \tTraining Loss: 0.00752328 \tValidation Loss 0.00791761 \tTraining Accuracy 34.875% \tValidation Accuracy 46.782%\n",
      "Epoch: 91 \tTraining Loss: 0.00752237 \tValidation Loss 0.00797036 \tTraining Accuracy 34.943% \tValidation Accuracy 47.204%\n",
      "Epoch: 92 \tTraining Loss: 0.00751790 \tValidation Loss 0.00795786 \tTraining Accuracy 35.239% \tValidation Accuracy 46.641%\n",
      "Epoch: 93 \tTraining Loss: 0.00751025 \tValidation Loss 0.00795288 \tTraining Accuracy 35.091% \tValidation Accuracy 47.555%\n",
      "Epoch: 94 \tTraining Loss: 0.00750534 \tValidation Loss 0.00797387 \tTraining Accuracy 35.684% \tValidation Accuracy 46.711%\n",
      "Epoch: 95 \tTraining Loss: 0.00750722 \tValidation Loss 0.00795547 \tTraining Accuracy 35.212% \tValidation Accuracy 45.832%\n",
      "Epoch: 96 \tTraining Loss: 0.00749787 \tValidation Loss 0.00797654 \tTraining Accuracy 35.502% \tValidation Accuracy 45.762%\n",
      "Epoch: 97 \tTraining Loss: 0.00750088 \tValidation Loss 0.00791824 \tTraining Accuracy 35.661% \tValidation Accuracy 47.731%\n",
      "Epoch: 98 \tTraining Loss: 0.00748899 \tValidation Loss 0.00788104 \tTraining Accuracy 35.779% \tValidation Accuracy 47.837%\n",
      "Epoch: 99 \tTraining Loss: 0.00749261 \tValidation Loss 0.00787921 \tTraining Accuracy 35.704% \tValidation Accuracy 47.380%\n",
      "Epoch: 100 \tTraining Loss: 0.00747829 \tValidation Loss 0.00789496 \tTraining Accuracy 36.200% \tValidation Accuracy 46.922%\n",
      "Epoch: 101 \tTraining Loss: 0.00747992 \tValidation Loss 0.00793066 \tTraining Accuracy 35.974% \tValidation Accuracy 47.591%\n",
      "Epoch: 102 \tTraining Loss: 0.00748085 \tValidation Loss 0.00790269 \tTraining Accuracy 36.045% \tValidation Accuracy 47.485%\n",
      "Epoch: 103 \tTraining Loss: 0.00747104 \tValidation Loss 0.00790141 \tTraining Accuracy 36.314% \tValidation Accuracy 47.098%\n",
      "Epoch: 104 \tTraining Loss: 0.00747087 \tValidation Loss 0.00790518 \tTraining Accuracy 36.250% \tValidation Accuracy 47.415%\n",
      "Epoch: 105 \tTraining Loss: 0.00746136 \tValidation Loss 0.00790852 \tTraining Accuracy 36.446% \tValidation Accuracy 47.098%\n",
      "Epoch: 106 \tTraining Loss: 0.00746175 \tValidation Loss 0.00789161 \tTraining Accuracy 36.476% \tValidation Accuracy 46.254%\n",
      "Epoch: 107 \tTraining Loss: 0.00745763 \tValidation Loss 0.00784661 \tTraining Accuracy 36.769% \tValidation Accuracy 47.696%\n",
      "Epoch: 108 \tTraining Loss: 0.00745359 \tValidation Loss 0.00791050 \tTraining Accuracy 36.722% \tValidation Accuracy 46.465%\n",
      "Epoch: 109 \tTraining Loss: 0.00745287 \tValidation Loss 0.00788997 \tTraining Accuracy 36.864% \tValidation Accuracy 48.259%\n",
      "Epoch: 110 \tTraining Loss: 0.00744562 \tValidation Loss 0.00785163 \tTraining Accuracy 36.985% \tValidation Accuracy 48.083%\n",
      "Epoch: 111 \tTraining Loss: 0.00744566 \tValidation Loss 0.00787478 \tTraining Accuracy 37.022% \tValidation Accuracy 46.535%\n",
      "Epoch: 112 \tTraining Loss: 0.00745019 \tValidation Loss 0.00784466 \tTraining Accuracy 36.806% \tValidation Accuracy 48.224%\n",
      "Epoch: 113 \tTraining Loss: 0.00744114 \tValidation Loss 0.00786338 \tTraining Accuracy 37.137% \tValidation Accuracy 46.676%\n",
      "Epoch: 114 \tTraining Loss: 0.00743930 \tValidation Loss 0.00784902 \tTraining Accuracy 37.113% \tValidation Accuracy 47.415%\n",
      "Epoch: 115 \tTraining Loss: 0.00743198 \tValidation Loss 0.00783998 \tTraining Accuracy 37.386% \tValidation Accuracy 47.837%\n",
      "Epoch: 116 \tTraining Loss: 0.00743497 \tValidation Loss 0.00788730 \tTraining Accuracy 37.069% \tValidation Accuracy 46.219%\n",
      "Epoch: 117 \tTraining Loss: 0.00742993 \tValidation Loss 0.00783792 \tTraining Accuracy 37.389% \tValidation Accuracy 46.957%\n",
      "Epoch: 118 \tTraining Loss: 0.00742484 \tValidation Loss 0.00785693 \tTraining Accuracy 37.521% \tValidation Accuracy 47.837%\n",
      "Epoch: 119 \tTraining Loss: 0.00742081 \tValidation Loss 0.00786163 \tTraining Accuracy 37.625% \tValidation Accuracy 47.344%\n",
      "Epoch: 120 \tTraining Loss: 0.00741693 \tValidation Loss 0.00782379 \tTraining Accuracy 37.669% \tValidation Accuracy 46.922%\n",
      "Epoch: 121 \tTraining Loss: 0.00741146 \tValidation Loss 0.00786013 \tTraining Accuracy 37.757% \tValidation Accuracy 46.711%\n",
      "Epoch: 122 \tTraining Loss: 0.00741683 \tValidation Loss 0.00785379 \tTraining Accuracy 37.605% \tValidation Accuracy 46.993%\n",
      "Epoch: 123 \tTraining Loss: 0.00741614 \tValidation Loss 0.00782422 \tTraining Accuracy 37.713% \tValidation Accuracy 47.063%\n",
      "Epoch: 124 \tTraining Loss: 0.00741197 \tValidation Loss 0.00785565 \tTraining Accuracy 37.753% \tValidation Accuracy 46.465%\n",
      "Epoch: 125 \tTraining Loss: 0.00740897 \tValidation Loss 0.00785825 \tTraining Accuracy 37.982% \tValidation Accuracy 47.520%\n",
      "Epoch: 126 \tTraining Loss: 0.00739397 \tValidation Loss 0.00783975 \tTraining Accuracy 38.333% \tValidation Accuracy 47.626%\n",
      "Epoch: 127 \tTraining Loss: 0.00739714 \tValidation Loss 0.00781077 \tTraining Accuracy 38.265% \tValidation Accuracy 47.063%\n",
      "Epoch: 128 \tTraining Loss: 0.00739435 \tValidation Loss 0.00780791 \tTraining Accuracy 38.430% \tValidation Accuracy 47.344%\n",
      "Epoch: 129 \tTraining Loss: 0.00739540 \tValidation Loss 0.00787440 \tTraining Accuracy 38.420% \tValidation Accuracy 46.711%\n",
      "Epoch: 130 \tTraining Loss: 0.00738979 \tValidation Loss 0.00788210 \tTraining Accuracy 38.420% \tValidation Accuracy 46.289%\n",
      "Epoch: 131 \tTraining Loss: 0.00739312 \tValidation Loss 0.00785285 \tTraining Accuracy 38.397% \tValidation Accuracy 47.626%\n",
      "Epoch: 132 \tTraining Loss: 0.00738515 \tValidation Loss 0.00780817 \tTraining Accuracy 38.390% \tValidation Accuracy 45.937%\n",
      "Epoch: 133 \tTraining Loss: 0.00738477 \tValidation Loss 0.00780318 \tTraining Accuracy 38.447% \tValidation Accuracy 46.606%\n",
      "Epoch: 134 \tTraining Loss: 0.00737640 \tValidation Loss 0.00782873 \tTraining Accuracy 38.933% \tValidation Accuracy 47.626%\n",
      "Epoch: 135 \tTraining Loss: 0.00738094 \tValidation Loss 0.00782337 \tTraining Accuracy 38.552% \tValidation Accuracy 47.591%\n",
      "Epoch: 136 \tTraining Loss: 0.00738102 \tValidation Loss 0.00782005 \tTraining Accuracy 38.687% \tValidation Accuracy 48.083%\n",
      "Epoch: 137 \tTraining Loss: 0.00736832 \tValidation Loss 0.00779908 \tTraining Accuracy 38.959% \tValidation Accuracy 47.837%\n",
      "Epoch: 138 \tTraining Loss: 0.00737173 \tValidation Loss 0.00784198 \tTraining Accuracy 38.980% \tValidation Accuracy 47.344%\n",
      "Epoch: 139 \tTraining Loss: 0.00736887 \tValidation Loss 0.00780981 \tTraining Accuracy 39.040% \tValidation Accuracy 48.189%\n",
      "Epoch: 140 \tTraining Loss: 0.00736939 \tValidation Loss 0.00782661 \tTraining Accuracy 39.091% \tValidation Accuracy 47.661%\n",
      "Epoch: 141 \tTraining Loss: 0.00735743 \tValidation Loss 0.00782503 \tTraining Accuracy 39.293% \tValidation Accuracy 47.274%\n",
      "Epoch: 142 \tTraining Loss: 0.00735809 \tValidation Loss 0.00783474 \tTraining Accuracy 39.340% \tValidation Accuracy 47.731%\n",
      "Epoch: 143 \tTraining Loss: 0.00734839 \tValidation Loss 0.00780156 \tTraining Accuracy 39.667% \tValidation Accuracy 47.626%\n",
      "Epoch: 144 \tTraining Loss: 0.00735212 \tValidation Loss 0.00779769 \tTraining Accuracy 39.398% \tValidation Accuracy 47.204%\n",
      "Epoch: 145 \tTraining Loss: 0.00735544 \tValidation Loss 0.00779955 \tTraining Accuracy 39.364% \tValidation Accuracy 47.591%\n",
      "Epoch: 146 \tTraining Loss: 0.00734851 \tValidation Loss 0.00783635 \tTraining Accuracy 39.391% \tValidation Accuracy 46.993%\n",
      "Epoch: 147 \tTraining Loss: 0.00735049 \tValidation Loss 0.00785057 \tTraining Accuracy 39.485% \tValidation Accuracy 47.168%\n",
      "Epoch: 148 \tTraining Loss: 0.00734405 \tValidation Loss 0.00778258 \tTraining Accuracy 39.576% \tValidation Accuracy 47.661%\n",
      "Epoch: 149 \tTraining Loss: 0.00734953 \tValidation Loss 0.00776426 \tTraining Accuracy 39.593% \tValidation Accuracy 48.294%\n",
      "Epoch: 150 \tTraining Loss: 0.00733624 \tValidation Loss 0.00780073 \tTraining Accuracy 39.866% \tValidation Accuracy 47.837%\n",
      "Epoch: 151 \tTraining Loss: 0.00733830 \tValidation Loss 0.00776498 \tTraining Accuracy 39.677% \tValidation Accuracy 47.098%\n",
      "Epoch: 152 \tTraining Loss: 0.00732933 \tValidation Loss 0.00778412 \tTraining Accuracy 40.098% \tValidation Accuracy 47.168%\n",
      "Epoch: 153 \tTraining Loss: 0.00733362 \tValidation Loss 0.00779909 \tTraining Accuracy 39.852% \tValidation Accuracy 46.922%\n",
      "Epoch: 154 \tTraining Loss: 0.00732430 \tValidation Loss 0.00777366 \tTraining Accuracy 40.156% \tValidation Accuracy 46.957%\n",
      "Epoch: 155 \tTraining Loss: 0.00732533 \tValidation Loss 0.00775373 \tTraining Accuracy 40.264% \tValidation Accuracy 46.606%\n",
      "Epoch: 156 \tTraining Loss: 0.00732336 \tValidation Loss 0.00778138 \tTraining Accuracy 40.186% \tValidation Accuracy 47.661%\n",
      "Epoch: 157 \tTraining Loss: 0.00731893 \tValidation Loss 0.00774306 \tTraining Accuracy 40.196% \tValidation Accuracy 48.013%\n",
      "Epoch: 158 \tTraining Loss: 0.00732975 \tValidation Loss 0.00780843 \tTraining Accuracy 39.960% \tValidation Accuracy 47.133%\n",
      "Epoch: 159 \tTraining Loss: 0.00731811 \tValidation Loss 0.00778915 \tTraining Accuracy 40.162% \tValidation Accuracy 47.555%\n",
      "Epoch: 160 \tTraining Loss: 0.00731477 \tValidation Loss 0.00776879 \tTraining Accuracy 40.392% \tValidation Accuracy 48.400%\n",
      "Epoch: 161 \tTraining Loss: 0.00731114 \tValidation Loss 0.00769671 \tTraining Accuracy 40.560% \tValidation Accuracy 48.435%\n",
      "Epoch: 162 \tTraining Loss: 0.00730668 \tValidation Loss 0.00772276 \tTraining Accuracy 40.641% \tValidation Accuracy 47.872%\n",
      "Epoch: 163 \tTraining Loss: 0.00730516 \tValidation Loss 0.00775474 \tTraining Accuracy 40.691% \tValidation Accuracy 48.575%\n",
      "Epoch: 164 \tTraining Loss: 0.00730437 \tValidation Loss 0.00777494 \tTraining Accuracy 40.415% \tValidation Accuracy 47.837%\n",
      "Epoch: 165 \tTraining Loss: 0.00730351 \tValidation Loss 0.00773313 \tTraining Accuracy 40.698% \tValidation Accuracy 48.189%\n",
      "Epoch: 166 \tTraining Loss: 0.00730691 \tValidation Loss 0.00777684 \tTraining Accuracy 40.429% \tValidation Accuracy 46.957%\n",
      "Epoch: 167 \tTraining Loss: 0.00730712 \tValidation Loss 0.00775882 \tTraining Accuracy 40.540% \tValidation Accuracy 47.977%\n",
      "Epoch: 168 \tTraining Loss: 0.00729848 \tValidation Loss 0.00774165 \tTraining Accuracy 40.658% \tValidation Accuracy 48.364%\n",
      "Epoch: 169 \tTraining Loss: 0.00730080 \tValidation Loss 0.00772671 \tTraining Accuracy 40.614% \tValidation Accuracy 48.189%\n",
      "Epoch: 170 \tTraining Loss: 0.00729792 \tValidation Loss 0.00772099 \tTraining Accuracy 40.799% \tValidation Accuracy 48.364%\n",
      "Epoch: 171 \tTraining Loss: 0.00728960 \tValidation Loss 0.00774079 \tTraining Accuracy 41.076% \tValidation Accuracy 48.435%\n",
      "Epoch: 172 \tTraining Loss: 0.00729420 \tValidation Loss 0.00769881 \tTraining Accuracy 40.779% \tValidation Accuracy 48.259%\n",
      "Epoch: 173 \tTraining Loss: 0.00729361 \tValidation Loss 0.00772183 \tTraining Accuracy 40.867% \tValidation Accuracy 48.048%\n",
      "Epoch: 174 \tTraining Loss: 0.00729291 \tValidation Loss 0.00772201 \tTraining Accuracy 40.819% \tValidation Accuracy 48.435%\n",
      "Epoch: 175 \tTraining Loss: 0.00728368 \tValidation Loss 0.00773979 \tTraining Accuracy 41.170% \tValidation Accuracy 47.766%\n",
      "Epoch: 176 \tTraining Loss: 0.00728111 \tValidation Loss 0.00770128 \tTraining Accuracy 41.355% \tValidation Accuracy 48.786%\n",
      "Epoch: 177 \tTraining Loss: 0.00727891 \tValidation Loss 0.00773222 \tTraining Accuracy 41.167% \tValidation Accuracy 48.224%\n",
      "Epoch: 178 \tTraining Loss: 0.00728053 \tValidation Loss 0.00769287 \tTraining Accuracy 41.281% \tValidation Accuracy 48.892%\n",
      "Epoch: 179 \tTraining Loss: 0.00728122 \tValidation Loss 0.00770601 \tTraining Accuracy 41.231% \tValidation Accuracy 48.786%\n",
      "Epoch: 180 \tTraining Loss: 0.00727517 \tValidation Loss 0.00770784 \tTraining Accuracy 41.419% \tValidation Accuracy 48.470%\n",
      "Epoch: 181 \tTraining Loss: 0.00727511 \tValidation Loss 0.00769979 \tTraining Accuracy 41.247% \tValidation Accuracy 48.118%\n",
      "Epoch: 182 \tTraining Loss: 0.00726834 \tValidation Loss 0.00774734 \tTraining Accuracy 41.386% \tValidation Accuracy 47.942%\n",
      "Epoch: 183 \tTraining Loss: 0.00727102 \tValidation Loss 0.00774103 \tTraining Accuracy 41.251% \tValidation Accuracy 48.716%\n",
      "Epoch: 184 \tTraining Loss: 0.00726715 \tValidation Loss 0.00773342 \tTraining Accuracy 41.574% \tValidation Accuracy 48.118%\n",
      "Epoch: 185 \tTraining Loss: 0.00726415 \tValidation Loss 0.00769829 \tTraining Accuracy 41.544% \tValidation Accuracy 48.435%\n",
      "Epoch: 186 \tTraining Loss: 0.00727226 \tValidation Loss 0.00767793 \tTraining Accuracy 41.298% \tValidation Accuracy 48.998%\n",
      "Epoch: 187 \tTraining Loss: 0.00725986 \tValidation Loss 0.00769214 \tTraining Accuracy 41.894% \tValidation Accuracy 48.470%\n",
      "Epoch: 188 \tTraining Loss: 0.00726649 \tValidation Loss 0.00767536 \tTraining Accuracy 41.338% \tValidation Accuracy 49.173%\n",
      "Epoch: 189 \tTraining Loss: 0.00725383 \tValidation Loss 0.00777909 \tTraining Accuracy 41.851% \tValidation Accuracy 48.083%\n",
      "Epoch: 190 \tTraining Loss: 0.00725101 \tValidation Loss 0.00770556 \tTraining Accuracy 42.097% \tValidation Accuracy 49.103%\n",
      "Epoch: 191 \tTraining Loss: 0.00725931 \tValidation Loss 0.00768454 \tTraining Accuracy 41.827% \tValidation Accuracy 48.118%\n",
      "Epoch: 192 \tTraining Loss: 0.00725652 \tValidation Loss 0.00768712 \tTraining Accuracy 41.787% \tValidation Accuracy 48.083%\n",
      "Epoch: 193 \tTraining Loss: 0.00725081 \tValidation Loss 0.00773110 \tTraining Accuracy 41.955% \tValidation Accuracy 49.173%\n",
      "Epoch: 194 \tTraining Loss: 0.00724963 \tValidation Loss 0.00770639 \tTraining Accuracy 41.881% \tValidation Accuracy 48.083%\n",
      "Epoch: 195 \tTraining Loss: 0.00724918 \tValidation Loss 0.00769953 \tTraining Accuracy 42.066% \tValidation Accuracy 48.822%\n",
      "Epoch: 196 \tTraining Loss: 0.00725451 \tValidation Loss 0.00769349 \tTraining Accuracy 41.803% \tValidation Accuracy 48.540%\n",
      "Epoch: 197 \tTraining Loss: 0.00724822 \tValidation Loss 0.00765496 \tTraining Accuracy 41.972% \tValidation Accuracy 49.173%\n",
      "Epoch: 198 \tTraining Loss: 0.00724757 \tValidation Loss 0.00768732 \tTraining Accuracy 41.827% \tValidation Accuracy 48.400%\n",
      "Epoch: 199 \tTraining Loss: 0.00724284 \tValidation Loss 0.00767510 \tTraining Accuracy 42.093% \tValidation Accuracy 49.103%\n",
      "Epoch: 200 \tTraining Loss: 0.00724601 \tValidation Loss 0.00764416 \tTraining Accuracy 41.958% \tValidation Accuracy 49.525%\n",
      "Epoch: 201 \tTraining Loss: 0.00724051 \tValidation Loss 0.00769579 \tTraining Accuracy 42.140% \tValidation Accuracy 48.822%\n",
      "Epoch: 202 \tTraining Loss: 0.00724868 \tValidation Loss 0.00766072 \tTraining Accuracy 41.905% \tValidation Accuracy 48.153%\n",
      "Epoch: 203 \tTraining Loss: 0.00723892 \tValidation Loss 0.00766544 \tTraining Accuracy 42.235% \tValidation Accuracy 48.540%\n",
      "Epoch: 204 \tTraining Loss: 0.00723504 \tValidation Loss 0.00769928 \tTraining Accuracy 42.380% \tValidation Accuracy 49.314%\n",
      "Epoch: 205 \tTraining Loss: 0.00723530 \tValidation Loss 0.00767030 \tTraining Accuracy 42.447% \tValidation Accuracy 49.420%\n",
      "Epoch: 206 \tTraining Loss: 0.00723706 \tValidation Loss 0.00764955 \tTraining Accuracy 42.188% \tValidation Accuracy 49.138%\n",
      "Epoch: 207 \tTraining Loss: 0.00722421 \tValidation Loss 0.00768342 \tTraining Accuracy 42.612% \tValidation Accuracy 49.033%\n",
      "Epoch: 208 \tTraining Loss: 0.00722720 \tValidation Loss 0.00765010 \tTraining Accuracy 42.484% \tValidation Accuracy 48.470%\n",
      "Epoch: 209 \tTraining Loss: 0.00723829 \tValidation Loss 0.00766914 \tTraining Accuracy 42.120% \tValidation Accuracy 48.998%\n",
      "Epoch: 210 \tTraining Loss: 0.00722685 \tValidation Loss 0.00764364 \tTraining Accuracy 42.521% \tValidation Accuracy 48.505%\n",
      "Epoch: 211 \tTraining Loss: 0.00722468 \tValidation Loss 0.00768308 \tTraining Accuracy 42.619% \tValidation Accuracy 49.384%\n",
      "Epoch: 212 \tTraining Loss: 0.00722690 \tValidation Loss 0.00762219 \tTraining Accuracy 42.565% \tValidation Accuracy 49.314%\n",
      "Epoch: 213 \tTraining Loss: 0.00722328 \tValidation Loss 0.00768922 \tTraining Accuracy 42.602% \tValidation Accuracy 47.837%\n",
      "Epoch: 214 \tTraining Loss: 0.00721497 \tValidation Loss 0.00763460 \tTraining Accuracy 42.882% \tValidation Accuracy 48.751%\n",
      "Epoch: 215 \tTraining Loss: 0.00721367 \tValidation Loss 0.00763214 \tTraining Accuracy 43.097% \tValidation Accuracy 48.259%\n",
      "Epoch: 216 \tTraining Loss: 0.00722092 \tValidation Loss 0.00766982 \tTraining Accuracy 42.818% \tValidation Accuracy 49.173%\n",
      "Epoch: 217 \tTraining Loss: 0.00722014 \tValidation Loss 0.00764602 \tTraining Accuracy 42.575% \tValidation Accuracy 49.279%\n",
      "Epoch: 218 \tTraining Loss: 0.00721885 \tValidation Loss 0.00768827 \tTraining Accuracy 42.562% \tValidation Accuracy 49.455%\n",
      "Epoch: 219 \tTraining Loss: 0.00721975 \tValidation Loss 0.00761176 \tTraining Accuracy 42.770% \tValidation Accuracy 49.455%\n",
      "Epoch: 220 \tTraining Loss: 0.00720842 \tValidation Loss 0.00769122 \tTraining Accuracy 42.777% \tValidation Accuracy 49.138%\n",
      "Epoch: 221 \tTraining Loss: 0.00721124 \tValidation Loss 0.00767115 \tTraining Accuracy 42.865% \tValidation Accuracy 49.595%\n",
      "Epoch: 222 \tTraining Loss: 0.00721689 \tValidation Loss 0.00760878 \tTraining Accuracy 42.710% \tValidation Accuracy 49.807%\n",
      "Epoch: 223 \tTraining Loss: 0.00720611 \tValidation Loss 0.00765594 \tTraining Accuracy 43.064% \tValidation Accuracy 48.435%\n",
      "Epoch: 224 \tTraining Loss: 0.00720062 \tValidation Loss 0.00764426 \tTraining Accuracy 43.188% \tValidation Accuracy 48.857%\n",
      "Epoch: 225 \tTraining Loss: 0.00720746 \tValidation Loss 0.00758434 \tTraining Accuracy 42.905% \tValidation Accuracy 50.229%\n",
      "Epoch: 226 \tTraining Loss: 0.00720877 \tValidation Loss 0.00760091 \tTraining Accuracy 42.865% \tValidation Accuracy 48.892%\n",
      "Epoch: 227 \tTraining Loss: 0.00719817 \tValidation Loss 0.00763523 \tTraining Accuracy 43.111% \tValidation Accuracy 49.138%\n",
      "Epoch: 228 \tTraining Loss: 0.00720697 \tValidation Loss 0.00765902 \tTraining Accuracy 42.885% \tValidation Accuracy 48.470%\n",
      "Epoch: 229 \tTraining Loss: 0.00720034 \tValidation Loss 0.00768274 \tTraining Accuracy 43.148% \tValidation Accuracy 49.173%\n",
      "Epoch: 230 \tTraining Loss: 0.00719928 \tValidation Loss 0.00763315 \tTraining Accuracy 43.050% \tValidation Accuracy 48.189%\n",
      "Epoch: 231 \tTraining Loss: 0.00720032 \tValidation Loss 0.00761319 \tTraining Accuracy 43.192% \tValidation Accuracy 48.857%\n",
      "Epoch: 232 \tTraining Loss: 0.00720420 \tValidation Loss 0.00765356 \tTraining Accuracy 43.094% \tValidation Accuracy 49.244%\n",
      "Epoch: 233 \tTraining Loss: 0.00719143 \tValidation Loss 0.00765688 \tTraining Accuracy 43.431% \tValidation Accuracy 50.053%\n",
      "Epoch: 234 \tTraining Loss: 0.00718803 \tValidation Loss 0.00757906 \tTraining Accuracy 43.451% \tValidation Accuracy 50.405%\n",
      "Epoch: 235 \tTraining Loss: 0.00719267 \tValidation Loss 0.00765260 \tTraining Accuracy 43.293% \tValidation Accuracy 49.525%\n",
      "Epoch: 236 \tTraining Loss: 0.00719865 \tValidation Loss 0.00762660 \tTraining Accuracy 43.242% \tValidation Accuracy 49.244%\n",
      "Epoch: 237 \tTraining Loss: 0.00719037 \tValidation Loss 0.00762904 \tTraining Accuracy 43.316% \tValidation Accuracy 49.384%\n",
      "Epoch: 238 \tTraining Loss: 0.00718463 \tValidation Loss 0.00764578 \tTraining Accuracy 43.808% \tValidation Accuracy 48.927%\n",
      "Epoch: 239 \tTraining Loss: 0.00719342 \tValidation Loss 0.00758998 \tTraining Accuracy 43.195% \tValidation Accuracy 50.018%\n",
      "Epoch: 240 \tTraining Loss: 0.00719205 \tValidation Loss 0.00763078 \tTraining Accuracy 43.161% \tValidation Accuracy 49.138%\n",
      "Epoch: 241 \tTraining Loss: 0.00719064 \tValidation Loss 0.00761899 \tTraining Accuracy 43.249% \tValidation Accuracy 48.822%\n",
      "Epoch: 242 \tTraining Loss: 0.00718596 \tValidation Loss 0.00763234 \tTraining Accuracy 43.549% \tValidation Accuracy 49.244%\n",
      "Epoch: 243 \tTraining Loss: 0.00718817 \tValidation Loss 0.00763893 \tTraining Accuracy 43.262% \tValidation Accuracy 48.646%\n",
      "Epoch: 244 \tTraining Loss: 0.00718344 \tValidation Loss 0.00765516 \tTraining Accuracy 43.663% \tValidation Accuracy 48.294%\n",
      "Epoch: 245 \tTraining Loss: 0.00718233 \tValidation Loss 0.00765518 \tTraining Accuracy 43.535% \tValidation Accuracy 48.857%\n",
      "Epoch: 246 \tTraining Loss: 0.00718569 \tValidation Loss 0.00761428 \tTraining Accuracy 43.441% \tValidation Accuracy 49.560%\n",
      "Epoch: 247 \tTraining Loss: 0.00717677 \tValidation Loss 0.00764914 \tTraining Accuracy 43.825% \tValidation Accuracy 48.470%\n",
      "Epoch: 248 \tTraining Loss: 0.00718139 \tValidation Loss 0.00767277 \tTraining Accuracy 43.738% \tValidation Accuracy 48.681%\n",
      "Epoch: 249 \tTraining Loss: 0.00717638 \tValidation Loss 0.00760506 \tTraining Accuracy 43.707% \tValidation Accuracy 49.420%\n",
      "Epoch: 250 \tTraining Loss: 0.00717323 \tValidation Loss 0.00758994 \tTraining Accuracy 43.761% \tValidation Accuracy 48.857%\n",
      "Epoch: 251 \tTraining Loss: 0.00717640 \tValidation Loss 0.00761459 \tTraining Accuracy 43.748% \tValidation Accuracy 49.138%\n",
      "Epoch: 252 \tTraining Loss: 0.00717564 \tValidation Loss 0.00759553 \tTraining Accuracy 43.677% \tValidation Accuracy 50.123%\n",
      "Epoch: 253 \tTraining Loss: 0.00718317 \tValidation Loss 0.00764814 \tTraining Accuracy 43.424% \tValidation Accuracy 48.857%\n",
      "Epoch: 254 \tTraining Loss: 0.00716849 \tValidation Loss 0.00765972 \tTraining Accuracy 44.048% \tValidation Accuracy 48.822%\n",
      "Epoch: 255 \tTraining Loss: 0.00716914 \tValidation Loss 0.00762944 \tTraining Accuracy 44.004% \tValidation Accuracy 49.666%\n",
      "Epoch: 256 \tTraining Loss: 0.00718065 \tValidation Loss 0.00764728 \tTraining Accuracy 43.613% \tValidation Accuracy 49.314%\n",
      "Epoch: 257 \tTraining Loss: 0.00716953 \tValidation Loss 0.00758900 \tTraining Accuracy 43.872% \tValidation Accuracy 49.736%\n",
      "Epoch: 258 \tTraining Loss: 0.00717391 \tValidation Loss 0.00756689 \tTraining Accuracy 43.818% \tValidation Accuracy 50.158%\n",
      "Epoch: 259 \tTraining Loss: 0.00716206 \tValidation Loss 0.00766012 \tTraining Accuracy 44.243% \tValidation Accuracy 48.927%\n",
      "Epoch: 260 \tTraining Loss: 0.00717234 \tValidation Loss 0.00765443 \tTraining Accuracy 43.825% \tValidation Accuracy 49.068%\n",
      "Epoch: 261 \tTraining Loss: 0.00716882 \tValidation Loss 0.00760479 \tTraining Accuracy 43.845% \tValidation Accuracy 49.279%\n",
      "Epoch: 262 \tTraining Loss: 0.00716932 \tValidation Loss 0.00758409 \tTraining Accuracy 43.933% \tValidation Accuracy 49.912%\n",
      "Epoch: 263 \tTraining Loss: 0.00715929 \tValidation Loss 0.00757332 \tTraining Accuracy 44.152% \tValidation Accuracy 51.002%\n",
      "Epoch: 264 \tTraining Loss: 0.00715289 \tValidation Loss 0.00759617 \tTraining Accuracy 44.351% \tValidation Accuracy 50.545%\n",
      "Epoch: 265 \tTraining Loss: 0.00716355 \tValidation Loss 0.00757498 \tTraining Accuracy 44.048% \tValidation Accuracy 50.932%\n",
      "Epoch: 266 \tTraining Loss: 0.00715993 \tValidation Loss 0.00760233 \tTraining Accuracy 44.139% \tValidation Accuracy 49.771%\n",
      "Epoch: 267 \tTraining Loss: 0.00716010 \tValidation Loss 0.00764083 \tTraining Accuracy 44.125% \tValidation Accuracy 49.138%\n",
      "Epoch: 268 \tTraining Loss: 0.00715414 \tValidation Loss 0.00759108 \tTraining Accuracy 44.310% \tValidation Accuracy 49.384%\n",
      "Epoch: 269 \tTraining Loss: 0.00716020 \tValidation Loss 0.00758399 \tTraining Accuracy 44.192% \tValidation Accuracy 49.877%\n",
      "Epoch: 270 \tTraining Loss: 0.00715974 \tValidation Loss 0.00763415 \tTraining Accuracy 44.108% \tValidation Accuracy 49.455%\n",
      "Epoch: 271 \tTraining Loss: 0.00715547 \tValidation Loss 0.00764301 \tTraining Accuracy 44.472% \tValidation Accuracy 48.962%\n",
      "Epoch: 272 \tTraining Loss: 0.00716036 \tValidation Loss 0.00757540 \tTraining Accuracy 44.176% \tValidation Accuracy 49.842%\n",
      "Epoch: 273 \tTraining Loss: 0.00715491 \tValidation Loss 0.00756329 \tTraining Accuracy 44.294% \tValidation Accuracy 50.651%\n",
      "Epoch: 274 \tTraining Loss: 0.00715680 \tValidation Loss 0.00760879 \tTraining Accuracy 44.294% \tValidation Accuracy 50.580%\n",
      "Epoch: 275 \tTraining Loss: 0.00715114 \tValidation Loss 0.00760826 \tTraining Accuracy 44.347% \tValidation Accuracy 49.947%\n",
      "Epoch: 276 \tTraining Loss: 0.00715310 \tValidation Loss 0.00761895 \tTraining Accuracy 44.223% \tValidation Accuracy 49.138%\n",
      "Epoch: 277 \tTraining Loss: 0.00715057 \tValidation Loss 0.00759363 \tTraining Accuracy 44.368% \tValidation Accuracy 50.651%\n",
      "Epoch: 278 \tTraining Loss: 0.00714614 \tValidation Loss 0.00757679 \tTraining Accuracy 44.529% \tValidation Accuracy 50.545%\n",
      "Epoch: 279 \tTraining Loss: 0.00714423 \tValidation Loss 0.00757769 \tTraining Accuracy 44.684% \tValidation Accuracy 49.595%\n",
      "Epoch: 280 \tTraining Loss: 0.00715241 \tValidation Loss 0.00757246 \tTraining Accuracy 44.260% \tValidation Accuracy 49.384%\n",
      "Epoch: 281 \tTraining Loss: 0.00715176 \tValidation Loss 0.00756537 \tTraining Accuracy 44.283% \tValidation Accuracy 49.244%\n",
      "Epoch: 282 \tTraining Loss: 0.00714606 \tValidation Loss 0.00758411 \tTraining Accuracy 44.354% \tValidation Accuracy 49.173%\n",
      "Epoch: 283 \tTraining Loss: 0.00714130 \tValidation Loss 0.00757701 \tTraining Accuracy 44.607% \tValidation Accuracy 50.088%\n",
      "Epoch: 284 \tTraining Loss: 0.00714065 \tValidation Loss 0.00758394 \tTraining Accuracy 44.654% \tValidation Accuracy 49.982%\n",
      "Epoch: 285 \tTraining Loss: 0.00714256 \tValidation Loss 0.00762761 \tTraining Accuracy 44.543% \tValidation Accuracy 49.138%\n",
      "Epoch: 286 \tTraining Loss: 0.00714595 \tValidation Loss 0.00756414 \tTraining Accuracy 44.472% \tValidation Accuracy 49.842%\n",
      "Epoch: 287 \tTraining Loss: 0.00714105 \tValidation Loss 0.00764477 \tTraining Accuracy 44.664% \tValidation Accuracy 48.716%\n",
      "Epoch: 288 \tTraining Loss: 0.00714024 \tValidation Loss 0.00754422 \tTraining Accuracy 44.513% \tValidation Accuracy 50.651%\n",
      "Epoch: 289 \tTraining Loss: 0.00714000 \tValidation Loss 0.00753247 \tTraining Accuracy 44.553% \tValidation Accuracy 49.525%\n",
      "Epoch: 290 \tTraining Loss: 0.00714566 \tValidation Loss 0.00751033 \tTraining Accuracy 44.371% \tValidation Accuracy 50.440%\n",
      "Epoch: 291 \tTraining Loss: 0.00713080 \tValidation Loss 0.00757327 \tTraining Accuracy 44.947% \tValidation Accuracy 50.475%\n",
      "Epoch: 292 \tTraining Loss: 0.00713355 \tValidation Loss 0.00758268 \tTraining Accuracy 44.934% \tValidation Accuracy 49.209%\n",
      "Epoch: 293 \tTraining Loss: 0.00713329 \tValidation Loss 0.00759098 \tTraining Accuracy 44.796% \tValidation Accuracy 49.173%\n",
      "Epoch: 294 \tTraining Loss: 0.00713653 \tValidation Loss 0.00758155 \tTraining Accuracy 44.725% \tValidation Accuracy 49.420%\n",
      "Epoch: 295 \tTraining Loss: 0.00713961 \tValidation Loss 0.00764326 \tTraining Accuracy 44.523% \tValidation Accuracy 50.018%\n",
      "Epoch: 296 \tTraining Loss: 0.00712739 \tValidation Loss 0.00760012 \tTraining Accuracy 44.974% \tValidation Accuracy 50.053%\n",
      "Epoch: 297 \tTraining Loss: 0.00713369 \tValidation Loss 0.00755124 \tTraining Accuracy 44.627% \tValidation Accuracy 49.525%\n",
      "Epoch: 298 \tTraining Loss: 0.00713747 \tValidation Loss 0.00757140 \tTraining Accuracy 44.627% \tValidation Accuracy 49.947%\n",
      "Epoch: 299 \tTraining Loss: 0.00713027 \tValidation Loss 0.00757902 \tTraining Accuracy 44.971% \tValidation Accuracy 50.264%\n",
      "Epoch: 300 \tTraining Loss: 0.00712541 \tValidation Loss 0.00758230 \tTraining Accuracy 45.069% \tValidation Accuracy 49.807%\n",
      "Epoch: 301 \tTraining Loss: 0.00713874 \tValidation Loss 0.00759203 \tTraining Accuracy 44.688% \tValidation Accuracy 49.666%\n",
      "Epoch: 302 \tTraining Loss: 0.00713262 \tValidation Loss 0.00757120 \tTraining Accuracy 44.779% \tValidation Accuracy 49.103%\n",
      "Epoch: 303 \tTraining Loss: 0.00713409 \tValidation Loss 0.00752861 \tTraining Accuracy 44.691% \tValidation Accuracy 50.299%\n",
      "Epoch: 304 \tTraining Loss: 0.00712624 \tValidation Loss 0.00757497 \tTraining Accuracy 44.971% \tValidation Accuracy 49.455%\n",
      "Epoch: 305 \tTraining Loss: 0.00712701 \tValidation Loss 0.00755538 \tTraining Accuracy 44.883% \tValidation Accuracy 50.053%\n",
      "Epoch: 306 \tTraining Loss: 0.00712451 \tValidation Loss 0.00757148 \tTraining Accuracy 45.129% \tValidation Accuracy 49.877%\n",
      "Epoch: 307 \tTraining Loss: 0.00711985 \tValidation Loss 0.00756942 \tTraining Accuracy 45.058% \tValidation Accuracy 49.771%\n",
      "Epoch: 308 \tTraining Loss: 0.00712651 \tValidation Loss 0.00761329 \tTraining Accuracy 44.903% \tValidation Accuracy 49.947%\n",
      "Epoch: 309 \tTraining Loss: 0.00712011 \tValidation Loss 0.00758370 \tTraining Accuracy 45.146% \tValidation Accuracy 49.947%\n",
      "Epoch: 310 \tTraining Loss: 0.00711634 \tValidation Loss 0.00754605 \tTraining Accuracy 45.308% \tValidation Accuracy 50.791%\n",
      "Epoch: 311 \tTraining Loss: 0.00711727 \tValidation Loss 0.00758561 \tTraining Accuracy 45.230% \tValidation Accuracy 49.982%\n",
      "Epoch: 312 \tTraining Loss: 0.00711629 \tValidation Loss 0.00758751 \tTraining Accuracy 45.190% \tValidation Accuracy 49.314%\n",
      "Epoch: 313 \tTraining Loss: 0.00711504 \tValidation Loss 0.00754402 \tTraining Accuracy 45.284% \tValidation Accuracy 49.209%\n",
      "Epoch: 314 \tTraining Loss: 0.00710764 \tValidation Loss 0.00759536 \tTraining Accuracy 45.466% \tValidation Accuracy 49.384%\n",
      "Epoch: 315 \tTraining Loss: 0.00711577 \tValidation Loss 0.00757569 \tTraining Accuracy 45.197% \tValidation Accuracy 50.193%\n",
      "Epoch: 316 \tTraining Loss: 0.00712197 \tValidation Loss 0.00758384 \tTraining Accuracy 44.961% \tValidation Accuracy 50.193%\n",
      "Epoch: 317 \tTraining Loss: 0.00711764 \tValidation Loss 0.00751745 \tTraining Accuracy 45.291% \tValidation Accuracy 50.334%\n",
      "Epoch: 318 \tTraining Loss: 0.00710800 \tValidation Loss 0.00756320 \tTraining Accuracy 45.399% \tValidation Accuracy 49.877%\n",
      "Epoch: 319 \tTraining Loss: 0.00711251 \tValidation Loss 0.00755394 \tTraining Accuracy 45.486% \tValidation Accuracy 50.229%\n",
      "Epoch: 320 \tTraining Loss: 0.00711200 \tValidation Loss 0.00752603 \tTraining Accuracy 45.362% \tValidation Accuracy 50.475%\n",
      "Epoch: 321 \tTraining Loss: 0.00710873 \tValidation Loss 0.00758852 \tTraining Accuracy 45.561% \tValidation Accuracy 49.595%\n",
      "Epoch: 322 \tTraining Loss: 0.00711082 \tValidation Loss 0.00755828 \tTraining Accuracy 45.365% \tValidation Accuracy 50.440%\n",
      "Epoch: 323 \tTraining Loss: 0.00710268 \tValidation Loss 0.00757216 \tTraining Accuracy 45.598% \tValidation Accuracy 49.736%\n",
      "Epoch: 324 \tTraining Loss: 0.00711370 \tValidation Loss 0.00756571 \tTraining Accuracy 45.308% \tValidation Accuracy 48.822%\n",
      "Epoch: 325 \tTraining Loss: 0.00711105 \tValidation Loss 0.00759083 \tTraining Accuracy 45.443% \tValidation Accuracy 48.998%\n",
      "Epoch: 326 \tTraining Loss: 0.00710746 \tValidation Loss 0.00758448 \tTraining Accuracy 45.540% \tValidation Accuracy 49.560%\n",
      "Epoch: 327 \tTraining Loss: 0.00710982 \tValidation Loss 0.00759072 \tTraining Accuracy 45.483% \tValidation Accuracy 49.490%\n",
      "Epoch: 328 \tTraining Loss: 0.00710430 \tValidation Loss 0.00759120 \tTraining Accuracy 45.557% \tValidation Accuracy 49.279%\n",
      "Epoch: 329 \tTraining Loss: 0.00710617 \tValidation Loss 0.00756227 \tTraining Accuracy 45.604% \tValidation Accuracy 50.405%\n",
      "Epoch: 330 \tTraining Loss: 0.00710197 \tValidation Loss 0.00751781 \tTraining Accuracy 45.628% \tValidation Accuracy 50.897%\n",
      "Epoch: 331 \tTraining Loss: 0.00709794 \tValidation Loss 0.00757826 \tTraining Accuracy 45.652% \tValidation Accuracy 48.822%\n",
      "Epoch: 332 \tTraining Loss: 0.00709683 \tValidation Loss 0.00754590 \tTraining Accuracy 45.827% \tValidation Accuracy 49.455%\n",
      "Epoch: 333 \tTraining Loss: 0.00710519 \tValidation Loss 0.00754020 \tTraining Accuracy 45.362% \tValidation Accuracy 50.369%\n",
      "Epoch: 334 \tTraining Loss: 0.00710192 \tValidation Loss 0.00752065 \tTraining Accuracy 45.587% \tValidation Accuracy 50.193%\n",
      "Epoch: 335 \tTraining Loss: 0.00709896 \tValidation Loss 0.00749655 \tTraining Accuracy 45.625% \tValidation Accuracy 51.002%\n",
      "Epoch: 336 \tTraining Loss: 0.00709888 \tValidation Loss 0.00755729 \tTraining Accuracy 45.648% \tValidation Accuracy 51.284%\n",
      "Epoch: 337 \tTraining Loss: 0.00709803 \tValidation Loss 0.00760302 \tTraining Accuracy 45.682% \tValidation Accuracy 49.666%\n",
      "Epoch: 338 \tTraining Loss: 0.00709292 \tValidation Loss 0.00756107 \tTraining Accuracy 45.682% \tValidation Accuracy 50.053%\n",
      "Epoch: 339 \tTraining Loss: 0.00710097 \tValidation Loss 0.00756110 \tTraining Accuracy 45.584% \tValidation Accuracy 49.525%\n",
      "Epoch: 340 \tTraining Loss: 0.00710128 \tValidation Loss 0.00756382 \tTraining Accuracy 45.459% \tValidation Accuracy 49.666%\n",
      "Epoch: 341 \tTraining Loss: 0.00709848 \tValidation Loss 0.00752756 \tTraining Accuracy 45.591% \tValidation Accuracy 50.158%\n",
      "Epoch: 342 \tTraining Loss: 0.00709512 \tValidation Loss 0.00751652 \tTraining Accuracy 45.759% \tValidation Accuracy 50.193%\n",
      "Epoch: 343 \tTraining Loss: 0.00709059 \tValidation Loss 0.00754012 \tTraining Accuracy 45.847% \tValidation Accuracy 50.756%\n",
      "Epoch: 344 \tTraining Loss: 0.00709332 \tValidation Loss 0.00756543 \tTraining Accuracy 45.749% \tValidation Accuracy 49.279%\n",
      "Epoch: 345 \tTraining Loss: 0.00708890 \tValidation Loss 0.00749261 \tTraining Accuracy 45.840% \tValidation Accuracy 50.545%\n",
      "Epoch: 346 \tTraining Loss: 0.00709205 \tValidation Loss 0.00752891 \tTraining Accuracy 45.881% \tValidation Accuracy 50.053%\n",
      "Epoch: 347 \tTraining Loss: 0.00708941 \tValidation Loss 0.00753693 \tTraining Accuracy 45.874% \tValidation Accuracy 50.053%\n",
      "Epoch: 348 \tTraining Loss: 0.00708767 \tValidation Loss 0.00755214 \tTraining Accuracy 45.938% \tValidation Accuracy 50.369%\n",
      "Epoch: 349 \tTraining Loss: 0.00709590 \tValidation Loss 0.00757789 \tTraining Accuracy 45.638% \tValidation Accuracy 50.088%\n",
      "Epoch: 350 \tTraining Loss: 0.00708980 \tValidation Loss 0.00753751 \tTraining Accuracy 45.931% \tValidation Accuracy 49.560%\n",
      "Epoch: 351 \tTraining Loss: 0.00708995 \tValidation Loss 0.00757789 \tTraining Accuracy 45.786% \tValidation Accuracy 49.209%\n",
      "Epoch: 352 \tTraining Loss: 0.00709023 \tValidation Loss 0.00754868 \tTraining Accuracy 45.739% \tValidation Accuracy 50.545%\n",
      "Epoch: 353 \tTraining Loss: 0.00708488 \tValidation Loss 0.00749506 \tTraining Accuracy 45.897% \tValidation Accuracy 50.405%\n",
      "Epoch: 354 \tTraining Loss: 0.00708409 \tValidation Loss 0.00753683 \tTraining Accuracy 46.056% \tValidation Accuracy 50.475%\n",
      "Epoch: 355 \tTraining Loss: 0.00707872 \tValidation Loss 0.00748070 \tTraining Accuracy 46.228% \tValidation Accuracy 50.827%\n",
      "Epoch: 356 \tTraining Loss: 0.00708769 \tValidation Loss 0.00752159 \tTraining Accuracy 45.813% \tValidation Accuracy 50.756%\n",
      "Epoch: 357 \tTraining Loss: 0.00708535 \tValidation Loss 0.00754559 \tTraining Accuracy 46.069% \tValidation Accuracy 49.982%\n",
      "Epoch: 358 \tTraining Loss: 0.00707731 \tValidation Loss 0.00756558 \tTraining Accuracy 46.164% \tValidation Accuracy 49.771%\n",
      "Epoch: 359 \tTraining Loss: 0.00707968 \tValidation Loss 0.00752545 \tTraining Accuracy 46.147% \tValidation Accuracy 50.369%\n",
      "Epoch: 360 \tTraining Loss: 0.00708070 \tValidation Loss 0.00753926 \tTraining Accuracy 46.090% \tValidation Accuracy 50.405%\n",
      "Epoch: 361 \tTraining Loss: 0.00707914 \tValidation Loss 0.00759348 \tTraining Accuracy 46.201% \tValidation Accuracy 49.666%\n",
      "Epoch: 362 \tTraining Loss: 0.00708468 \tValidation Loss 0.00749717 \tTraining Accuracy 45.985% \tValidation Accuracy 50.440%\n",
      "Epoch: 363 \tTraining Loss: 0.00708295 \tValidation Loss 0.00754178 \tTraining Accuracy 46.086% \tValidation Accuracy 49.807%\n",
      "Epoch: 364 \tTraining Loss: 0.00707566 \tValidation Loss 0.00749722 \tTraining Accuracy 46.245% \tValidation Accuracy 50.862%\n",
      "Epoch: 365 \tTraining Loss: 0.00707642 \tValidation Loss 0.00752296 \tTraining Accuracy 46.251% \tValidation Accuracy 49.490%\n",
      "Epoch: 366 \tTraining Loss: 0.00707200 \tValidation Loss 0.00753076 \tTraining Accuracy 46.369% \tValidation Accuracy 50.405%\n",
      "Epoch: 367 \tTraining Loss: 0.00707622 \tValidation Loss 0.00757535 \tTraining Accuracy 46.295% \tValidation Accuracy 49.807%\n",
      "Epoch: 368 \tTraining Loss: 0.00707422 \tValidation Loss 0.00751750 \tTraining Accuracy 46.248% \tValidation Accuracy 49.912%\n",
      "Epoch: 369 \tTraining Loss: 0.00707055 \tValidation Loss 0.00752001 \tTraining Accuracy 46.295% \tValidation Accuracy 50.616%\n",
      "Epoch: 370 \tTraining Loss: 0.00706433 \tValidation Loss 0.00755446 \tTraining Accuracy 46.524% \tValidation Accuracy 49.525%\n",
      "Epoch: 371 \tTraining Loss: 0.00707179 \tValidation Loss 0.00750963 \tTraining Accuracy 46.356% \tValidation Accuracy 50.088%\n",
      "Epoch: 372 \tTraining Loss: 0.00707751 \tValidation Loss 0.00753646 \tTraining Accuracy 46.147% \tValidation Accuracy 49.912%\n",
      "Epoch: 373 \tTraining Loss: 0.00707118 \tValidation Loss 0.00749823 \tTraining Accuracy 46.177% \tValidation Accuracy 50.264%\n",
      "Epoch: 374 \tTraining Loss: 0.00706750 \tValidation Loss 0.00747031 \tTraining Accuracy 46.541% \tValidation Accuracy 51.776%\n",
      "Epoch: 375 \tTraining Loss: 0.00706963 \tValidation Loss 0.00758672 \tTraining Accuracy 46.416% \tValidation Accuracy 49.560%\n",
      "Epoch: 376 \tTraining Loss: 0.00707129 \tValidation Loss 0.00754713 \tTraining Accuracy 46.342% \tValidation Accuracy 48.962%\n",
      "Epoch: 377 \tTraining Loss: 0.00706239 \tValidation Loss 0.00751974 \tTraining Accuracy 46.666% \tValidation Accuracy 50.264%\n",
      "Epoch: 378 \tTraining Loss: 0.00706464 \tValidation Loss 0.00752581 \tTraining Accuracy 46.558% \tValidation Accuracy 50.334%\n",
      "Epoch: 379 \tTraining Loss: 0.00706566 \tValidation Loss 0.00751323 \tTraining Accuracy 46.453% \tValidation Accuracy 51.389%\n",
      "Epoch: 380 \tTraining Loss: 0.00706332 \tValidation Loss 0.00752408 \tTraining Accuracy 46.622% \tValidation Accuracy 50.932%\n",
      "Epoch: 381 \tTraining Loss: 0.00706780 \tValidation Loss 0.00755924 \tTraining Accuracy 46.474% \tValidation Accuracy 49.033%\n",
      "Epoch: 382 \tTraining Loss: 0.00706459 \tValidation Loss 0.00750446 \tTraining Accuracy 46.531% \tValidation Accuracy 50.334%\n",
      "Epoch: 383 \tTraining Loss: 0.00705543 \tValidation Loss 0.00749978 \tTraining Accuracy 46.821% \tValidation Accuracy 50.475%\n",
      "Epoch: 384 \tTraining Loss: 0.00706196 \tValidation Loss 0.00750765 \tTraining Accuracy 46.689% \tValidation Accuracy 49.701%\n",
      "Epoch: 385 \tTraining Loss: 0.00705562 \tValidation Loss 0.00753231 \tTraining Accuracy 46.868% \tValidation Accuracy 50.651%\n",
      "Epoch: 386 \tTraining Loss: 0.00706048 \tValidation Loss 0.00749496 \tTraining Accuracy 46.598% \tValidation Accuracy 50.932%\n",
      "Epoch: 387 \tTraining Loss: 0.00705607 \tValidation Loss 0.00754366 \tTraining Accuracy 46.780% \tValidation Accuracy 50.651%\n",
      "Epoch: 388 \tTraining Loss: 0.00705444 \tValidation Loss 0.00754954 \tTraining Accuracy 46.831% \tValidation Accuracy 50.510%\n",
      "Epoch: 389 \tTraining Loss: 0.00705601 \tValidation Loss 0.00751200 \tTraining Accuracy 46.683% \tValidation Accuracy 51.249%\n",
      "Epoch: 390 \tTraining Loss: 0.00706531 \tValidation Loss 0.00755272 \tTraining Accuracy 46.437% \tValidation Accuracy 51.178%\n",
      "Epoch: 391 \tTraining Loss: 0.00704564 \tValidation Loss 0.00744961 \tTraining Accuracy 47.090% \tValidation Accuracy 50.756%\n",
      "Epoch: 392 \tTraining Loss: 0.00706270 \tValidation Loss 0.00753478 \tTraining Accuracy 46.501% \tValidation Accuracy 50.510%\n",
      "Epoch: 393 \tTraining Loss: 0.00704826 \tValidation Loss 0.00748137 \tTraining Accuracy 46.993% \tValidation Accuracy 50.475%\n",
      "Epoch: 394 \tTraining Loss: 0.00705126 \tValidation Loss 0.00754423 \tTraining Accuracy 46.854% \tValidation Accuracy 50.299%\n",
      "Epoch: 395 \tTraining Loss: 0.00704620 \tValidation Loss 0.00752775 \tTraining Accuracy 47.016% \tValidation Accuracy 49.877%\n",
      "Epoch: 396 \tTraining Loss: 0.00705320 \tValidation Loss 0.00754080 \tTraining Accuracy 46.918% \tValidation Accuracy 50.405%\n",
      "Epoch: 397 \tTraining Loss: 0.00705350 \tValidation Loss 0.00752303 \tTraining Accuracy 46.710% \tValidation Accuracy 51.073%\n",
      "Epoch: 398 \tTraining Loss: 0.00705544 \tValidation Loss 0.00754004 \tTraining Accuracy 46.831% \tValidation Accuracy 50.545%\n",
      "Epoch: 399 \tTraining Loss: 0.00704541 \tValidation Loss 0.00750372 \tTraining Accuracy 46.972% \tValidation Accuracy 50.616%\n",
      "Epoch: 400 \tTraining Loss: 0.00704864 \tValidation Loss 0.00748236 \tTraining Accuracy 46.828% \tValidation Accuracy 50.580%\n",
      "Epoch: 401 \tTraining Loss: 0.00705291 \tValidation Loss 0.00752265 \tTraining Accuracy 46.902% \tValidation Accuracy 49.877%\n",
      "Epoch: 402 \tTraining Loss: 0.00704789 \tValidation Loss 0.00750928 \tTraining Accuracy 47.003% \tValidation Accuracy 51.178%\n",
      "Epoch: 403 \tTraining Loss: 0.00704870 \tValidation Loss 0.00749360 \tTraining Accuracy 46.922% \tValidation Accuracy 50.440%\n",
      "Epoch: 404 \tTraining Loss: 0.00704563 \tValidation Loss 0.00748484 \tTraining Accuracy 47.100% \tValidation Accuracy 50.229%\n",
      "Epoch: 405 \tTraining Loss: 0.00704749 \tValidation Loss 0.00750822 \tTraining Accuracy 47.077% \tValidation Accuracy 50.193%\n",
      "Epoch: 406 \tTraining Loss: 0.00704342 \tValidation Loss 0.00751809 \tTraining Accuracy 47.080% \tValidation Accuracy 50.510%\n",
      "Epoch: 407 \tTraining Loss: 0.00705040 \tValidation Loss 0.00748621 \tTraining Accuracy 46.865% \tValidation Accuracy 50.651%\n",
      "Epoch: 408 \tTraining Loss: 0.00704322 \tValidation Loss 0.00747434 \tTraining Accuracy 47.084% \tValidation Accuracy 50.299%\n",
      "Epoch: 409 \tTraining Loss: 0.00704338 \tValidation Loss 0.00750273 \tTraining Accuracy 47.121% \tValidation Accuracy 50.651%\n",
      "Epoch: 410 \tTraining Loss: 0.00704002 \tValidation Loss 0.00755743 \tTraining Accuracy 47.100% \tValidation Accuracy 50.405%\n",
      "Epoch: 411 \tTraining Loss: 0.00704278 \tValidation Loss 0.00751635 \tTraining Accuracy 47.094% \tValidation Accuracy 50.440%\n",
      "Epoch: 412 \tTraining Loss: 0.00704014 \tValidation Loss 0.00755033 \tTraining Accuracy 47.070% \tValidation Accuracy 50.299%\n",
      "Epoch: 413 \tTraining Loss: 0.00703499 \tValidation Loss 0.00750472 \tTraining Accuracy 47.316% \tValidation Accuracy 50.721%\n",
      "Epoch: 414 \tTraining Loss: 0.00704003 \tValidation Loss 0.00755885 \tTraining Accuracy 47.087% \tValidation Accuracy 50.756%\n",
      "Epoch: 415 \tTraining Loss: 0.00703866 \tValidation Loss 0.00751287 \tTraining Accuracy 47.326% \tValidation Accuracy 52.058%\n",
      "Epoch: 416 \tTraining Loss: 0.00703524 \tValidation Loss 0.00758406 \tTraining Accuracy 47.131% \tValidation Accuracy 49.209%\n",
      "Epoch: 417 \tTraining Loss: 0.00704738 \tValidation Loss 0.00748265 \tTraining Accuracy 46.888% \tValidation Accuracy 51.319%\n",
      "Epoch: 418 \tTraining Loss: 0.00704130 \tValidation Loss 0.00751138 \tTraining Accuracy 47.138% \tValidation Accuracy 50.616%\n",
      "Epoch: 419 \tTraining Loss: 0.00704164 \tValidation Loss 0.00748167 \tTraining Accuracy 47.111% \tValidation Accuracy 51.530%\n",
      "Epoch: 420 \tTraining Loss: 0.00703608 \tValidation Loss 0.00754482 \tTraining Accuracy 47.242% \tValidation Accuracy 50.053%\n",
      "Epoch: 421 \tTraining Loss: 0.00703569 \tValidation Loss 0.00745213 \tTraining Accuracy 47.289% \tValidation Accuracy 51.108%\n",
      "Epoch: 422 \tTraining Loss: 0.00703260 \tValidation Loss 0.00751730 \tTraining Accuracy 47.346% \tValidation Accuracy 50.651%\n",
      "Epoch: 423 \tTraining Loss: 0.00703786 \tValidation Loss 0.00752989 \tTraining Accuracy 47.161% \tValidation Accuracy 50.158%\n",
      "Epoch: 424 \tTraining Loss: 0.00703160 \tValidation Loss 0.00751253 \tTraining Accuracy 47.242% \tValidation Accuracy 50.897%\n",
      "Epoch: 425 \tTraining Loss: 0.00703666 \tValidation Loss 0.00754429 \tTraining Accuracy 47.437% \tValidation Accuracy 51.249%\n",
      "Epoch: 426 \tTraining Loss: 0.00704018 \tValidation Loss 0.00752335 \tTraining Accuracy 47.040% \tValidation Accuracy 50.510%\n",
      "Epoch: 427 \tTraining Loss: 0.00702612 \tValidation Loss 0.00745931 \tTraining Accuracy 47.670% \tValidation Accuracy 51.354%\n",
      "Epoch: 428 \tTraining Loss: 0.00702623 \tValidation Loss 0.00756664 \tTraining Accuracy 47.488% \tValidation Accuracy 49.595%\n",
      "Epoch: 429 \tTraining Loss: 0.00703680 \tValidation Loss 0.00749888 \tTraining Accuracy 47.188% \tValidation Accuracy 51.600%\n",
      "Epoch: 430 \tTraining Loss: 0.00702671 \tValidation Loss 0.00745575 \tTraining Accuracy 47.538% \tValidation Accuracy 51.249%\n",
      "Epoch: 431 \tTraining Loss: 0.00702881 \tValidation Loss 0.00745675 \tTraining Accuracy 47.373% \tValidation Accuracy 51.425%\n",
      "Epoch: 432 \tTraining Loss: 0.00703081 \tValidation Loss 0.00748560 \tTraining Accuracy 47.299% \tValidation Accuracy 50.651%\n",
      "Epoch: 433 \tTraining Loss: 0.00702902 \tValidation Loss 0.00748534 \tTraining Accuracy 47.421% \tValidation Accuracy 51.002%\n",
      "Epoch: 434 \tTraining Loss: 0.00703103 \tValidation Loss 0.00747366 \tTraining Accuracy 47.313% \tValidation Accuracy 51.178%\n",
      "Epoch: 435 \tTraining Loss: 0.00702978 \tValidation Loss 0.00751388 \tTraining Accuracy 47.404% \tValidation Accuracy 51.038%\n",
      "Epoch: 436 \tTraining Loss: 0.00702628 \tValidation Loss 0.00751830 \tTraining Accuracy 47.491% \tValidation Accuracy 50.862%\n",
      "Epoch: 437 \tTraining Loss: 0.00701759 \tValidation Loss 0.00748461 \tTraining Accuracy 47.805% \tValidation Accuracy 51.354%\n",
      "Epoch: 438 \tTraining Loss: 0.00702019 \tValidation Loss 0.00745778 \tTraining Accuracy 47.694% \tValidation Accuracy 50.932%\n",
      "Epoch: 439 \tTraining Loss: 0.00702387 \tValidation Loss 0.00747851 \tTraining Accuracy 47.596% \tValidation Accuracy 51.741%\n",
      "Epoch: 440 \tTraining Loss: 0.00702356 \tValidation Loss 0.00749630 \tTraining Accuracy 47.448% \tValidation Accuracy 50.932%\n",
      "Epoch: 441 \tTraining Loss: 0.00702032 \tValidation Loss 0.00747759 \tTraining Accuracy 47.549% \tValidation Accuracy 51.249%\n",
      "Epoch: 442 \tTraining Loss: 0.00701786 \tValidation Loss 0.00750658 \tTraining Accuracy 47.758% \tValidation Accuracy 50.475%\n",
      "Epoch: 443 \tTraining Loss: 0.00702723 \tValidation Loss 0.00750168 \tTraining Accuracy 47.444% \tValidation Accuracy 51.671%\n",
      "Epoch: 444 \tTraining Loss: 0.00702537 \tValidation Loss 0.00745390 \tTraining Accuracy 47.505% \tValidation Accuracy 51.002%\n",
      "Epoch: 445 \tTraining Loss: 0.00701479 \tValidation Loss 0.00746846 \tTraining Accuracy 47.734% \tValidation Accuracy 50.827%\n",
      "Epoch: 446 \tTraining Loss: 0.00701820 \tValidation Loss 0.00746910 \tTraining Accuracy 47.744% \tValidation Accuracy 50.440%\n",
      "Epoch: 447 \tTraining Loss: 0.00701465 \tValidation Loss 0.00748435 \tTraining Accuracy 47.832% \tValidation Accuracy 50.545%\n",
      "Epoch: 448 \tTraining Loss: 0.00701701 \tValidation Loss 0.00749072 \tTraining Accuracy 47.677% \tValidation Accuracy 51.249%\n",
      "Epoch: 449 \tTraining Loss: 0.00701296 \tValidation Loss 0.00749744 \tTraining Accuracy 47.950% \tValidation Accuracy 50.405%\n",
      "Epoch: 450 \tTraining Loss: 0.00701572 \tValidation Loss 0.00743285 \tTraining Accuracy 47.838% \tValidation Accuracy 52.234%\n",
      "Epoch: 451 \tTraining Loss: 0.00701330 \tValidation Loss 0.00749360 \tTraining Accuracy 47.845% \tValidation Accuracy 51.530%\n",
      "Epoch: 452 \tTraining Loss: 0.00701211 \tValidation Loss 0.00746364 \tTraining Accuracy 47.734% \tValidation Accuracy 51.178%\n",
      "Epoch: 453 \tTraining Loss: 0.00701363 \tValidation Loss 0.00752202 \tTraining Accuracy 47.916% \tValidation Accuracy 50.440%\n",
      "Epoch: 454 \tTraining Loss: 0.00701183 \tValidation Loss 0.00748353 \tTraining Accuracy 47.818% \tValidation Accuracy 51.249%\n",
      "Epoch: 455 \tTraining Loss: 0.00701460 \tValidation Loss 0.00745963 \tTraining Accuracy 47.842% \tValidation Accuracy 51.249%\n",
      "Epoch: 456 \tTraining Loss: 0.00700648 \tValidation Loss 0.00749571 \tTraining Accuracy 48.054% \tValidation Accuracy 51.143%\n",
      "Epoch: 457 \tTraining Loss: 0.00700641 \tValidation Loss 0.00750328 \tTraining Accuracy 48.142% \tValidation Accuracy 50.686%\n",
      "Epoch: 458 \tTraining Loss: 0.00700319 \tValidation Loss 0.00744687 \tTraining Accuracy 48.152% \tValidation Accuracy 51.389%\n",
      "Epoch: 459 \tTraining Loss: 0.00700433 \tValidation Loss 0.00749817 \tTraining Accuracy 48.064% \tValidation Accuracy 49.982%\n",
      "Epoch: 460 \tTraining Loss: 0.00701231 \tValidation Loss 0.00750689 \tTraining Accuracy 47.865% \tValidation Accuracy 50.686%\n",
      "Epoch: 461 \tTraining Loss: 0.00701495 \tValidation Loss 0.00747437 \tTraining Accuracy 47.818% \tValidation Accuracy 51.706%\n",
      "Epoch: 462 \tTraining Loss: 0.00700996 \tValidation Loss 0.00747668 \tTraining Accuracy 47.889% \tValidation Accuracy 51.178%\n",
      "Epoch: 463 \tTraining Loss: 0.00700717 \tValidation Loss 0.00748684 \tTraining Accuracy 47.892% \tValidation Accuracy 50.791%\n",
      "Epoch: 464 \tTraining Loss: 0.00701440 \tValidation Loss 0.00742805 \tTraining Accuracy 47.751% \tValidation Accuracy 51.495%\n",
      "Epoch: 465 \tTraining Loss: 0.00701200 \tValidation Loss 0.00746725 \tTraining Accuracy 47.913% \tValidation Accuracy 50.967%\n",
      "Epoch: 466 \tTraining Loss: 0.00700689 \tValidation Loss 0.00745429 \tTraining Accuracy 47.997% \tValidation Accuracy 51.214%\n",
      "Epoch: 467 \tTraining Loss: 0.00700481 \tValidation Loss 0.00750655 \tTraining Accuracy 48.165% \tValidation Accuracy 51.495%\n",
      "Epoch: 468 \tTraining Loss: 0.00700112 \tValidation Loss 0.00745181 \tTraining Accuracy 48.260% \tValidation Accuracy 51.425%\n",
      "Epoch: 469 \tTraining Loss: 0.00699839 \tValidation Loss 0.00743683 \tTraining Accuracy 48.273% \tValidation Accuracy 51.002%\n",
      "Epoch: 470 \tTraining Loss: 0.00699647 \tValidation Loss 0.00741923 \tTraining Accuracy 48.303% \tValidation Accuracy 52.304%\n",
      "Epoch: 471 \tTraining Loss: 0.00700480 \tValidation Loss 0.00744584 \tTraining Accuracy 48.000% \tValidation Accuracy 51.706%\n",
      "Epoch: 472 \tTraining Loss: 0.00700837 \tValidation Loss 0.00747158 \tTraining Accuracy 47.882% \tValidation Accuracy 52.726%\n",
      "Epoch: 473 \tTraining Loss: 0.00699544 \tValidation Loss 0.00748646 \tTraining Accuracy 48.485% \tValidation Accuracy 51.565%\n",
      "Epoch: 474 \tTraining Loss: 0.00699609 \tValidation Loss 0.00749420 \tTraining Accuracy 48.290% \tValidation Accuracy 50.827%\n",
      "Epoch: 475 \tTraining Loss: 0.00700779 \tValidation Loss 0.00745436 \tTraining Accuracy 47.990% \tValidation Accuracy 52.480%\n",
      "Epoch: 476 \tTraining Loss: 0.00699338 \tValidation Loss 0.00743594 \tTraining Accuracy 48.428% \tValidation Accuracy 51.882%\n",
      "Epoch: 477 \tTraining Loss: 0.00699646 \tValidation Loss 0.00746496 \tTraining Accuracy 48.344% \tValidation Accuracy 51.530%\n",
      "Epoch: 478 \tTraining Loss: 0.00699814 \tValidation Loss 0.00749736 \tTraining Accuracy 48.121% \tValidation Accuracy 51.108%\n",
      "Epoch: 479 \tTraining Loss: 0.00699509 \tValidation Loss 0.00747389 \tTraining Accuracy 48.233% \tValidation Accuracy 51.073%\n",
      "Epoch: 480 \tTraining Loss: 0.00699616 \tValidation Loss 0.00740783 \tTraining Accuracy 48.351% \tValidation Accuracy 52.023%\n",
      "Epoch: 481 \tTraining Loss: 0.00699044 \tValidation Loss 0.00746624 \tTraining Accuracy 48.502% \tValidation Accuracy 51.565%\n",
      "Epoch: 482 \tTraining Loss: 0.00699198 \tValidation Loss 0.00746586 \tTraining Accuracy 48.418% \tValidation Accuracy 51.108%\n",
      "Epoch: 483 \tTraining Loss: 0.00698899 \tValidation Loss 0.00745512 \tTraining Accuracy 48.388% \tValidation Accuracy 51.143%\n",
      "Epoch: 484 \tTraining Loss: 0.00699630 \tValidation Loss 0.00750097 \tTraining Accuracy 48.283% \tValidation Accuracy 50.616%\n",
      "Epoch: 485 \tTraining Loss: 0.00699589 \tValidation Loss 0.00752414 \tTraining Accuracy 48.202% \tValidation Accuracy 50.932%\n",
      "Epoch: 486 \tTraining Loss: 0.00699578 \tValidation Loss 0.00747729 \tTraining Accuracy 48.303% \tValidation Accuracy 51.952%\n",
      "Epoch: 487 \tTraining Loss: 0.00699676 \tValidation Loss 0.00745558 \tTraining Accuracy 48.283% \tValidation Accuracy 51.847%\n",
      "Epoch: 488 \tTraining Loss: 0.00699691 \tValidation Loss 0.00748408 \tTraining Accuracy 48.152% \tValidation Accuracy 51.671%\n",
      "Epoch: 489 \tTraining Loss: 0.00699725 \tValidation Loss 0.00746653 \tTraining Accuracy 48.276% \tValidation Accuracy 51.917%\n",
      "Epoch: 490 \tTraining Loss: 0.00699335 \tValidation Loss 0.00745468 \tTraining Accuracy 48.401% \tValidation Accuracy 51.847%\n",
      "Epoch: 491 \tTraining Loss: 0.00699045 \tValidation Loss 0.00743323 \tTraining Accuracy 48.364% \tValidation Accuracy 51.917%\n",
      "Epoch: 492 \tTraining Loss: 0.00699407 \tValidation Loss 0.00746325 \tTraining Accuracy 48.378% \tValidation Accuracy 51.530%\n",
      "Epoch: 493 \tTraining Loss: 0.00699430 \tValidation Loss 0.00735204 \tTraining Accuracy 48.246% \tValidation Accuracy 53.007%\n",
      "Epoch: 494 \tTraining Loss: 0.00698042 \tValidation Loss 0.00747908 \tTraining Accuracy 48.869% \tValidation Accuracy 51.354%\n",
      "Epoch: 495 \tTraining Loss: 0.00698468 \tValidation Loss 0.00744382 \tTraining Accuracy 48.600% \tValidation Accuracy 52.445%\n",
      "Epoch: 496 \tTraining Loss: 0.00698785 \tValidation Loss 0.00744461 \tTraining Accuracy 48.570% \tValidation Accuracy 51.600%\n",
      "Epoch: 497 \tTraining Loss: 0.00698955 \tValidation Loss 0.00746457 \tTraining Accuracy 48.401% \tValidation Accuracy 51.214%\n",
      "Epoch: 498 \tTraining Loss: 0.00697747 \tValidation Loss 0.00744651 \tTraining Accuracy 48.728% \tValidation Accuracy 51.811%\n",
      "Epoch: 499 \tTraining Loss: 0.00698719 \tValidation Loss 0.00744226 \tTraining Accuracy 48.448% \tValidation Accuracy 52.093%\n",
      "Epoch: 500 \tTraining Loss: 0.00698182 \tValidation Loss 0.00743997 \tTraining Accuracy 48.691% \tValidation Accuracy 51.741%\n",
      "Epoch: 501 \tTraining Loss: 0.00698289 \tValidation Loss 0.00746680 \tTraining Accuracy 48.768% \tValidation Accuracy 52.234%\n",
      "Epoch: 502 \tTraining Loss: 0.00698210 \tValidation Loss 0.00747326 \tTraining Accuracy 48.795% \tValidation Accuracy 51.636%\n",
      "Epoch: 503 \tTraining Loss: 0.00698069 \tValidation Loss 0.00741766 \tTraining Accuracy 48.745% \tValidation Accuracy 51.249%\n",
      "Epoch: 504 \tTraining Loss: 0.00697523 \tValidation Loss 0.00741410 \tTraining Accuracy 48.907% \tValidation Accuracy 52.304%\n",
      "Epoch: 505 \tTraining Loss: 0.00698263 \tValidation Loss 0.00744760 \tTraining Accuracy 48.640% \tValidation Accuracy 53.078%\n",
      "Epoch: 506 \tTraining Loss: 0.00697225 \tValidation Loss 0.00742882 \tTraining Accuracy 48.819% \tValidation Accuracy 51.530%\n",
      "Epoch: 507 \tTraining Loss: 0.00698651 \tValidation Loss 0.00747480 \tTraining Accuracy 48.404% \tValidation Accuracy 52.726%\n",
      "Epoch: 508 \tTraining Loss: 0.00697937 \tValidation Loss 0.00744729 \tTraining Accuracy 48.768% \tValidation Accuracy 51.495%\n",
      "Epoch: 509 \tTraining Loss: 0.00698055 \tValidation Loss 0.00744728 \tTraining Accuracy 48.590% \tValidation Accuracy 52.093%\n",
      "Epoch: 510 \tTraining Loss: 0.00697861 \tValidation Loss 0.00739692 \tTraining Accuracy 48.691% \tValidation Accuracy 52.691%\n",
      "Epoch: 511 \tTraining Loss: 0.00697990 \tValidation Loss 0.00740589 \tTraining Accuracy 48.677% \tValidation Accuracy 52.234%\n",
      "Epoch: 512 \tTraining Loss: 0.00698241 \tValidation Loss 0.00747716 \tTraining Accuracy 48.543% \tValidation Accuracy 51.636%\n",
      "Epoch: 513 \tTraining Loss: 0.00698046 \tValidation Loss 0.00742558 \tTraining Accuracy 48.600% \tValidation Accuracy 52.339%\n",
      "Epoch: 514 \tTraining Loss: 0.00697422 \tValidation Loss 0.00748800 \tTraining Accuracy 48.883% \tValidation Accuracy 51.354%\n",
      "Epoch: 515 \tTraining Loss: 0.00698288 \tValidation Loss 0.00741499 \tTraining Accuracy 48.469% \tValidation Accuracy 51.495%\n",
      "Epoch: 516 \tTraining Loss: 0.00697310 \tValidation Loss 0.00742992 \tTraining Accuracy 49.008% \tValidation Accuracy 52.691%\n",
      "Epoch: 517 \tTraining Loss: 0.00696885 \tValidation Loss 0.00748661 \tTraining Accuracy 49.136% \tValidation Accuracy 51.002%\n",
      "Epoch: 518 \tTraining Loss: 0.00696785 \tValidation Loss 0.00741666 \tTraining Accuracy 49.122% \tValidation Accuracy 52.480%\n",
      "Epoch: 519 \tTraining Loss: 0.00696766 \tValidation Loss 0.00751201 \tTraining Accuracy 48.954% \tValidation Accuracy 51.530%\n",
      "Epoch: 520 \tTraining Loss: 0.00698162 \tValidation Loss 0.00743308 \tTraining Accuracy 48.580% \tValidation Accuracy 51.530%\n",
      "Epoch: 521 \tTraining Loss: 0.00697825 \tValidation Loss 0.00743109 \tTraining Accuracy 48.674% \tValidation Accuracy 52.269%\n",
      "Epoch: 522 \tTraining Loss: 0.00697134 \tValidation Loss 0.00752141 \tTraining Accuracy 48.957% \tValidation Accuracy 51.917%\n",
      "Epoch: 523 \tTraining Loss: 0.00697666 \tValidation Loss 0.00745700 \tTraining Accuracy 48.768% \tValidation Accuracy 51.847%\n",
      "Epoch: 524 \tTraining Loss: 0.00697263 \tValidation Loss 0.00743685 \tTraining Accuracy 48.839% \tValidation Accuracy 52.058%\n",
      "Epoch: 525 \tTraining Loss: 0.00697256 \tValidation Loss 0.00742293 \tTraining Accuracy 48.896% \tValidation Accuracy 53.254%\n",
      "Epoch: 526 \tTraining Loss: 0.00696709 \tValidation Loss 0.00748014 \tTraining Accuracy 49.115% \tValidation Accuracy 51.811%\n",
      "Epoch: 527 \tTraining Loss: 0.00695704 \tValidation Loss 0.00748090 \tTraining Accuracy 49.156% \tValidation Accuracy 51.987%\n",
      "Epoch: 528 \tTraining Loss: 0.00697183 \tValidation Loss 0.00744723 \tTraining Accuracy 48.876% \tValidation Accuracy 52.304%\n",
      "Epoch: 529 \tTraining Loss: 0.00696741 \tValidation Loss 0.00742713 \tTraining Accuracy 49.062% \tValidation Accuracy 52.550%\n",
      "Epoch: 530 \tTraining Loss: 0.00696433 \tValidation Loss 0.00739474 \tTraining Accuracy 48.940% \tValidation Accuracy 52.269%\n",
      "Epoch: 531 \tTraining Loss: 0.00696588 \tValidation Loss 0.00744510 \tTraining Accuracy 49.156% \tValidation Accuracy 51.565%\n",
      "Epoch: 532 \tTraining Loss: 0.00696956 \tValidation Loss 0.00746885 \tTraining Accuracy 49.132% \tValidation Accuracy 52.832%\n",
      "Epoch: 533 \tTraining Loss: 0.00696718 \tValidation Loss 0.00744379 \tTraining Accuracy 48.984% \tValidation Accuracy 51.917%\n",
      "Epoch: 534 \tTraining Loss: 0.00697107 \tValidation Loss 0.00745427 \tTraining Accuracy 48.920% \tValidation Accuracy 52.445%\n",
      "Epoch: 535 \tTraining Loss: 0.00695634 \tValidation Loss 0.00745401 \tTraining Accuracy 49.422% \tValidation Accuracy 52.515%\n",
      "Epoch: 536 \tTraining Loss: 0.00695840 \tValidation Loss 0.00738515 \tTraining Accuracy 49.247% \tValidation Accuracy 52.691%\n",
      "Epoch: 537 \tTraining Loss: 0.00696689 \tValidation Loss 0.00742874 \tTraining Accuracy 49.115% \tValidation Accuracy 51.987%\n",
      "Epoch: 538 \tTraining Loss: 0.00696834 \tValidation Loss 0.00740728 \tTraining Accuracy 49.035% \tValidation Accuracy 52.550%\n",
      "Epoch: 539 \tTraining Loss: 0.00696279 \tValidation Loss 0.00744476 \tTraining Accuracy 49.082% \tValidation Accuracy 53.254%\n",
      "Epoch: 540 \tTraining Loss: 0.00696891 \tValidation Loss 0.00744459 \tTraining Accuracy 48.890% \tValidation Accuracy 52.023%\n",
      "Epoch: 541 \tTraining Loss: 0.00695916 \tValidation Loss 0.00741694 \tTraining Accuracy 49.270% \tValidation Accuracy 52.163%\n",
      "Epoch: 542 \tTraining Loss: 0.00696480 \tValidation Loss 0.00748431 \tTraining Accuracy 48.940% \tValidation Accuracy 51.917%\n",
      "Epoch: 543 \tTraining Loss: 0.00695587 \tValidation Loss 0.00742846 \tTraining Accuracy 49.395% \tValidation Accuracy 52.620%\n",
      "Epoch: 544 \tTraining Loss: 0.00694871 \tValidation Loss 0.00745802 \tTraining Accuracy 49.611% \tValidation Accuracy 51.319%\n",
      "Epoch: 545 \tTraining Loss: 0.00694973 \tValidation Loss 0.00743515 \tTraining Accuracy 49.533% \tValidation Accuracy 52.198%\n",
      "Epoch: 546 \tTraining Loss: 0.00695879 \tValidation Loss 0.00740610 \tTraining Accuracy 49.200% \tValidation Accuracy 51.882%\n",
      "Epoch: 547 \tTraining Loss: 0.00695659 \tValidation Loss 0.00744618 \tTraining Accuracy 49.294% \tValidation Accuracy 51.776%\n",
      "Epoch: 548 \tTraining Loss: 0.00696711 \tValidation Loss 0.00741199 \tTraining Accuracy 49.028% \tValidation Accuracy 53.465%\n",
      "Epoch: 549 \tTraining Loss: 0.00696124 \tValidation Loss 0.00740180 \tTraining Accuracy 49.223% \tValidation Accuracy 52.832%\n",
      "Epoch: 550 \tTraining Loss: 0.00695941 \tValidation Loss 0.00750263 \tTraining Accuracy 49.115% \tValidation Accuracy 50.545%\n",
      "Epoch: 551 \tTraining Loss: 0.00695757 \tValidation Loss 0.00744428 \tTraining Accuracy 49.284% \tValidation Accuracy 51.495%\n",
      "Epoch: 552 \tTraining Loss: 0.00695554 \tValidation Loss 0.00745440 \tTraining Accuracy 49.388% \tValidation Accuracy 52.761%\n",
      "Epoch: 553 \tTraining Loss: 0.00694468 \tValidation Loss 0.00740181 \tTraining Accuracy 49.695% \tValidation Accuracy 52.550%\n",
      "Epoch: 554 \tTraining Loss: 0.00694913 \tValidation Loss 0.00741754 \tTraining Accuracy 49.574% \tValidation Accuracy 52.445%\n",
      "Epoch: 555 \tTraining Loss: 0.00695629 \tValidation Loss 0.00737979 \tTraining Accuracy 49.281% \tValidation Accuracy 52.972%\n",
      "Epoch: 556 \tTraining Loss: 0.00695616 \tValidation Loss 0.00743807 \tTraining Accuracy 49.301% \tValidation Accuracy 51.741%\n",
      "Epoch: 557 \tTraining Loss: 0.00695660 \tValidation Loss 0.00742349 \tTraining Accuracy 49.328% \tValidation Accuracy 52.269%\n",
      "Epoch: 558 \tTraining Loss: 0.00694263 \tValidation Loss 0.00749189 \tTraining Accuracy 49.604% \tValidation Accuracy 51.706%\n",
      "Epoch: 559 \tTraining Loss: 0.00694644 \tValidation Loss 0.00740504 \tTraining Accuracy 49.611% \tValidation Accuracy 51.882%\n",
      "Epoch: 560 \tTraining Loss: 0.00694644 \tValidation Loss 0.00744139 \tTraining Accuracy 49.607% \tValidation Accuracy 51.354%\n",
      "Epoch: 561 \tTraining Loss: 0.00695565 \tValidation Loss 0.00739598 \tTraining Accuracy 49.297% \tValidation Accuracy 52.937%\n",
      "Epoch: 562 \tTraining Loss: 0.00694914 \tValidation Loss 0.00742238 \tTraining Accuracy 49.348% \tValidation Accuracy 53.113%\n",
      "Epoch: 563 \tTraining Loss: 0.00695596 \tValidation Loss 0.00745386 \tTraining Accuracy 49.328% \tValidation Accuracy 51.565%\n",
      "Epoch: 564 \tTraining Loss: 0.00695318 \tValidation Loss 0.00739421 \tTraining Accuracy 49.301% \tValidation Accuracy 52.796%\n",
      "Epoch: 565 \tTraining Loss: 0.00694334 \tValidation Loss 0.00738058 \tTraining Accuracy 49.698% \tValidation Accuracy 53.113%\n",
      "Epoch: 566 \tTraining Loss: 0.00695204 \tValidation Loss 0.00744179 \tTraining Accuracy 49.365% \tValidation Accuracy 53.148%\n",
      "Epoch: 567 \tTraining Loss: 0.00693960 \tValidation Loss 0.00744334 \tTraining Accuracy 49.813% \tValidation Accuracy 53.007%\n",
      "Epoch: 568 \tTraining Loss: 0.00694497 \tValidation Loss 0.00743022 \tTraining Accuracy 49.540% \tValidation Accuracy 53.148%\n",
      "Epoch: 569 \tTraining Loss: 0.00694497 \tValidation Loss 0.00740746 \tTraining Accuracy 49.671% \tValidation Accuracy 52.023%\n",
      "Epoch: 570 \tTraining Loss: 0.00694352 \tValidation Loss 0.00740536 \tTraining Accuracy 49.614% \tValidation Accuracy 52.585%\n",
      "Epoch: 571 \tTraining Loss: 0.00694495 \tValidation Loss 0.00742818 \tTraining Accuracy 49.591% \tValidation Accuracy 52.269%\n",
      "Epoch: 572 \tTraining Loss: 0.00694700 \tValidation Loss 0.00742575 \tTraining Accuracy 49.550% \tValidation Accuracy 51.706%\n",
      "Epoch: 573 \tTraining Loss: 0.00694186 \tValidation Loss 0.00743688 \tTraining Accuracy 49.715% \tValidation Accuracy 52.691%\n",
      "Epoch: 574 \tTraining Loss: 0.00694366 \tValidation Loss 0.00747693 \tTraining Accuracy 49.628% \tValidation Accuracy 51.952%\n",
      "Epoch: 575 \tTraining Loss: 0.00694198 \tValidation Loss 0.00742712 \tTraining Accuracy 49.719% \tValidation Accuracy 52.867%\n",
      "Epoch: 576 \tTraining Loss: 0.00693883 \tValidation Loss 0.00738809 \tTraining Accuracy 49.830% \tValidation Accuracy 51.952%\n",
      "Epoch: 577 \tTraining Loss: 0.00693916 \tValidation Loss 0.00742763 \tTraining Accuracy 49.786% \tValidation Accuracy 52.234%\n",
      "Epoch: 578 \tTraining Loss: 0.00693140 \tValidation Loss 0.00745047 \tTraining Accuracy 49.975% \tValidation Accuracy 51.847%\n",
      "Epoch: 579 \tTraining Loss: 0.00694011 \tValidation Loss 0.00744348 \tTraining Accuracy 49.645% \tValidation Accuracy 51.776%\n",
      "Epoch: 580 \tTraining Loss: 0.00694203 \tValidation Loss 0.00745323 \tTraining Accuracy 49.752% \tValidation Accuracy 51.952%\n",
      "Epoch: 581 \tTraining Loss: 0.00694313 \tValidation Loss 0.00745821 \tTraining Accuracy 49.678% \tValidation Accuracy 51.143%\n",
      "Epoch: 582 \tTraining Loss: 0.00694029 \tValidation Loss 0.00742143 \tTraining Accuracy 49.847% \tValidation Accuracy 52.656%\n",
      "Epoch: 583 \tTraining Loss: 0.00693774 \tValidation Loss 0.00746379 \tTraining Accuracy 49.729% \tValidation Accuracy 52.832%\n",
      "Epoch: 584 \tTraining Loss: 0.00693962 \tValidation Loss 0.00744757 \tTraining Accuracy 49.675% \tValidation Accuracy 52.550%\n",
      "Epoch: 585 \tTraining Loss: 0.00693311 \tValidation Loss 0.00742105 \tTraining Accuracy 49.867% \tValidation Accuracy 52.128%\n",
      "Epoch: 586 \tTraining Loss: 0.00693479 \tValidation Loss 0.00748863 \tTraining Accuracy 49.759% \tValidation Accuracy 50.967%\n",
      "Epoch: 587 \tTraining Loss: 0.00694242 \tValidation Loss 0.00743371 \tTraining Accuracy 49.769% \tValidation Accuracy 52.656%\n",
      "Epoch: 588 \tTraining Loss: 0.00693922 \tValidation Loss 0.00743137 \tTraining Accuracy 49.742% \tValidation Accuracy 52.374%\n",
      "Epoch: 589 \tTraining Loss: 0.00693962 \tValidation Loss 0.00742098 \tTraining Accuracy 49.611% \tValidation Accuracy 53.113%\n",
      "Epoch: 590 \tTraining Loss: 0.00694267 \tValidation Loss 0.00744484 \tTraining Accuracy 49.587% \tValidation Accuracy 52.269%\n",
      "Epoch: 591 \tTraining Loss: 0.00693884 \tValidation Loss 0.00743793 \tTraining Accuracy 49.793% \tValidation Accuracy 52.761%\n",
      "Epoch: 592 \tTraining Loss: 0.00693067 \tValidation Loss 0.00737850 \tTraining Accuracy 49.890% \tValidation Accuracy 52.409%\n",
      "Epoch: 593 \tTraining Loss: 0.00693993 \tValidation Loss 0.00743293 \tTraining Accuracy 49.800% \tValidation Accuracy 51.002%\n",
      "Epoch: 594 \tTraining Loss: 0.00694012 \tValidation Loss 0.00738072 \tTraining Accuracy 49.574% \tValidation Accuracy 52.656%\n",
      "Epoch: 595 \tTraining Loss: 0.00693103 \tValidation Loss 0.00741731 \tTraining Accuracy 50.103% \tValidation Accuracy 53.570%\n",
      "Epoch: 596 \tTraining Loss: 0.00693558 \tValidation Loss 0.00739264 \tTraining Accuracy 49.705% \tValidation Accuracy 52.234%\n",
      "Epoch: 597 \tTraining Loss: 0.00692194 \tValidation Loss 0.00739961 \tTraining Accuracy 50.217% \tValidation Accuracy 52.163%\n",
      "Epoch: 598 \tTraining Loss: 0.00693753 \tValidation Loss 0.00742277 \tTraining Accuracy 49.735% \tValidation Accuracy 52.691%\n",
      "Epoch: 599 \tTraining Loss: 0.00693522 \tValidation Loss 0.00741038 \tTraining Accuracy 49.739% \tValidation Accuracy 52.937%\n",
      "Epoch: 600 \tTraining Loss: 0.00693384 \tValidation Loss 0.00739405 \tTraining Accuracy 49.965% \tValidation Accuracy 52.445%\n",
      "Epoch: 601 \tTraining Loss: 0.00692871 \tValidation Loss 0.00743175 \tTraining Accuracy 49.948% \tValidation Accuracy 51.038%\n",
      "Epoch: 602 \tTraining Loss: 0.00692517 \tValidation Loss 0.00744918 \tTraining Accuracy 50.136% \tValidation Accuracy 52.409%\n",
      "Epoch: 603 \tTraining Loss: 0.00691852 \tValidation Loss 0.00745556 \tTraining Accuracy 50.308% \tValidation Accuracy 52.550%\n",
      "Epoch: 604 \tTraining Loss: 0.00692896 \tValidation Loss 0.00742636 \tTraining Accuracy 50.032% \tValidation Accuracy 52.480%\n",
      "Epoch: 605 \tTraining Loss: 0.00692163 \tValidation Loss 0.00745483 \tTraining Accuracy 50.207% \tValidation Accuracy 52.937%\n",
      "Epoch: 606 \tTraining Loss: 0.00693270 \tValidation Loss 0.00737073 \tTraining Accuracy 49.776% \tValidation Accuracy 53.429%\n",
      "Epoch: 607 \tTraining Loss: 0.00693275 \tValidation Loss 0.00742097 \tTraining Accuracy 49.796% \tValidation Accuracy 52.832%\n",
      "Epoch: 608 \tTraining Loss: 0.00692963 \tValidation Loss 0.00739764 \tTraining Accuracy 49.934% \tValidation Accuracy 53.043%\n",
      "Epoch: 609 \tTraining Loss: 0.00692768 \tValidation Loss 0.00745197 \tTraining Accuracy 50.093% \tValidation Accuracy 53.078%\n",
      "Epoch: 610 \tTraining Loss: 0.00691593 \tValidation Loss 0.00743570 \tTraining Accuracy 50.433% \tValidation Accuracy 52.023%\n",
      "Epoch: 611 \tTraining Loss: 0.00692182 \tValidation Loss 0.00743425 \tTraining Accuracy 50.221% \tValidation Accuracy 53.289%\n",
      "Epoch: 612 \tTraining Loss: 0.00692765 \tValidation Loss 0.00742106 \tTraining Accuracy 50.029% \tValidation Accuracy 53.148%\n",
      "Epoch: 613 \tTraining Loss: 0.00692106 \tValidation Loss 0.00741502 \tTraining Accuracy 50.322% \tValidation Accuracy 52.234%\n",
      "Epoch: 614 \tTraining Loss: 0.00692393 \tValidation Loss 0.00738866 \tTraining Accuracy 50.120% \tValidation Accuracy 53.852%\n",
      "Epoch: 615 \tTraining Loss: 0.00691825 \tValidation Loss 0.00741403 \tTraining Accuracy 50.342% \tValidation Accuracy 53.113%\n",
      "Epoch: 616 \tTraining Loss: 0.00691766 \tValidation Loss 0.00744608 \tTraining Accuracy 50.460% \tValidation Accuracy 51.565%\n",
      "Epoch: 617 \tTraining Loss: 0.00692407 \tValidation Loss 0.00738834 \tTraining Accuracy 50.248% \tValidation Accuracy 53.148%\n",
      "Epoch: 618 \tTraining Loss: 0.00691072 \tValidation Loss 0.00741878 \tTraining Accuracy 50.477% \tValidation Accuracy 53.183%\n",
      "Epoch: 619 \tTraining Loss: 0.00692622 \tValidation Loss 0.00739300 \tTraining Accuracy 49.992% \tValidation Accuracy 53.429%\n",
      "Epoch: 620 \tTraining Loss: 0.00692011 \tValidation Loss 0.00738182 \tTraining Accuracy 50.382% \tValidation Accuracy 53.043%\n",
      "Epoch: 621 \tTraining Loss: 0.00691872 \tValidation Loss 0.00737857 \tTraining Accuracy 50.339% \tValidation Accuracy 52.761%\n",
      "Epoch: 622 \tTraining Loss: 0.00691362 \tValidation Loss 0.00743860 \tTraining Accuracy 50.490% \tValidation Accuracy 52.339%\n",
      "Epoch: 623 \tTraining Loss: 0.00691289 \tValidation Loss 0.00746398 \tTraining Accuracy 50.504% \tValidation Accuracy 52.163%\n",
      "Epoch: 624 \tTraining Loss: 0.00691198 \tValidation Loss 0.00738442 \tTraining Accuracy 50.362% \tValidation Accuracy 52.128%\n",
      "Epoch: 625 \tTraining Loss: 0.00692254 \tValidation Loss 0.00737985 \tTraining Accuracy 50.062% \tValidation Accuracy 51.882%\n",
      "Epoch: 626 \tTraining Loss: 0.00691981 \tValidation Loss 0.00743629 \tTraining Accuracy 50.221% \tValidation Accuracy 52.304%\n",
      "Epoch: 627 \tTraining Loss: 0.00692162 \tValidation Loss 0.00737747 \tTraining Accuracy 50.167% \tValidation Accuracy 53.429%\n",
      "Epoch: 628 \tTraining Loss: 0.00690475 \tValidation Loss 0.00741008 \tTraining Accuracy 50.625% \tValidation Accuracy 52.550%\n",
      "Epoch: 629 \tTraining Loss: 0.00691158 \tValidation Loss 0.00739775 \tTraining Accuracy 50.453% \tValidation Accuracy 53.289%\n",
      "Epoch: 630 \tTraining Loss: 0.00691838 \tValidation Loss 0.00742123 \tTraining Accuracy 50.329% \tValidation Accuracy 53.043%\n",
      "Epoch: 631 \tTraining Loss: 0.00691839 \tValidation Loss 0.00742923 \tTraining Accuracy 50.224% \tValidation Accuracy 52.128%\n",
      "Epoch: 632 \tTraining Loss: 0.00691404 \tValidation Loss 0.00744283 \tTraining Accuracy 50.261% \tValidation Accuracy 52.691%\n",
      "Epoch: 633 \tTraining Loss: 0.00690943 \tValidation Loss 0.00741488 \tTraining Accuracy 50.537% \tValidation Accuracy 52.761%\n",
      "Epoch: 634 \tTraining Loss: 0.00690932 \tValidation Loss 0.00740971 \tTraining Accuracy 50.517% \tValidation Accuracy 50.897%\n",
      "Epoch: 635 \tTraining Loss: 0.00691161 \tValidation Loss 0.00744995 \tTraining Accuracy 50.521% \tValidation Accuracy 51.917%\n",
      "Epoch: 636 \tTraining Loss: 0.00690589 \tValidation Loss 0.00742786 \tTraining Accuracy 50.642% \tValidation Accuracy 52.093%\n",
      "Epoch: 637 \tTraining Loss: 0.00690583 \tValidation Loss 0.00740412 \tTraining Accuracy 50.777% \tValidation Accuracy 51.811%\n",
      "Epoch: 638 \tTraining Loss: 0.00690622 \tValidation Loss 0.00743310 \tTraining Accuracy 50.571% \tValidation Accuracy 52.902%\n",
      "Epoch: 639 \tTraining Loss: 0.00690190 \tValidation Loss 0.00743728 \tTraining Accuracy 50.659% \tValidation Accuracy 52.269%\n",
      "Epoch: 640 \tTraining Loss: 0.00690646 \tValidation Loss 0.00740814 \tTraining Accuracy 50.716% \tValidation Accuracy 52.796%\n",
      "Epoch: 641 \tTraining Loss: 0.00691341 \tValidation Loss 0.00740395 \tTraining Accuracy 50.453% \tValidation Accuracy 52.234%\n",
      "Epoch: 642 \tTraining Loss: 0.00690583 \tValidation Loss 0.00739608 \tTraining Accuracy 50.662% \tValidation Accuracy 52.128%\n",
      "Epoch: 643 \tTraining Loss: 0.00690930 \tValidation Loss 0.00738973 \tTraining Accuracy 50.463% \tValidation Accuracy 52.691%\n",
      "Epoch: 644 \tTraining Loss: 0.00690134 \tValidation Loss 0.00745101 \tTraining Accuracy 50.723% \tValidation Accuracy 52.620%\n",
      "Epoch: 645 \tTraining Loss: 0.00690680 \tValidation Loss 0.00743514 \tTraining Accuracy 50.554% \tValidation Accuracy 52.269%\n",
      "Epoch: 646 \tTraining Loss: 0.00690620 \tValidation Loss 0.00740208 \tTraining Accuracy 50.460% \tValidation Accuracy 52.409%\n",
      "Epoch: 647 \tTraining Loss: 0.00690866 \tValidation Loss 0.00744999 \tTraining Accuracy 50.514% \tValidation Accuracy 52.585%\n",
      "Epoch: 648 \tTraining Loss: 0.00690111 \tValidation Loss 0.00740852 \tTraining Accuracy 50.723% \tValidation Accuracy 53.007%\n",
      "Epoch: 649 \tTraining Loss: 0.00689195 \tValidation Loss 0.00740171 \tTraining Accuracy 50.959% \tValidation Accuracy 53.043%\n",
      "Epoch: 650 \tTraining Loss: 0.00689950 \tValidation Loss 0.00741125 \tTraining Accuracy 50.676% \tValidation Accuracy 52.304%\n",
      "Epoch: 651 \tTraining Loss: 0.00690480 \tValidation Loss 0.00740966 \tTraining Accuracy 50.655% \tValidation Accuracy 53.007%\n",
      "Epoch: 652 \tTraining Loss: 0.00690253 \tValidation Loss 0.00740314 \tTraining Accuracy 50.868% \tValidation Accuracy 52.867%\n",
      "Epoch: 653 \tTraining Loss: 0.00689330 \tValidation Loss 0.00740873 \tTraining Accuracy 50.888% \tValidation Accuracy 51.671%\n",
      "Epoch: 654 \tTraining Loss: 0.00690340 \tValidation Loss 0.00737539 \tTraining Accuracy 50.679% \tValidation Accuracy 52.445%\n",
      "Epoch: 655 \tTraining Loss: 0.00690315 \tValidation Loss 0.00742920 \tTraining Accuracy 50.659% \tValidation Accuracy 52.620%\n",
      "Epoch: 656 \tTraining Loss: 0.00690018 \tValidation Loss 0.00745188 \tTraining Accuracy 50.736% \tValidation Accuracy 51.319%\n",
      "Epoch: 657 \tTraining Loss: 0.00689693 \tValidation Loss 0.00746320 \tTraining Accuracy 50.814% \tValidation Accuracy 50.580%\n",
      "Epoch: 658 \tTraining Loss: 0.00689874 \tValidation Loss 0.00738828 \tTraining Accuracy 50.783% \tValidation Accuracy 52.902%\n",
      "Epoch: 659 \tTraining Loss: 0.00690202 \tValidation Loss 0.00737138 \tTraining Accuracy 50.615% \tValidation Accuracy 53.429%\n",
      "Epoch: 660 \tTraining Loss: 0.00690293 \tValidation Loss 0.00742076 \tTraining Accuracy 50.588% \tValidation Accuracy 52.409%\n",
      "Epoch: 661 \tTraining Loss: 0.00690872 \tValidation Loss 0.00737891 \tTraining Accuracy 50.436% \tValidation Accuracy 53.535%\n",
      "Epoch: 662 \tTraining Loss: 0.00689455 \tValidation Loss 0.00737992 \tTraining Accuracy 50.831% \tValidation Accuracy 53.183%\n",
      "Epoch: 663 \tTraining Loss: 0.00690491 \tValidation Loss 0.00741073 \tTraining Accuracy 50.598% \tValidation Accuracy 52.374%\n",
      "Epoch: 664 \tTraining Loss: 0.00688804 \tValidation Loss 0.00735702 \tTraining Accuracy 51.040% \tValidation Accuracy 52.269%\n",
      "Epoch: 665 \tTraining Loss: 0.00689296 \tValidation Loss 0.00739542 \tTraining Accuracy 50.888% \tValidation Accuracy 52.023%\n",
      "Epoch: 666 \tTraining Loss: 0.00690273 \tValidation Loss 0.00741095 \tTraining Accuracy 50.756% \tValidation Accuracy 53.394%\n",
      "Epoch: 667 \tTraining Loss: 0.00688989 \tValidation Loss 0.00740885 \tTraining Accuracy 51.019% \tValidation Accuracy 52.726%\n",
      "Epoch: 668 \tTraining Loss: 0.00690166 \tValidation Loss 0.00742670 \tTraining Accuracy 50.871% \tValidation Accuracy 53.113%\n",
      "Epoch: 669 \tTraining Loss: 0.00690417 \tValidation Loss 0.00737604 \tTraining Accuracy 50.595% \tValidation Accuracy 53.394%\n",
      "Epoch: 670 \tTraining Loss: 0.00688656 \tValidation Loss 0.00734993 \tTraining Accuracy 51.191% \tValidation Accuracy 53.113%\n",
      "Epoch: 671 \tTraining Loss: 0.00688616 \tValidation Loss 0.00740988 \tTraining Accuracy 51.093% \tValidation Accuracy 52.691%\n",
      "Epoch: 672 \tTraining Loss: 0.00689336 \tValidation Loss 0.00742888 \tTraining Accuracy 51.023% \tValidation Accuracy 52.550%\n",
      "Epoch: 673 \tTraining Loss: 0.00689530 \tValidation Loss 0.00743536 \tTraining Accuracy 50.976% \tValidation Accuracy 52.550%\n",
      "Epoch: 674 \tTraining Loss: 0.00689314 \tValidation Loss 0.00736812 \tTraining Accuracy 50.885% \tValidation Accuracy 53.254%\n",
      "Epoch: 675 \tTraining Loss: 0.00688606 \tValidation Loss 0.00740403 \tTraining Accuracy 51.238% \tValidation Accuracy 52.128%\n",
      "Epoch: 676 \tTraining Loss: 0.00688764 \tValidation Loss 0.00742064 \tTraining Accuracy 50.955% \tValidation Accuracy 52.093%\n",
      "Epoch: 677 \tTraining Loss: 0.00689893 \tValidation Loss 0.00733720 \tTraining Accuracy 50.827% \tValidation Accuracy 52.832%\n",
      "Epoch: 678 \tTraining Loss: 0.00689286 \tValidation Loss 0.00738132 \tTraining Accuracy 50.871% \tValidation Accuracy 53.429%\n",
      "Epoch: 679 \tTraining Loss: 0.00688989 \tValidation Loss 0.00742150 \tTraining Accuracy 50.922% \tValidation Accuracy 51.214%\n",
      "Epoch: 680 \tTraining Loss: 0.00688605 \tValidation Loss 0.00738983 \tTraining Accuracy 51.242% \tValidation Accuracy 52.726%\n",
      "Epoch: 681 \tTraining Loss: 0.00688218 \tValidation Loss 0.00743406 \tTraining Accuracy 51.306% \tValidation Accuracy 51.249%\n",
      "Epoch: 682 \tTraining Loss: 0.00688436 \tValidation Loss 0.00737901 \tTraining Accuracy 51.269% \tValidation Accuracy 52.374%\n",
      "Epoch: 683 \tTraining Loss: 0.00689670 \tValidation Loss 0.00739160 \tTraining Accuracy 50.858% \tValidation Accuracy 52.902%\n",
      "Epoch: 684 \tTraining Loss: 0.00688763 \tValidation Loss 0.00736939 \tTraining Accuracy 51.043% \tValidation Accuracy 53.043%\n",
      "Epoch: 685 \tTraining Loss: 0.00689063 \tValidation Loss 0.00740949 \tTraining Accuracy 51.029% \tValidation Accuracy 52.234%\n",
      "Epoch: 686 \tTraining Loss: 0.00689318 \tValidation Loss 0.00741631 \tTraining Accuracy 50.885% \tValidation Accuracy 52.093%\n",
      "Epoch: 687 \tTraining Loss: 0.00688144 \tValidation Loss 0.00738898 \tTraining Accuracy 51.265% \tValidation Accuracy 53.289%\n",
      "Epoch: 688 \tTraining Loss: 0.00688726 \tValidation Loss 0.00740035 \tTraining Accuracy 51.097% \tValidation Accuracy 53.007%\n",
      "Epoch: 689 \tTraining Loss: 0.00687888 \tValidation Loss 0.00737748 \tTraining Accuracy 51.242% \tValidation Accuracy 52.972%\n",
      "Epoch: 690 \tTraining Loss: 0.00688593 \tValidation Loss 0.00742298 \tTraining Accuracy 51.053% \tValidation Accuracy 53.183%\n",
      "Epoch: 691 \tTraining Loss: 0.00688500 \tValidation Loss 0.00737137 \tTraining Accuracy 51.023% \tValidation Accuracy 52.656%\n",
      "Epoch: 692 \tTraining Loss: 0.00688017 \tValidation Loss 0.00739988 \tTraining Accuracy 51.248% \tValidation Accuracy 52.339%\n",
      "Epoch: 693 \tTraining Loss: 0.00688495 \tValidation Loss 0.00741832 \tTraining Accuracy 51.036% \tValidation Accuracy 52.902%\n",
      "Epoch: 694 \tTraining Loss: 0.00688830 \tValidation Loss 0.00738589 \tTraining Accuracy 51.023% \tValidation Accuracy 52.867%\n",
      "Epoch: 695 \tTraining Loss: 0.00688477 \tValidation Loss 0.00736807 \tTraining Accuracy 51.056% \tValidation Accuracy 53.043%\n",
      "Epoch: 696 \tTraining Loss: 0.00687549 \tValidation Loss 0.00740394 \tTraining Accuracy 51.336% \tValidation Accuracy 53.394%\n",
      "Epoch: 697 \tTraining Loss: 0.00687913 \tValidation Loss 0.00740057 \tTraining Accuracy 51.225% \tValidation Accuracy 52.269%\n",
      "Epoch: 698 \tTraining Loss: 0.00688525 \tValidation Loss 0.00736100 \tTraining Accuracy 51.077% \tValidation Accuracy 52.585%\n",
      "Epoch: 699 \tTraining Loss: 0.00687368 \tValidation Loss 0.00742603 \tTraining Accuracy 51.474% \tValidation Accuracy 52.163%\n",
      "Epoch: 700 \tTraining Loss: 0.00689007 \tValidation Loss 0.00737050 \tTraining Accuracy 51.006% \tValidation Accuracy 53.359%\n",
      "Epoch: 701 \tTraining Loss: 0.00687200 \tValidation Loss 0.00736483 \tTraining Accuracy 51.596% \tValidation Accuracy 52.937%\n",
      "Epoch: 702 \tTraining Loss: 0.00687745 \tValidation Loss 0.00737307 \tTraining Accuracy 51.518% \tValidation Accuracy 53.148%\n",
      "Epoch: 703 \tTraining Loss: 0.00687286 \tValidation Loss 0.00733967 \tTraining Accuracy 51.481% \tValidation Accuracy 53.429%\n",
      "Epoch: 704 \tTraining Loss: 0.00687246 \tValidation Loss 0.00736217 \tTraining Accuracy 51.596% \tValidation Accuracy 53.218%\n",
      "Epoch: 705 \tTraining Loss: 0.00687467 \tValidation Loss 0.00739189 \tTraining Accuracy 51.531% \tValidation Accuracy 54.309%\n",
      "Epoch: 706 \tTraining Loss: 0.00687784 \tValidation Loss 0.00740676 \tTraining Accuracy 51.441% \tValidation Accuracy 52.937%\n",
      "Epoch: 707 \tTraining Loss: 0.00687284 \tValidation Loss 0.00736922 \tTraining Accuracy 51.531% \tValidation Accuracy 53.007%\n",
      "Epoch: 708 \tTraining Loss: 0.00687484 \tValidation Loss 0.00744165 \tTraining Accuracy 51.447% \tValidation Accuracy 52.726%\n",
      "Epoch: 709 \tTraining Loss: 0.00688160 \tValidation Loss 0.00737543 \tTraining Accuracy 51.171% \tValidation Accuracy 54.696%\n",
      "Epoch: 710 \tTraining Loss: 0.00687230 \tValidation Loss 0.00743099 \tTraining Accuracy 51.376% \tValidation Accuracy 52.023%\n",
      "Epoch: 711 \tTraining Loss: 0.00687638 \tValidation Loss 0.00735668 \tTraining Accuracy 51.205% \tValidation Accuracy 52.937%\n",
      "Epoch: 712 \tTraining Loss: 0.00688097 \tValidation Loss 0.00736127 \tTraining Accuracy 51.100% \tValidation Accuracy 53.359%\n",
      "Epoch: 713 \tTraining Loss: 0.00686991 \tValidation Loss 0.00734005 \tTraining Accuracy 51.633% \tValidation Accuracy 54.133%\n",
      "Epoch: 714 \tTraining Loss: 0.00686434 \tValidation Loss 0.00739542 \tTraining Accuracy 51.535% \tValidation Accuracy 53.183%\n",
      "Epoch: 715 \tTraining Loss: 0.00686819 \tValidation Loss 0.00744719 \tTraining Accuracy 51.511% \tValidation Accuracy 52.691%\n",
      "Epoch: 716 \tTraining Loss: 0.00687344 \tValidation Loss 0.00736310 \tTraining Accuracy 51.424% \tValidation Accuracy 52.796%\n",
      "Epoch: 717 \tTraining Loss: 0.00686206 \tValidation Loss 0.00743107 \tTraining Accuracy 51.804% \tValidation Accuracy 52.234%\n",
      "Epoch: 718 \tTraining Loss: 0.00686418 \tValidation Loss 0.00736104 \tTraining Accuracy 51.781% \tValidation Accuracy 53.641%\n",
      "Epoch: 719 \tTraining Loss: 0.00687816 \tValidation Loss 0.00742238 \tTraining Accuracy 51.370% \tValidation Accuracy 51.952%\n",
      "Epoch: 720 \tTraining Loss: 0.00686894 \tValidation Loss 0.00737163 \tTraining Accuracy 51.629% \tValidation Accuracy 53.043%\n",
      "Epoch: 721 \tTraining Loss: 0.00686544 \tValidation Loss 0.00736892 \tTraining Accuracy 51.680% \tValidation Accuracy 53.148%\n",
      "Epoch: 722 \tTraining Loss: 0.00686244 \tValidation Loss 0.00735618 \tTraining Accuracy 51.798% \tValidation Accuracy 53.746%\n",
      "Epoch: 723 \tTraining Loss: 0.00685680 \tValidation Loss 0.00738065 \tTraining Accuracy 51.909% \tValidation Accuracy 53.992%\n",
      "Epoch: 724 \tTraining Loss: 0.00687282 \tValidation Loss 0.00739245 \tTraining Accuracy 51.444% \tValidation Accuracy 53.429%\n",
      "Epoch: 725 \tTraining Loss: 0.00686228 \tValidation Loss 0.00734468 \tTraining Accuracy 51.747% \tValidation Accuracy 53.535%\n",
      "Epoch: 726 \tTraining Loss: 0.00686387 \tValidation Loss 0.00735604 \tTraining Accuracy 51.724% \tValidation Accuracy 54.801%\n",
      "Epoch: 727 \tTraining Loss: 0.00686192 \tValidation Loss 0.00733537 \tTraining Accuracy 51.875% \tValidation Accuracy 54.203%\n",
      "Epoch: 728 \tTraining Loss: 0.00686813 \tValidation Loss 0.00732436 \tTraining Accuracy 51.558% \tValidation Accuracy 53.570%\n",
      "Epoch: 729 \tTraining Loss: 0.00686107 \tValidation Loss 0.00741185 \tTraining Accuracy 51.821% \tValidation Accuracy 53.359%\n",
      "Epoch: 730 \tTraining Loss: 0.00684975 \tValidation Loss 0.00737021 \tTraining Accuracy 52.047% \tValidation Accuracy 52.374%\n",
      "Epoch: 731 \tTraining Loss: 0.00687105 \tValidation Loss 0.00741248 \tTraining Accuracy 51.521% \tValidation Accuracy 52.585%\n",
      "Epoch: 732 \tTraining Loss: 0.00686371 \tValidation Loss 0.00734683 \tTraining Accuracy 51.740% \tValidation Accuracy 52.620%\n",
      "Epoch: 733 \tTraining Loss: 0.00686987 \tValidation Loss 0.00741018 \tTraining Accuracy 51.569% \tValidation Accuracy 53.254%\n",
      "Epoch: 734 \tTraining Loss: 0.00685565 \tValidation Loss 0.00733839 \tTraining Accuracy 51.902% \tValidation Accuracy 53.746%\n",
      "Epoch: 735 \tTraining Loss: 0.00686014 \tValidation Loss 0.00736735 \tTraining Accuracy 51.841% \tValidation Accuracy 52.269%\n",
      "Epoch: 736 \tTraining Loss: 0.00686153 \tValidation Loss 0.00735647 \tTraining Accuracy 51.747% \tValidation Accuracy 53.535%\n",
      "Epoch: 737 \tTraining Loss: 0.00685571 \tValidation Loss 0.00741364 \tTraining Accuracy 51.953% \tValidation Accuracy 52.409%\n",
      "Epoch: 738 \tTraining Loss: 0.00686628 \tValidation Loss 0.00737844 \tTraining Accuracy 51.478% \tValidation Accuracy 53.465%\n",
      "Epoch: 739 \tTraining Loss: 0.00685411 \tValidation Loss 0.00737099 \tTraining Accuracy 51.963% \tValidation Accuracy 53.570%\n",
      "Epoch: 740 \tTraining Loss: 0.00686350 \tValidation Loss 0.00739760 \tTraining Accuracy 51.575% \tValidation Accuracy 52.867%\n",
      "Epoch: 741 \tTraining Loss: 0.00685917 \tValidation Loss 0.00738185 \tTraining Accuracy 52.003% \tValidation Accuracy 52.726%\n",
      "Epoch: 742 \tTraining Loss: 0.00686902 \tValidation Loss 0.00733315 \tTraining Accuracy 51.562% \tValidation Accuracy 54.696%\n",
      "Epoch: 743 \tTraining Loss: 0.00686621 \tValidation Loss 0.00739977 \tTraining Accuracy 51.626% \tValidation Accuracy 53.711%\n",
      "Epoch: 744 \tTraining Loss: 0.00685576 \tValidation Loss 0.00734322 \tTraining Accuracy 51.993% \tValidation Accuracy 54.555%\n",
      "Epoch: 745 \tTraining Loss: 0.00685540 \tValidation Loss 0.00732651 \tTraining Accuracy 52.118% \tValidation Accuracy 53.148%\n",
      "Epoch: 746 \tTraining Loss: 0.00685390 \tValidation Loss 0.00731048 \tTraining Accuracy 51.996% \tValidation Accuracy 54.238%\n",
      "Epoch: 747 \tTraining Loss: 0.00686404 \tValidation Loss 0.00735231 \tTraining Accuracy 51.703% \tValidation Accuracy 54.766%\n",
      "Epoch: 748 \tTraining Loss: 0.00686459 \tValidation Loss 0.00735082 \tTraining Accuracy 51.649% \tValidation Accuracy 53.429%\n",
      "Epoch: 749 \tTraining Loss: 0.00685919 \tValidation Loss 0.00738194 \tTraining Accuracy 51.747% \tValidation Accuracy 53.043%\n",
      "Epoch: 750 \tTraining Loss: 0.00685977 \tValidation Loss 0.00739874 \tTraining Accuracy 51.767% \tValidation Accuracy 52.409%\n",
      "Epoch: 751 \tTraining Loss: 0.00684891 \tValidation Loss 0.00735097 \tTraining Accuracy 52.121% \tValidation Accuracy 53.254%\n",
      "Epoch: 752 \tTraining Loss: 0.00684765 \tValidation Loss 0.00733719 \tTraining Accuracy 52.114% \tValidation Accuracy 53.183%\n",
      "Epoch: 753 \tTraining Loss: 0.00685247 \tValidation Loss 0.00738084 \tTraining Accuracy 51.996% \tValidation Accuracy 52.620%\n",
      "Epoch: 754 \tTraining Loss: 0.00684508 \tValidation Loss 0.00740522 \tTraining Accuracy 52.195% \tValidation Accuracy 52.761%\n",
      "Epoch: 755 \tTraining Loss: 0.00685255 \tValidation Loss 0.00736083 \tTraining Accuracy 52.030% \tValidation Accuracy 53.324%\n",
      "Epoch: 756 \tTraining Loss: 0.00685685 \tValidation Loss 0.00735255 \tTraining Accuracy 51.872% \tValidation Accuracy 53.289%\n",
      "Epoch: 757 \tTraining Loss: 0.00685124 \tValidation Loss 0.00738684 \tTraining Accuracy 51.963% \tValidation Accuracy 53.394%\n",
      "Epoch: 758 \tTraining Loss: 0.00685209 \tValidation Loss 0.00743519 \tTraining Accuracy 51.939% \tValidation Accuracy 52.832%\n",
      "Epoch: 759 \tTraining Loss: 0.00684764 \tValidation Loss 0.00737616 \tTraining Accuracy 52.286% \tValidation Accuracy 52.374%\n",
      "Epoch: 760 \tTraining Loss: 0.00685581 \tValidation Loss 0.00734757 \tTraining Accuracy 51.821% \tValidation Accuracy 53.605%\n",
      "Epoch: 761 \tTraining Loss: 0.00685224 \tValidation Loss 0.00740707 \tTraining Accuracy 51.993% \tValidation Accuracy 53.746%\n",
      "Epoch: 762 \tTraining Loss: 0.00684964 \tValidation Loss 0.00734705 \tTraining Accuracy 52.034% \tValidation Accuracy 54.520%\n",
      "Epoch: 763 \tTraining Loss: 0.00684563 \tValidation Loss 0.00742734 \tTraining Accuracy 52.219% \tValidation Accuracy 53.007%\n",
      "Epoch: 764 \tTraining Loss: 0.00684874 \tValidation Loss 0.00740443 \tTraining Accuracy 52.054% \tValidation Accuracy 53.007%\n",
      "Epoch: 765 \tTraining Loss: 0.00684231 \tValidation Loss 0.00734308 \tTraining Accuracy 52.317% \tValidation Accuracy 53.746%\n",
      "Epoch: 766 \tTraining Loss: 0.00684948 \tValidation Loss 0.00738213 \tTraining Accuracy 52.145% \tValidation Accuracy 52.937%\n",
      "Epoch: 767 \tTraining Loss: 0.00684985 \tValidation Loss 0.00736554 \tTraining Accuracy 52.054% \tValidation Accuracy 53.183%\n",
      "Epoch: 768 \tTraining Loss: 0.00683977 \tValidation Loss 0.00736131 \tTraining Accuracy 52.438% \tValidation Accuracy 53.605%\n",
      "Epoch: 769 \tTraining Loss: 0.00684528 \tValidation Loss 0.00733489 \tTraining Accuracy 52.162% \tValidation Accuracy 54.027%\n",
      "Epoch: 770 \tTraining Loss: 0.00685172 \tValidation Loss 0.00736145 \tTraining Accuracy 52.020% \tValidation Accuracy 53.324%\n",
      "Epoch: 771 \tTraining Loss: 0.00684969 \tValidation Loss 0.00737152 \tTraining Accuracy 52.034% \tValidation Accuracy 52.515%\n",
      "Epoch: 772 \tTraining Loss: 0.00685105 \tValidation Loss 0.00739750 \tTraining Accuracy 52.044% \tValidation Accuracy 51.741%\n",
      "Epoch: 773 \tTraining Loss: 0.00684713 \tValidation Loss 0.00740049 \tTraining Accuracy 52.138% \tValidation Accuracy 52.198%\n",
      "Epoch: 774 \tTraining Loss: 0.00684350 \tValidation Loss 0.00733365 \tTraining Accuracy 52.135% \tValidation Accuracy 54.238%\n",
      "Epoch: 775 \tTraining Loss: 0.00684845 \tValidation Loss 0.00741082 \tTraining Accuracy 52.074% \tValidation Accuracy 53.113%\n",
      "Epoch: 776 \tTraining Loss: 0.00684850 \tValidation Loss 0.00735069 \tTraining Accuracy 51.929% \tValidation Accuracy 53.007%\n",
      "Epoch: 777 \tTraining Loss: 0.00684187 \tValidation Loss 0.00744409 \tTraining Accuracy 52.273% \tValidation Accuracy 52.093%\n",
      "Epoch: 778 \tTraining Loss: 0.00684419 \tValidation Loss 0.00740183 \tTraining Accuracy 52.236% \tValidation Accuracy 52.515%\n",
      "Epoch: 779 \tTraining Loss: 0.00684687 \tValidation Loss 0.00736838 \tTraining Accuracy 52.135% \tValidation Accuracy 53.148%\n",
      "Epoch: 780 \tTraining Loss: 0.00683254 \tValidation Loss 0.00736214 \tTraining Accuracy 52.472% \tValidation Accuracy 53.183%\n",
      "Epoch: 781 \tTraining Loss: 0.00684669 \tValidation Loss 0.00738525 \tTraining Accuracy 52.101% \tValidation Accuracy 53.535%\n",
      "Epoch: 782 \tTraining Loss: 0.00685047 \tValidation Loss 0.00736805 \tTraining Accuracy 51.973% \tValidation Accuracy 54.414%\n",
      "Epoch: 783 \tTraining Loss: 0.00683910 \tValidation Loss 0.00735715 \tTraining Accuracy 52.266% \tValidation Accuracy 53.007%\n",
      "Epoch: 784 \tTraining Loss: 0.00683715 \tValidation Loss 0.00743192 \tTraining Accuracy 52.441% \tValidation Accuracy 53.429%\n",
      "Epoch: 785 \tTraining Loss: 0.00683765 \tValidation Loss 0.00737169 \tTraining Accuracy 52.354% \tValidation Accuracy 53.324%\n",
      "Epoch: 786 \tTraining Loss: 0.00684375 \tValidation Loss 0.00737300 \tTraining Accuracy 52.111% \tValidation Accuracy 53.218%\n",
      "Epoch: 787 \tTraining Loss: 0.00684836 \tValidation Loss 0.00732411 \tTraining Accuracy 52.094% \tValidation Accuracy 53.992%\n",
      "Epoch: 788 \tTraining Loss: 0.00683592 \tValidation Loss 0.00737159 \tTraining Accuracy 52.610% \tValidation Accuracy 52.902%\n",
      "Epoch: 789 \tTraining Loss: 0.00684012 \tValidation Loss 0.00729328 \tTraining Accuracy 52.364% \tValidation Accuracy 54.063%\n",
      "Epoch: 790 \tTraining Loss: 0.00683221 \tValidation Loss 0.00733122 \tTraining Accuracy 52.522% \tValidation Accuracy 54.379%\n",
      "Epoch: 791 \tTraining Loss: 0.00683194 \tValidation Loss 0.00735090 \tTraining Accuracy 52.563% \tValidation Accuracy 54.203%\n",
      "Epoch: 792 \tTraining Loss: 0.00683595 \tValidation Loss 0.00738418 \tTraining Accuracy 52.391% \tValidation Accuracy 53.289%\n",
      "Epoch: 793 \tTraining Loss: 0.00683732 \tValidation Loss 0.00736785 \tTraining Accuracy 52.428% \tValidation Accuracy 53.570%\n",
      "Epoch: 794 \tTraining Loss: 0.00683973 \tValidation Loss 0.00737232 \tTraining Accuracy 52.505% \tValidation Accuracy 54.414%\n",
      "Epoch: 795 \tTraining Loss: 0.00684099 \tValidation Loss 0.00737071 \tTraining Accuracy 52.306% \tValidation Accuracy 54.485%\n",
      "Epoch: 796 \tTraining Loss: 0.00683466 \tValidation Loss 0.00739087 \tTraining Accuracy 52.468% \tValidation Accuracy 53.324%\n",
      "Epoch: 797 \tTraining Loss: 0.00683386 \tValidation Loss 0.00740150 \tTraining Accuracy 52.364% \tValidation Accuracy 53.781%\n",
      "Epoch: 798 \tTraining Loss: 0.00683585 \tValidation Loss 0.00735692 \tTraining Accuracy 52.367% \tValidation Accuracy 53.465%\n",
      "Epoch: 799 \tTraining Loss: 0.00683292 \tValidation Loss 0.00732566 \tTraining Accuracy 52.576% \tValidation Accuracy 53.429%\n",
      "Epoch: 800 \tTraining Loss: 0.00683307 \tValidation Loss 0.00727329 \tTraining Accuracy 52.627% \tValidation Accuracy 54.450%\n",
      "Epoch: 801 \tTraining Loss: 0.00683579 \tValidation Loss 0.00737320 \tTraining Accuracy 52.404% \tValidation Accuracy 53.781%\n",
      "Epoch: 802 \tTraining Loss: 0.00683465 \tValidation Loss 0.00738030 \tTraining Accuracy 52.397% \tValidation Accuracy 53.570%\n",
      "Epoch: 803 \tTraining Loss: 0.00683289 \tValidation Loss 0.00732949 \tTraining Accuracy 52.492% \tValidation Accuracy 53.746%\n",
      "Epoch: 804 \tTraining Loss: 0.00682821 \tValidation Loss 0.00735266 \tTraining Accuracy 52.664% \tValidation Accuracy 53.781%\n",
      "Epoch: 805 \tTraining Loss: 0.00683128 \tValidation Loss 0.00735414 \tTraining Accuracy 52.539% \tValidation Accuracy 53.465%\n",
      "Epoch: 806 \tTraining Loss: 0.00683514 \tValidation Loss 0.00739890 \tTraining Accuracy 52.499% \tValidation Accuracy 54.309%\n",
      "Epoch: 807 \tTraining Loss: 0.00683537 \tValidation Loss 0.00733263 \tTraining Accuracy 52.418% \tValidation Accuracy 53.570%\n",
      "Epoch: 808 \tTraining Loss: 0.00682913 \tValidation Loss 0.00736847 \tTraining Accuracy 52.670% \tValidation Accuracy 53.641%\n",
      "Epoch: 809 \tTraining Loss: 0.00682738 \tValidation Loss 0.00737425 \tTraining Accuracy 52.637% \tValidation Accuracy 53.465%\n",
      "Epoch: 810 \tTraining Loss: 0.00683281 \tValidation Loss 0.00733611 \tTraining Accuracy 52.583% \tValidation Accuracy 54.027%\n",
      "Epoch: 811 \tTraining Loss: 0.00682693 \tValidation Loss 0.00736432 \tTraining Accuracy 52.627% \tValidation Accuracy 52.972%\n",
      "Epoch: 812 \tTraining Loss: 0.00682037 \tValidation Loss 0.00738106 \tTraining Accuracy 52.788% \tValidation Accuracy 53.781%\n",
      "Epoch: 813 \tTraining Loss: 0.00683292 \tValidation Loss 0.00740615 \tTraining Accuracy 52.509% \tValidation Accuracy 53.500%\n",
      "Epoch: 814 \tTraining Loss: 0.00682408 \tValidation Loss 0.00737340 \tTraining Accuracy 52.869% \tValidation Accuracy 52.796%\n",
      "Epoch: 815 \tTraining Loss: 0.00682625 \tValidation Loss 0.00736711 \tTraining Accuracy 52.711% \tValidation Accuracy 53.113%\n",
      "Epoch: 816 \tTraining Loss: 0.00682187 \tValidation Loss 0.00735889 \tTraining Accuracy 52.728% \tValidation Accuracy 53.605%\n",
      "Epoch: 817 \tTraining Loss: 0.00682796 \tValidation Loss 0.00738266 \tTraining Accuracy 52.674% \tValidation Accuracy 53.605%\n",
      "Epoch: 818 \tTraining Loss: 0.00682473 \tValidation Loss 0.00732487 \tTraining Accuracy 52.765% \tValidation Accuracy 53.781%\n",
      "Epoch: 819 \tTraining Loss: 0.00683007 \tValidation Loss 0.00738703 \tTraining Accuracy 52.586% \tValidation Accuracy 53.992%\n",
      "Epoch: 820 \tTraining Loss: 0.00682614 \tValidation Loss 0.00728883 \tTraining Accuracy 52.721% \tValidation Accuracy 54.344%\n",
      "Epoch: 821 \tTraining Loss: 0.00682763 \tValidation Loss 0.00737949 \tTraining Accuracy 52.633% \tValidation Accuracy 53.324%\n",
      "Epoch: 822 \tTraining Loss: 0.00684379 \tValidation Loss 0.00741620 \tTraining Accuracy 52.195% \tValidation Accuracy 53.043%\n",
      "Epoch: 823 \tTraining Loss: 0.00683254 \tValidation Loss 0.00734357 \tTraining Accuracy 52.387% \tValidation Accuracy 53.957%\n",
      "Epoch: 824 \tTraining Loss: 0.00681722 \tValidation Loss 0.00732592 \tTraining Accuracy 52.933% \tValidation Accuracy 53.992%\n",
      "Epoch: 825 \tTraining Loss: 0.00682334 \tValidation Loss 0.00735317 \tTraining Accuracy 52.697% \tValidation Accuracy 53.957%\n",
      "Epoch: 826 \tTraining Loss: 0.00682328 \tValidation Loss 0.00735837 \tTraining Accuracy 52.819% \tValidation Accuracy 53.394%\n",
      "Epoch: 827 \tTraining Loss: 0.00682638 \tValidation Loss 0.00730239 \tTraining Accuracy 52.667% \tValidation Accuracy 54.731%\n",
      "Epoch: 828 \tTraining Loss: 0.00682114 \tValidation Loss 0.00735597 \tTraining Accuracy 52.775% \tValidation Accuracy 53.429%\n",
      "Epoch: 829 \tTraining Loss: 0.00681745 \tValidation Loss 0.00733722 \tTraining Accuracy 52.842% \tValidation Accuracy 54.555%\n",
      "Epoch: 830 \tTraining Loss: 0.00681906 \tValidation Loss 0.00740664 \tTraining Accuracy 52.920% \tValidation Accuracy 53.500%\n",
      "Epoch: 831 \tTraining Loss: 0.00682827 \tValidation Loss 0.00735040 \tTraining Accuracy 52.617% \tValidation Accuracy 54.133%\n",
      "Epoch: 832 \tTraining Loss: 0.00682166 \tValidation Loss 0.00739204 \tTraining Accuracy 52.825% \tValidation Accuracy 52.972%\n",
      "Epoch: 833 \tTraining Loss: 0.00682554 \tValidation Loss 0.00735304 \tTraining Accuracy 52.630% \tValidation Accuracy 53.570%\n",
      "Epoch: 834 \tTraining Loss: 0.00682245 \tValidation Loss 0.00732732 \tTraining Accuracy 52.664% \tValidation Accuracy 54.133%\n",
      "Epoch: 835 \tTraining Loss: 0.00681475 \tValidation Loss 0.00735871 \tTraining Accuracy 53.065% \tValidation Accuracy 53.570%\n",
      "Epoch: 836 \tTraining Loss: 0.00681920 \tValidation Loss 0.00737677 \tTraining Accuracy 52.896% \tValidation Accuracy 53.183%\n",
      "Epoch: 837 \tTraining Loss: 0.00681819 \tValidation Loss 0.00737187 \tTraining Accuracy 52.889% \tValidation Accuracy 53.781%\n",
      "Epoch: 838 \tTraining Loss: 0.00681217 \tValidation Loss 0.00737430 \tTraining Accuracy 53.011% \tValidation Accuracy 53.465%\n",
      "Epoch: 839 \tTraining Loss: 0.00682032 \tValidation Loss 0.00735147 \tTraining Accuracy 52.849% \tValidation Accuracy 53.957%\n",
      "Epoch: 840 \tTraining Loss: 0.00681372 \tValidation Loss 0.00741870 \tTraining Accuracy 53.024% \tValidation Accuracy 52.726%\n",
      "Epoch: 841 \tTraining Loss: 0.00681608 \tValidation Loss 0.00733211 \tTraining Accuracy 53.115% \tValidation Accuracy 54.379%\n",
      "Epoch: 842 \tTraining Loss: 0.00681180 \tValidation Loss 0.00739037 \tTraining Accuracy 53.112% \tValidation Accuracy 53.500%\n",
      "Epoch: 843 \tTraining Loss: 0.00681695 \tValidation Loss 0.00734830 \tTraining Accuracy 52.896% \tValidation Accuracy 53.570%\n",
      "Epoch: 844 \tTraining Loss: 0.00681585 \tValidation Loss 0.00731695 \tTraining Accuracy 52.994% \tValidation Accuracy 54.168%\n",
      "Epoch: 845 \tTraining Loss: 0.00681501 \tValidation Loss 0.00738655 \tTraining Accuracy 52.910% \tValidation Accuracy 53.218%\n",
      "Epoch: 846 \tTraining Loss: 0.00680971 \tValidation Loss 0.00735621 \tTraining Accuracy 53.092% \tValidation Accuracy 53.992%\n",
      "Epoch: 847 \tTraining Loss: 0.00681417 \tValidation Loss 0.00735258 \tTraining Accuracy 52.984% \tValidation Accuracy 54.520%\n",
      "Epoch: 848 \tTraining Loss: 0.00681253 \tValidation Loss 0.00728757 \tTraining Accuracy 53.169% \tValidation Accuracy 54.872%\n",
      "Epoch: 849 \tTraining Loss: 0.00681228 \tValidation Loss 0.00734390 \tTraining Accuracy 53.061% \tValidation Accuracy 54.661%\n",
      "Epoch: 850 \tTraining Loss: 0.00680605 \tValidation Loss 0.00739289 \tTraining Accuracy 53.095% \tValidation Accuracy 52.937%\n",
      "Epoch: 851 \tTraining Loss: 0.00680494 \tValidation Loss 0.00736485 \tTraining Accuracy 53.348% \tValidation Accuracy 53.887%\n",
      "Epoch: 852 \tTraining Loss: 0.00680961 \tValidation Loss 0.00737541 \tTraining Accuracy 53.122% \tValidation Accuracy 53.746%\n",
      "Epoch: 853 \tTraining Loss: 0.00681143 \tValidation Loss 0.00731953 \tTraining Accuracy 53.129% \tValidation Accuracy 53.570%\n",
      "Epoch: 854 \tTraining Loss: 0.00680712 \tValidation Loss 0.00734641 \tTraining Accuracy 53.135% \tValidation Accuracy 54.555%\n",
      "Epoch: 855 \tTraining Loss: 0.00680709 \tValidation Loss 0.00732652 \tTraining Accuracy 53.294% \tValidation Accuracy 55.153%\n",
      "Epoch: 856 \tTraining Loss: 0.00680741 \tValidation Loss 0.00732898 \tTraining Accuracy 53.075% \tValidation Accuracy 53.781%\n",
      "Epoch: 857 \tTraining Loss: 0.00680621 \tValidation Loss 0.00736795 \tTraining Accuracy 53.129% \tValidation Accuracy 53.605%\n",
      "Epoch: 858 \tTraining Loss: 0.00680809 \tValidation Loss 0.00738789 \tTraining Accuracy 53.098% \tValidation Accuracy 53.043%\n",
      "Epoch: 859 \tTraining Loss: 0.00681186 \tValidation Loss 0.00737393 \tTraining Accuracy 52.933% \tValidation Accuracy 54.098%\n",
      "Epoch: 860 \tTraining Loss: 0.00680553 \tValidation Loss 0.00735749 \tTraining Accuracy 53.243% \tValidation Accuracy 54.555%\n",
      "Epoch: 861 \tTraining Loss: 0.00681232 \tValidation Loss 0.00736497 \tTraining Accuracy 53.041% \tValidation Accuracy 53.218%\n",
      "Epoch: 862 \tTraining Loss: 0.00681113 \tValidation Loss 0.00741151 \tTraining Accuracy 53.001% \tValidation Accuracy 53.465%\n",
      "Epoch: 863 \tTraining Loss: 0.00680494 \tValidation Loss 0.00734372 \tTraining Accuracy 53.257% \tValidation Accuracy 53.746%\n",
      "Epoch: 864 \tTraining Loss: 0.00679664 \tValidation Loss 0.00732086 \tTraining Accuracy 53.422% \tValidation Accuracy 54.168%\n",
      "Epoch: 865 \tTraining Loss: 0.00681137 \tValidation Loss 0.00728665 \tTraining Accuracy 53.142% \tValidation Accuracy 54.520%\n",
      "Epoch: 866 \tTraining Loss: 0.00681196 \tValidation Loss 0.00738514 \tTraining Accuracy 53.149% \tValidation Accuracy 53.852%\n",
      "Epoch: 867 \tTraining Loss: 0.00680590 \tValidation Loss 0.00732211 \tTraining Accuracy 53.142% \tValidation Accuracy 53.359%\n",
      "Epoch: 868 \tTraining Loss: 0.00680237 \tValidation Loss 0.00735159 \tTraining Accuracy 53.301% \tValidation Accuracy 54.450%\n",
      "Epoch: 869 \tTraining Loss: 0.00680298 \tValidation Loss 0.00731991 \tTraining Accuracy 53.344% \tValidation Accuracy 54.696%\n",
      "Epoch: 870 \tTraining Loss: 0.00680613 \tValidation Loss 0.00729315 \tTraining Accuracy 53.351% \tValidation Accuracy 54.801%\n",
      "Epoch: 871 \tTraining Loss: 0.00680607 \tValidation Loss 0.00729792 \tTraining Accuracy 53.095% \tValidation Accuracy 54.485%\n",
      "Epoch: 872 \tTraining Loss: 0.00680470 \tValidation Loss 0.00737222 \tTraining Accuracy 53.210% \tValidation Accuracy 53.535%\n",
      "Epoch: 873 \tTraining Loss: 0.00680737 \tValidation Loss 0.00733536 \tTraining Accuracy 53.075% \tValidation Accuracy 54.274%\n",
      "Epoch: 874 \tTraining Loss: 0.00679902 \tValidation Loss 0.00739623 \tTraining Accuracy 53.365% \tValidation Accuracy 53.324%\n",
      "Epoch: 875 \tTraining Loss: 0.00679995 \tValidation Loss 0.00739260 \tTraining Accuracy 53.321% \tValidation Accuracy 54.098%\n",
      "Epoch: 876 \tTraining Loss: 0.00680601 \tValidation Loss 0.00733419 \tTraining Accuracy 53.142% \tValidation Accuracy 55.223%\n",
      "Epoch: 877 \tTraining Loss: 0.00680509 \tValidation Loss 0.00731426 \tTraining Accuracy 53.257% \tValidation Accuracy 54.485%\n",
      "Epoch: 878 \tTraining Loss: 0.00680318 \tValidation Loss 0.00736080 \tTraining Accuracy 53.257% \tValidation Accuracy 54.027%\n",
      "Epoch: 879 \tTraining Loss: 0.00679929 \tValidation Loss 0.00738843 \tTraining Accuracy 53.321% \tValidation Accuracy 53.992%\n",
      "Epoch: 880 \tTraining Loss: 0.00680391 \tValidation Loss 0.00730758 \tTraining Accuracy 53.277% \tValidation Accuracy 54.485%\n",
      "Epoch: 881 \tTraining Loss: 0.00679314 \tValidation Loss 0.00734355 \tTraining Accuracy 53.671% \tValidation Accuracy 53.324%\n",
      "Epoch: 882 \tTraining Loss: 0.00679728 \tValidation Loss 0.00735482 \tTraining Accuracy 53.580% \tValidation Accuracy 53.852%\n",
      "Epoch: 883 \tTraining Loss: 0.00679614 \tValidation Loss 0.00737883 \tTraining Accuracy 53.520% \tValidation Accuracy 54.133%\n",
      "Epoch: 884 \tTraining Loss: 0.00679428 \tValidation Loss 0.00731662 \tTraining Accuracy 53.496% \tValidation Accuracy 54.555%\n",
      "Epoch: 885 \tTraining Loss: 0.00679868 \tValidation Loss 0.00724753 \tTraining Accuracy 53.334% \tValidation Accuracy 55.153%\n",
      "Epoch: 886 \tTraining Loss: 0.00680507 \tValidation Loss 0.00737620 \tTraining Accuracy 53.135% \tValidation Accuracy 54.274%\n",
      "Epoch: 887 \tTraining Loss: 0.00678999 \tValidation Loss 0.00737433 \tTraining Accuracy 53.604% \tValidation Accuracy 53.289%\n",
      "Epoch: 888 \tTraining Loss: 0.00679591 \tValidation Loss 0.00734446 \tTraining Accuracy 53.476% \tValidation Accuracy 53.887%\n",
      "Epoch: 889 \tTraining Loss: 0.00679239 \tValidation Loss 0.00740324 \tTraining Accuracy 53.489% \tValidation Accuracy 53.359%\n",
      "Epoch: 890 \tTraining Loss: 0.00679626 \tValidation Loss 0.00738370 \tTraining Accuracy 53.459% \tValidation Accuracy 53.922%\n",
      "Epoch: 891 \tTraining Loss: 0.00679654 \tValidation Loss 0.00739092 \tTraining Accuracy 53.526% \tValidation Accuracy 53.465%\n",
      "Epoch: 892 \tTraining Loss: 0.00679037 \tValidation Loss 0.00733343 \tTraining Accuracy 53.594% \tValidation Accuracy 55.153%\n",
      "Epoch: 893 \tTraining Loss: 0.00679081 \tValidation Loss 0.00732562 \tTraining Accuracy 53.671% \tValidation Accuracy 55.047%\n",
      "Epoch: 894 \tTraining Loss: 0.00679888 \tValidation Loss 0.00735069 \tTraining Accuracy 53.381% \tValidation Accuracy 54.590%\n",
      "Epoch: 895 \tTraining Loss: 0.00679875 \tValidation Loss 0.00731101 \tTraining Accuracy 53.284% \tValidation Accuracy 53.816%\n",
      "Epoch: 896 \tTraining Loss: 0.00679579 \tValidation Loss 0.00734737 \tTraining Accuracy 53.520% \tValidation Accuracy 54.414%\n",
      "Epoch: 897 \tTraining Loss: 0.00679027 \tValidation Loss 0.00733774 \tTraining Accuracy 53.664% \tValidation Accuracy 53.922%\n",
      "Epoch: 898 \tTraining Loss: 0.00679943 \tValidation Loss 0.00733157 \tTraining Accuracy 53.321% \tValidation Accuracy 54.625%\n",
      "Epoch: 899 \tTraining Loss: 0.00679006 \tValidation Loss 0.00733942 \tTraining Accuracy 53.661% \tValidation Accuracy 53.922%\n",
      "Epoch: 900 \tTraining Loss: 0.00679184 \tValidation Loss 0.00734483 \tTraining Accuracy 53.577% \tValidation Accuracy 55.329%\n",
      "Epoch: 901 \tTraining Loss: 0.00679568 \tValidation Loss 0.00738618 \tTraining Accuracy 53.509% \tValidation Accuracy 54.450%\n",
      "Epoch: 902 \tTraining Loss: 0.00678995 \tValidation Loss 0.00730140 \tTraining Accuracy 53.560% \tValidation Accuracy 55.399%\n",
      "Epoch: 903 \tTraining Loss: 0.00678602 \tValidation Loss 0.00732462 \tTraining Accuracy 53.688% \tValidation Accuracy 54.590%\n",
      "Epoch: 904 \tTraining Loss: 0.00678717 \tValidation Loss 0.00733318 \tTraining Accuracy 53.725% \tValidation Accuracy 55.083%\n",
      "Epoch: 905 \tTraining Loss: 0.00679440 \tValidation Loss 0.00734634 \tTraining Accuracy 53.486% \tValidation Accuracy 54.731%\n",
      "Epoch: 906 \tTraining Loss: 0.00679157 \tValidation Loss 0.00734035 \tTraining Accuracy 53.496% \tValidation Accuracy 54.274%\n",
      "Epoch: 907 \tTraining Loss: 0.00678723 \tValidation Loss 0.00734248 \tTraining Accuracy 53.718% \tValidation Accuracy 53.887%\n",
      "Epoch: 908 \tTraining Loss: 0.00678953 \tValidation Loss 0.00733241 \tTraining Accuracy 53.722% \tValidation Accuracy 54.485%\n",
      "Epoch: 909 \tTraining Loss: 0.00679381 \tValidation Loss 0.00735754 \tTraining Accuracy 53.496% \tValidation Accuracy 54.063%\n",
      "Epoch: 910 \tTraining Loss: 0.00680019 \tValidation Loss 0.00734007 \tTraining Accuracy 53.311% \tValidation Accuracy 54.872%\n",
      "Epoch: 911 \tTraining Loss: 0.00679374 \tValidation Loss 0.00724875 \tTraining Accuracy 53.540% \tValidation Accuracy 55.681%\n",
      "Epoch: 912 \tTraining Loss: 0.00678594 \tValidation Loss 0.00737643 \tTraining Accuracy 53.685% \tValidation Accuracy 53.641%\n",
      "Epoch: 913 \tTraining Loss: 0.00678703 \tValidation Loss 0.00734339 \tTraining Accuracy 53.678% \tValidation Accuracy 54.133%\n",
      "Epoch: 914 \tTraining Loss: 0.00679105 \tValidation Loss 0.00731605 \tTraining Accuracy 53.590% \tValidation Accuracy 54.379%\n",
      "Epoch: 915 \tTraining Loss: 0.00678519 \tValidation Loss 0.00734896 \tTraining Accuracy 53.887% \tValidation Accuracy 53.957%\n",
      "Epoch: 916 \tTraining Loss: 0.00679149 \tValidation Loss 0.00734462 \tTraining Accuracy 53.678% \tValidation Accuracy 55.083%\n",
      "Epoch: 917 \tTraining Loss: 0.00677892 \tValidation Loss 0.00731836 \tTraining Accuracy 53.998% \tValidation Accuracy 54.027%\n",
      "Epoch: 918 \tTraining Loss: 0.00678334 \tValidation Loss 0.00730191 \tTraining Accuracy 53.789% \tValidation Accuracy 54.309%\n",
      "Epoch: 919 \tTraining Loss: 0.00678010 \tValidation Loss 0.00730321 \tTraining Accuracy 53.937% \tValidation Accuracy 54.836%\n",
      "Epoch: 920 \tTraining Loss: 0.00679253 \tValidation Loss 0.00729425 \tTraining Accuracy 53.594% \tValidation Accuracy 54.520%\n",
      "Epoch: 921 \tTraining Loss: 0.00678600 \tValidation Loss 0.00735800 \tTraining Accuracy 53.705% \tValidation Accuracy 54.520%\n",
      "Epoch: 922 \tTraining Loss: 0.00678429 \tValidation Loss 0.00738021 \tTraining Accuracy 54.015% \tValidation Accuracy 54.133%\n",
      "Epoch: 923 \tTraining Loss: 0.00678001 \tValidation Loss 0.00729138 \tTraining Accuracy 53.890% \tValidation Accuracy 54.696%\n",
      "Epoch: 924 \tTraining Loss: 0.00678583 \tValidation Loss 0.00731722 \tTraining Accuracy 53.712% \tValidation Accuracy 54.450%\n",
      "Epoch: 925 \tTraining Loss: 0.00678677 \tValidation Loss 0.00732959 \tTraining Accuracy 53.671% \tValidation Accuracy 53.711%\n",
      "Epoch: 926 \tTraining Loss: 0.00678279 \tValidation Loss 0.00730442 \tTraining Accuracy 53.749% \tValidation Accuracy 55.364%\n",
      "Epoch: 927 \tTraining Loss: 0.00679132 \tValidation Loss 0.00733408 \tTraining Accuracy 53.499% \tValidation Accuracy 54.590%\n",
      "Epoch: 928 \tTraining Loss: 0.00678618 \tValidation Loss 0.00732589 \tTraining Accuracy 53.728% \tValidation Accuracy 53.957%\n",
      "Epoch: 929 \tTraining Loss: 0.00678785 \tValidation Loss 0.00734357 \tTraining Accuracy 53.637% \tValidation Accuracy 54.133%\n",
      "Epoch: 930 \tTraining Loss: 0.00678338 \tValidation Loss 0.00737530 \tTraining Accuracy 53.830% \tValidation Accuracy 54.027%\n",
      "Epoch: 931 \tTraining Loss: 0.00678343 \tValidation Loss 0.00735211 \tTraining Accuracy 53.819% \tValidation Accuracy 54.238%\n",
      "Epoch: 932 \tTraining Loss: 0.00677898 \tValidation Loss 0.00731709 \tTraining Accuracy 53.954% \tValidation Accuracy 55.012%\n",
      "Epoch: 933 \tTraining Loss: 0.00678071 \tValidation Loss 0.00729651 \tTraining Accuracy 53.830% \tValidation Accuracy 55.962%\n",
      "Epoch: 934 \tTraining Loss: 0.00678085 \tValidation Loss 0.00732139 \tTraining Accuracy 53.830% \tValidation Accuracy 53.852%\n",
      "Epoch: 935 \tTraining Loss: 0.00677484 \tValidation Loss 0.00735559 \tTraining Accuracy 54.116% \tValidation Accuracy 54.696%\n",
      "Epoch: 936 \tTraining Loss: 0.00678219 \tValidation Loss 0.00738152 \tTraining Accuracy 53.907% \tValidation Accuracy 54.098%\n",
      "Epoch: 937 \tTraining Loss: 0.00677069 \tValidation Loss 0.00731708 \tTraining Accuracy 54.119% \tValidation Accuracy 54.520%\n",
      "Epoch: 938 \tTraining Loss: 0.00677624 \tValidation Loss 0.00740536 \tTraining Accuracy 54.032% \tValidation Accuracy 53.641%\n",
      "Epoch: 939 \tTraining Loss: 0.00677744 \tValidation Loss 0.00738132 \tTraining Accuracy 53.917% \tValidation Accuracy 54.063%\n",
      "Epoch: 940 \tTraining Loss: 0.00678076 \tValidation Loss 0.00734997 \tTraining Accuracy 53.766% \tValidation Accuracy 53.957%\n",
      "Epoch: 941 \tTraining Loss: 0.00678407 \tValidation Loss 0.00732838 \tTraining Accuracy 53.809% \tValidation Accuracy 54.168%\n",
      "Epoch: 942 \tTraining Loss: 0.00678190 \tValidation Loss 0.00734007 \tTraining Accuracy 54.008% \tValidation Accuracy 55.153%\n",
      "Epoch: 943 \tTraining Loss: 0.00678438 \tValidation Loss 0.00735506 \tTraining Accuracy 53.718% \tValidation Accuracy 53.500%\n",
      "Epoch: 944 \tTraining Loss: 0.00677686 \tValidation Loss 0.00729424 \tTraining Accuracy 53.948% \tValidation Accuracy 55.223%\n",
      "Epoch: 945 \tTraining Loss: 0.00677225 \tValidation Loss 0.00734629 \tTraining Accuracy 54.113% \tValidation Accuracy 53.922%\n",
      "Epoch: 946 \tTraining Loss: 0.00677316 \tValidation Loss 0.00734505 \tTraining Accuracy 54.079% \tValidation Accuracy 54.063%\n",
      "Epoch: 947 \tTraining Loss: 0.00678232 \tValidation Loss 0.00733101 \tTraining Accuracy 53.806% \tValidation Accuracy 54.731%\n",
      "Epoch: 948 \tTraining Loss: 0.00677284 \tValidation Loss 0.00736874 \tTraining Accuracy 54.045% \tValidation Accuracy 54.625%\n",
      "Epoch: 949 \tTraining Loss: 0.00677019 \tValidation Loss 0.00732004 \tTraining Accuracy 54.190% \tValidation Accuracy 54.414%\n",
      "Epoch: 950 \tTraining Loss: 0.00678274 \tValidation Loss 0.00732993 \tTraining Accuracy 53.863% \tValidation Accuracy 55.223%\n",
      "Epoch: 951 \tTraining Loss: 0.00676669 \tValidation Loss 0.00724362 \tTraining Accuracy 54.311% \tValidation Accuracy 55.927%\n",
      "Epoch: 952 \tTraining Loss: 0.00677345 \tValidation Loss 0.00733306 \tTraining Accuracy 54.065% \tValidation Accuracy 54.942%\n",
      "Epoch: 953 \tTraining Loss: 0.00676458 \tValidation Loss 0.00734228 \tTraining Accuracy 54.200% \tValidation Accuracy 53.641%\n",
      "Epoch: 954 \tTraining Loss: 0.00677466 \tValidation Loss 0.00730281 \tTraining Accuracy 53.870% \tValidation Accuracy 54.696%\n",
      "Epoch: 955 \tTraining Loss: 0.00677199 \tValidation Loss 0.00732057 \tTraining Accuracy 54.197% \tValidation Accuracy 54.625%\n",
      "Epoch: 956 \tTraining Loss: 0.00676834 \tValidation Loss 0.00738123 \tTraining Accuracy 54.281% \tValidation Accuracy 53.676%\n",
      "Epoch: 957 \tTraining Loss: 0.00677855 \tValidation Loss 0.00732866 \tTraining Accuracy 53.779% \tValidation Accuracy 54.661%\n",
      "Epoch: 958 \tTraining Loss: 0.00677070 \tValidation Loss 0.00732503 \tTraining Accuracy 54.156% \tValidation Accuracy 53.887%\n",
      "Epoch: 959 \tTraining Loss: 0.00677153 \tValidation Loss 0.00733499 \tTraining Accuracy 53.998% \tValidation Accuracy 55.118%\n",
      "Epoch: 960 \tTraining Loss: 0.00676805 \tValidation Loss 0.00727159 \tTraining Accuracy 54.220% \tValidation Accuracy 54.625%\n",
      "Epoch: 961 \tTraining Loss: 0.00677202 \tValidation Loss 0.00729206 \tTraining Accuracy 54.045% \tValidation Accuracy 55.188%\n",
      "Epoch: 962 \tTraining Loss: 0.00677712 \tValidation Loss 0.00732955 \tTraining Accuracy 53.823% \tValidation Accuracy 54.696%\n",
      "Epoch: 963 \tTraining Loss: 0.00676905 \tValidation Loss 0.00731241 \tTraining Accuracy 54.241% \tValidation Accuracy 55.047%\n",
      "Epoch: 964 \tTraining Loss: 0.00676583 \tValidation Loss 0.00733949 \tTraining Accuracy 54.291% \tValidation Accuracy 54.696%\n",
      "Epoch: 965 \tTraining Loss: 0.00676396 \tValidation Loss 0.00731290 \tTraining Accuracy 54.413% \tValidation Accuracy 54.766%\n",
      "Epoch: 966 \tTraining Loss: 0.00676454 \tValidation Loss 0.00727382 \tTraining Accuracy 54.241% \tValidation Accuracy 55.399%\n",
      "Epoch: 967 \tTraining Loss: 0.00678072 \tValidation Loss 0.00732637 \tTraining Accuracy 53.873% \tValidation Accuracy 55.997%\n",
      "Epoch: 968 \tTraining Loss: 0.00676675 \tValidation Loss 0.00737811 \tTraining Accuracy 54.231% \tValidation Accuracy 54.379%\n",
      "Epoch: 969 \tTraining Loss: 0.00675993 \tValidation Loss 0.00735675 \tTraining Accuracy 54.581% \tValidation Accuracy 53.429%\n",
      "Epoch: 970 \tTraining Loss: 0.00676985 \tValidation Loss 0.00735990 \tTraining Accuracy 54.116% \tValidation Accuracy 55.083%\n",
      "Epoch: 971 \tTraining Loss: 0.00676712 \tValidation Loss 0.00728377 \tTraining Accuracy 54.116% \tValidation Accuracy 54.555%\n",
      "Epoch: 972 \tTraining Loss: 0.00676613 \tValidation Loss 0.00735441 \tTraining Accuracy 54.291% \tValidation Accuracy 54.133%\n",
      "Epoch: 973 \tTraining Loss: 0.00677254 \tValidation Loss 0.00730532 \tTraining Accuracy 54.052% \tValidation Accuracy 54.836%\n",
      "Epoch: 974 \tTraining Loss: 0.00676711 \tValidation Loss 0.00737738 \tTraining Accuracy 54.193% \tValidation Accuracy 53.957%\n",
      "Epoch: 975 \tTraining Loss: 0.00676540 \tValidation Loss 0.00731338 \tTraining Accuracy 54.224% \tValidation Accuracy 54.274%\n",
      "Epoch: 976 \tTraining Loss: 0.00675731 \tValidation Loss 0.00731102 \tTraining Accuracy 54.500% \tValidation Accuracy 54.450%\n",
      "Epoch: 977 \tTraining Loss: 0.00676071 \tValidation Loss 0.00732600 \tTraining Accuracy 54.375% \tValidation Accuracy 54.485%\n",
      "Epoch: 978 \tTraining Loss: 0.00677465 \tValidation Loss 0.00728946 \tTraining Accuracy 54.076% \tValidation Accuracy 54.555%\n",
      "Epoch: 979 \tTraining Loss: 0.00676789 \tValidation Loss 0.00733196 \tTraining Accuracy 54.217% \tValidation Accuracy 54.027%\n",
      "Epoch: 980 \tTraining Loss: 0.00676434 \tValidation Loss 0.00733045 \tTraining Accuracy 54.291% \tValidation Accuracy 54.485%\n",
      "Epoch: 981 \tTraining Loss: 0.00676386 \tValidation Loss 0.00732558 \tTraining Accuracy 54.278% \tValidation Accuracy 54.203%\n",
      "Epoch: 982 \tTraining Loss: 0.00676432 \tValidation Loss 0.00732056 \tTraining Accuracy 54.345% \tValidation Accuracy 55.047%\n",
      "Epoch: 983 \tTraining Loss: 0.00676638 \tValidation Loss 0.00731334 \tTraining Accuracy 54.274% \tValidation Accuracy 55.118%\n",
      "Epoch: 984 \tTraining Loss: 0.00675558 \tValidation Loss 0.00731997 \tTraining Accuracy 54.534% \tValidation Accuracy 54.238%\n",
      "Epoch: 985 \tTraining Loss: 0.00676316 \tValidation Loss 0.00726776 \tTraining Accuracy 54.379% \tValidation Accuracy 56.490%\n",
      "Epoch: 986 \tTraining Loss: 0.00676804 \tValidation Loss 0.00730860 \tTraining Accuracy 54.129% \tValidation Accuracy 55.188%\n",
      "Epoch: 987 \tTraining Loss: 0.00676502 \tValidation Loss 0.00728649 \tTraining Accuracy 54.278% \tValidation Accuracy 54.836%\n",
      "Epoch: 988 \tTraining Loss: 0.00676177 \tValidation Loss 0.00729141 \tTraining Accuracy 54.301% \tValidation Accuracy 55.083%\n",
      "Epoch: 989 \tTraining Loss: 0.00675126 \tValidation Loss 0.00727213 \tTraining Accuracy 54.706% \tValidation Accuracy 55.083%\n",
      "Epoch: 990 \tTraining Loss: 0.00676845 \tValidation Loss 0.00728370 \tTraining Accuracy 54.183% \tValidation Accuracy 55.470%\n",
      "Epoch: 991 \tTraining Loss: 0.00675965 \tValidation Loss 0.00725636 \tTraining Accuracy 54.450% \tValidation Accuracy 55.505%\n",
      "Epoch: 992 \tTraining Loss: 0.00676249 \tValidation Loss 0.00729749 \tTraining Accuracy 54.375% \tValidation Accuracy 54.238%\n",
      "Epoch: 993 \tTraining Loss: 0.00675257 \tValidation Loss 0.00733497 \tTraining Accuracy 54.709% \tValidation Accuracy 53.852%\n",
      "Epoch: 994 \tTraining Loss: 0.00675725 \tValidation Loss 0.00730765 \tTraining Accuracy 54.473% \tValidation Accuracy 54.661%\n",
      "Epoch: 995 \tTraining Loss: 0.00676358 \tValidation Loss 0.00732218 \tTraining Accuracy 54.318% \tValidation Accuracy 54.696%\n",
      "Epoch: 996 \tTraining Loss: 0.00675558 \tValidation Loss 0.00725199 \tTraining Accuracy 54.520% \tValidation Accuracy 54.661%\n",
      "Epoch: 997 \tTraining Loss: 0.00675984 \tValidation Loss 0.00727493 \tTraining Accuracy 54.365% \tValidation Accuracy 55.681%\n",
      "Epoch: 998 \tTraining Loss: 0.00675689 \tValidation Loss 0.00731484 \tTraining Accuracy 54.503% \tValidation Accuracy 55.259%\n",
      "Epoch: 999 \tTraining Loss: 0.00675470 \tValidation Loss 0.00731823 \tTraining Accuracy 54.581% \tValidation Accuracy 54.696%\n",
      "Epoch: 1000 \tTraining Loss: 0.00675392 \tValidation Loss 0.00735943 \tTraining Accuracy 54.530% \tValidation Accuracy 54.238%\n",
      "Epoch: 1001 \tTraining Loss: 0.00676108 \tValidation Loss 0.00729600 \tTraining Accuracy 54.355% \tValidation Accuracy 54.977%\n",
      "Epoch: 1002 \tTraining Loss: 0.00675922 \tValidation Loss 0.00730789 \tTraining Accuracy 54.490% \tValidation Accuracy 55.153%\n",
      "Epoch: 1003 \tTraining Loss: 0.00675269 \tValidation Loss 0.00728208 \tTraining Accuracy 54.568% \tValidation Accuracy 54.731%\n",
      "Epoch: 1004 \tTraining Loss: 0.00675475 \tValidation Loss 0.00732308 \tTraining Accuracy 54.581% \tValidation Accuracy 55.118%\n",
      "Epoch: 1005 \tTraining Loss: 0.00676012 \tValidation Loss 0.00735615 \tTraining Accuracy 54.426% \tValidation Accuracy 54.274%\n",
      "Epoch: 1006 \tTraining Loss: 0.00675771 \tValidation Loss 0.00725260 \tTraining Accuracy 54.520% \tValidation Accuracy 56.208%\n",
      "Epoch: 1007 \tTraining Loss: 0.00675065 \tValidation Loss 0.00727278 \tTraining Accuracy 54.712% \tValidation Accuracy 55.751%\n",
      "Epoch: 1008 \tTraining Loss: 0.00675633 \tValidation Loss 0.00731112 \tTraining Accuracy 54.530% \tValidation Accuracy 54.309%\n",
      "Epoch: 1009 \tTraining Loss: 0.00674906 \tValidation Loss 0.00730239 \tTraining Accuracy 54.807% \tValidation Accuracy 54.450%\n",
      "Epoch: 1010 \tTraining Loss: 0.00674629 \tValidation Loss 0.00730598 \tTraining Accuracy 54.881% \tValidation Accuracy 55.364%\n",
      "Epoch: 1011 \tTraining Loss: 0.00675487 \tValidation Loss 0.00731241 \tTraining Accuracy 54.571% \tValidation Accuracy 54.414%\n",
      "Epoch: 1012 \tTraining Loss: 0.00675729 \tValidation Loss 0.00727865 \tTraining Accuracy 54.497% \tValidation Accuracy 55.188%\n",
      "Epoch: 1013 \tTraining Loss: 0.00675026 \tValidation Loss 0.00730791 \tTraining Accuracy 54.773% \tValidation Accuracy 54.485%\n",
      "Epoch: 1014 \tTraining Loss: 0.00674756 \tValidation Loss 0.00731543 \tTraining Accuracy 54.921% \tValidation Accuracy 55.434%\n",
      "Epoch: 1015 \tTraining Loss: 0.00674255 \tValidation Loss 0.00726312 \tTraining Accuracy 54.830% \tValidation Accuracy 55.751%\n",
      "Epoch: 1016 \tTraining Loss: 0.00675470 \tValidation Loss 0.00732191 \tTraining Accuracy 54.477% \tValidation Accuracy 55.470%\n",
      "Epoch: 1017 \tTraining Loss: 0.00675261 \tValidation Loss 0.00727722 \tTraining Accuracy 54.601% \tValidation Accuracy 55.047%\n",
      "Epoch: 1018 \tTraining Loss: 0.00675113 \tValidation Loss 0.00727383 \tTraining Accuracy 54.679% \tValidation Accuracy 55.399%\n",
      "Epoch: 1019 \tTraining Loss: 0.00675379 \tValidation Loss 0.00733267 \tTraining Accuracy 54.456% \tValidation Accuracy 54.379%\n",
      "Epoch: 1020 \tTraining Loss: 0.00674450 \tValidation Loss 0.00732083 \tTraining Accuracy 54.817% \tValidation Accuracy 54.027%\n",
      "Epoch: 1021 \tTraining Loss: 0.00675610 \tValidation Loss 0.00730501 \tTraining Accuracy 54.507% \tValidation Accuracy 54.942%\n",
      "Epoch: 1022 \tTraining Loss: 0.00674565 \tValidation Loss 0.00727955 \tTraining Accuracy 54.837% \tValidation Accuracy 55.540%\n",
      "Epoch: 1023 \tTraining Loss: 0.00675191 \tValidation Loss 0.00730023 \tTraining Accuracy 54.669% \tValidation Accuracy 55.681%\n",
      "Epoch: 1024 \tTraining Loss: 0.00675207 \tValidation Loss 0.00730541 \tTraining Accuracy 54.466% \tValidation Accuracy 55.223%\n",
      "Epoch: 1025 \tTraining Loss: 0.00673917 \tValidation Loss 0.00727526 \tTraining Accuracy 55.043% \tValidation Accuracy 56.173%\n",
      "Epoch: 1026 \tTraining Loss: 0.00674820 \tValidation Loss 0.00730925 \tTraining Accuracy 54.803% \tValidation Accuracy 55.856%\n",
      "Epoch: 1027 \tTraining Loss: 0.00674891 \tValidation Loss 0.00730106 \tTraining Accuracy 54.699% \tValidation Accuracy 54.801%\n",
      "Epoch: 1028 \tTraining Loss: 0.00674802 \tValidation Loss 0.00727451 \tTraining Accuracy 54.830% \tValidation Accuracy 54.625%\n",
      "Epoch: 1029 \tTraining Loss: 0.00674230 \tValidation Loss 0.00727220 \tTraining Accuracy 54.942% \tValidation Accuracy 55.716%\n",
      "Epoch: 1030 \tTraining Loss: 0.00673876 \tValidation Loss 0.00737769 \tTraining Accuracy 54.995% \tValidation Accuracy 54.309%\n",
      "Epoch: 1031 \tTraining Loss: 0.00674201 \tValidation Loss 0.00727647 \tTraining Accuracy 54.972% \tValidation Accuracy 56.841%\n",
      "Epoch: 1032 \tTraining Loss: 0.00673981 \tValidation Loss 0.00732892 \tTraining Accuracy 55.026% \tValidation Accuracy 54.520%\n",
      "Epoch: 1033 \tTraining Loss: 0.00674959 \tValidation Loss 0.00726312 \tTraining Accuracy 54.682% \tValidation Accuracy 55.294%\n",
      "Epoch: 1034 \tTraining Loss: 0.00674775 \tValidation Loss 0.00734655 \tTraining Accuracy 54.716% \tValidation Accuracy 54.661%\n",
      "Epoch: 1035 \tTraining Loss: 0.00674278 \tValidation Loss 0.00727512 \tTraining Accuracy 54.904% \tValidation Accuracy 55.294%\n",
      "Epoch: 1036 \tTraining Loss: 0.00673755 \tValidation Loss 0.00734902 \tTraining Accuracy 55.026% \tValidation Accuracy 55.259%\n",
      "Epoch: 1037 \tTraining Loss: 0.00674309 \tValidation Loss 0.00729655 \tTraining Accuracy 54.749% \tValidation Accuracy 54.872%\n",
      "Epoch: 1038 \tTraining Loss: 0.00674028 \tValidation Loss 0.00729715 \tTraining Accuracy 54.901% \tValidation Accuracy 55.083%\n",
      "Epoch: 1039 \tTraining Loss: 0.00674489 \tValidation Loss 0.00726108 \tTraining Accuracy 54.921% \tValidation Accuracy 55.575%\n",
      "Epoch: 1040 \tTraining Loss: 0.00673745 \tValidation Loss 0.00735365 \tTraining Accuracy 55.097% \tValidation Accuracy 55.645%\n",
      "Epoch: 1041 \tTraining Loss: 0.00674731 \tValidation Loss 0.00731120 \tTraining Accuracy 54.628% \tValidation Accuracy 54.766%\n",
      "Epoch: 1042 \tTraining Loss: 0.00674156 \tValidation Loss 0.00727595 \tTraining Accuracy 54.928% \tValidation Accuracy 55.329%\n",
      "Epoch: 1043 \tTraining Loss: 0.00673929 \tValidation Loss 0.00731614 \tTraining Accuracy 55.002% \tValidation Accuracy 55.399%\n",
      "Epoch: 1044 \tTraining Loss: 0.00673884 \tValidation Loss 0.00725805 \tTraining Accuracy 54.918% \tValidation Accuracy 55.364%\n",
      "Epoch: 1045 \tTraining Loss: 0.00674889 \tValidation Loss 0.00729409 \tTraining Accuracy 54.719% \tValidation Accuracy 55.329%\n",
      "Epoch: 1046 \tTraining Loss: 0.00673209 \tValidation Loss 0.00724970 \tTraining Accuracy 55.208% \tValidation Accuracy 55.610%\n",
      "Epoch: 1047 \tTraining Loss: 0.00673643 \tValidation Loss 0.00729551 \tTraining Accuracy 55.137% \tValidation Accuracy 55.997%\n",
      "Epoch: 1048 \tTraining Loss: 0.00673739 \tValidation Loss 0.00732383 \tTraining Accuracy 54.952% \tValidation Accuracy 56.068%\n",
      "Epoch: 1049 \tTraining Loss: 0.00674086 \tValidation Loss 0.00732284 \tTraining Accuracy 54.898% \tValidation Accuracy 55.470%\n",
      "Epoch: 1050 \tTraining Loss: 0.00674717 \tValidation Loss 0.00724447 \tTraining Accuracy 54.675% \tValidation Accuracy 56.068%\n",
      "Epoch: 1051 \tTraining Loss: 0.00673326 \tValidation Loss 0.00731230 \tTraining Accuracy 55.073% \tValidation Accuracy 54.203%\n",
      "Epoch: 1052 \tTraining Loss: 0.00673696 \tValidation Loss 0.00732394 \tTraining Accuracy 55.110% \tValidation Accuracy 54.203%\n",
      "Epoch: 1053 \tTraining Loss: 0.00673866 \tValidation Loss 0.00729082 \tTraining Accuracy 54.952% \tValidation Accuracy 54.836%\n",
      "Epoch: 1054 \tTraining Loss: 0.00673610 \tValidation Loss 0.00728534 \tTraining Accuracy 55.107% \tValidation Accuracy 55.540%\n",
      "Epoch: 1055 \tTraining Loss: 0.00673613 \tValidation Loss 0.00724271 \tTraining Accuracy 55.002% \tValidation Accuracy 55.434%\n",
      "Epoch: 1056 \tTraining Loss: 0.00674079 \tValidation Loss 0.00727509 \tTraining Accuracy 54.891% \tValidation Accuracy 55.470%\n",
      "Epoch: 1057 \tTraining Loss: 0.00673104 \tValidation Loss 0.00731770 \tTraining Accuracy 55.157% \tValidation Accuracy 55.188%\n",
      "Epoch: 1058 \tTraining Loss: 0.00673899 \tValidation Loss 0.00733254 \tTraining Accuracy 54.904% \tValidation Accuracy 54.555%\n",
      "Epoch: 1059 \tTraining Loss: 0.00673322 \tValidation Loss 0.00728614 \tTraining Accuracy 55.120% \tValidation Accuracy 55.223%\n",
      "Epoch: 1060 \tTraining Loss: 0.00674372 \tValidation Loss 0.00730046 \tTraining Accuracy 54.820% \tValidation Accuracy 55.786%\n",
      "Epoch: 1061 \tTraining Loss: 0.00673238 \tValidation Loss 0.00728260 \tTraining Accuracy 55.184% \tValidation Accuracy 55.153%\n",
      "Epoch: 1062 \tTraining Loss: 0.00674358 \tValidation Loss 0.00732792 \tTraining Accuracy 54.770% \tValidation Accuracy 55.470%\n",
      "Epoch: 1063 \tTraining Loss: 0.00674543 \tValidation Loss 0.00732787 \tTraining Accuracy 54.723% \tValidation Accuracy 54.872%\n",
      "Epoch: 1064 \tTraining Loss: 0.00673614 \tValidation Loss 0.00725855 \tTraining Accuracy 55.029% \tValidation Accuracy 56.243%\n",
      "Epoch: 1065 \tTraining Loss: 0.00673671 \tValidation Loss 0.00728287 \tTraining Accuracy 54.948% \tValidation Accuracy 55.892%\n",
      "Epoch: 1066 \tTraining Loss: 0.00673702 \tValidation Loss 0.00728598 \tTraining Accuracy 55.134% \tValidation Accuracy 54.977%\n",
      "Epoch: 1067 \tTraining Loss: 0.00673360 \tValidation Loss 0.00731666 \tTraining Accuracy 55.076% \tValidation Accuracy 56.138%\n",
      "Epoch: 1068 \tTraining Loss: 0.00673199 \tValidation Loss 0.00727377 \tTraining Accuracy 55.194% \tValidation Accuracy 55.927%\n",
      "Epoch: 1069 \tTraining Loss: 0.00673330 \tValidation Loss 0.00724722 \tTraining Accuracy 55.211% \tValidation Accuracy 55.892%\n",
      "Epoch: 1070 \tTraining Loss: 0.00672533 \tValidation Loss 0.00724692 \tTraining Accuracy 55.444% \tValidation Accuracy 54.731%\n",
      "Epoch: 1071 \tTraining Loss: 0.00673043 \tValidation Loss 0.00730089 \tTraining Accuracy 55.093% \tValidation Accuracy 55.751%\n",
      "Epoch: 1072 \tTraining Loss: 0.00672974 \tValidation Loss 0.00726268 \tTraining Accuracy 55.090% \tValidation Accuracy 55.716%\n",
      "Epoch: 1073 \tTraining Loss: 0.00673573 \tValidation Loss 0.00732639 \tTraining Accuracy 55.157% \tValidation Accuracy 55.575%\n",
      "Epoch: 1074 \tTraining Loss: 0.00673063 \tValidation Loss 0.00727823 \tTraining Accuracy 55.211% \tValidation Accuracy 55.716%\n",
      "Epoch: 1075 \tTraining Loss: 0.00672915 \tValidation Loss 0.00727867 \tTraining Accuracy 55.137% \tValidation Accuracy 54.590%\n",
      "Epoch: 1076 \tTraining Loss: 0.00672666 \tValidation Loss 0.00734033 \tTraining Accuracy 55.316% \tValidation Accuracy 54.625%\n",
      "Epoch: 1077 \tTraining Loss: 0.00672733 \tValidation Loss 0.00722843 \tTraining Accuracy 55.359% \tValidation Accuracy 55.927%\n",
      "Epoch: 1078 \tTraining Loss: 0.00673104 \tValidation Loss 0.00725844 \tTraining Accuracy 55.107% \tValidation Accuracy 54.766%\n",
      "Epoch: 1079 \tTraining Loss: 0.00672799 \tValidation Loss 0.00729190 \tTraining Accuracy 55.235% \tValidation Accuracy 55.294%\n",
      "Epoch: 1080 \tTraining Loss: 0.00673013 \tValidation Loss 0.00725274 \tTraining Accuracy 55.228% \tValidation Accuracy 55.786%\n",
      "Epoch: 1081 \tTraining Loss: 0.00673127 \tValidation Loss 0.00724619 \tTraining Accuracy 55.171% \tValidation Accuracy 56.279%\n",
      "Epoch: 1082 \tTraining Loss: 0.00673637 \tValidation Loss 0.00730245 \tTraining Accuracy 54.938% \tValidation Accuracy 54.027%\n",
      "Epoch: 1083 \tTraining Loss: 0.00673358 \tValidation Loss 0.00731041 \tTraining Accuracy 55.107% \tValidation Accuracy 54.907%\n",
      "Epoch: 1084 \tTraining Loss: 0.00671819 \tValidation Loss 0.00725342 \tTraining Accuracy 55.518% \tValidation Accuracy 55.645%\n",
      "Epoch: 1085 \tTraining Loss: 0.00672856 \tValidation Loss 0.00727433 \tTraining Accuracy 55.278% \tValidation Accuracy 55.540%\n",
      "Epoch: 1086 \tTraining Loss: 0.00672120 \tValidation Loss 0.00730554 \tTraining Accuracy 55.498% \tValidation Accuracy 54.625%\n",
      "Epoch: 1087 \tTraining Loss: 0.00671688 \tValidation Loss 0.00727318 \tTraining Accuracy 55.551% \tValidation Accuracy 55.188%\n",
      "Epoch: 1088 \tTraining Loss: 0.00672676 \tValidation Loss 0.00728264 \tTraining Accuracy 55.353% \tValidation Accuracy 55.892%\n",
      "Epoch: 1089 \tTraining Loss: 0.00672909 \tValidation Loss 0.00726999 \tTraining Accuracy 55.268% \tValidation Accuracy 56.173%\n",
      "Epoch: 1090 \tTraining Loss: 0.00671854 \tValidation Loss 0.00729544 \tTraining Accuracy 55.558% \tValidation Accuracy 55.856%\n",
      "Epoch: 1091 \tTraining Loss: 0.00673283 \tValidation Loss 0.00732561 \tTraining Accuracy 55.150% \tValidation Accuracy 53.922%\n",
      "Epoch: 1092 \tTraining Loss: 0.00673151 \tValidation Loss 0.00724085 \tTraining Accuracy 55.295% \tValidation Accuracy 55.751%\n",
      "Epoch: 1093 \tTraining Loss: 0.00672346 \tValidation Loss 0.00729170 \tTraining Accuracy 55.457% \tValidation Accuracy 55.716%\n",
      "Epoch: 1094 \tTraining Loss: 0.00671361 \tValidation Loss 0.00723254 \tTraining Accuracy 55.524% \tValidation Accuracy 56.982%\n",
      "Epoch: 1095 \tTraining Loss: 0.00672113 \tValidation Loss 0.00727741 \tTraining Accuracy 55.545% \tValidation Accuracy 55.153%\n",
      "Epoch: 1096 \tTraining Loss: 0.00672671 \tValidation Loss 0.00727894 \tTraining Accuracy 55.312% \tValidation Accuracy 56.103%\n",
      "Epoch: 1097 \tTraining Loss: 0.00673122 \tValidation Loss 0.00734278 \tTraining Accuracy 55.059% \tValidation Accuracy 55.786%\n",
      "Epoch: 1098 \tTraining Loss: 0.00672131 \tValidation Loss 0.00720844 \tTraining Accuracy 55.464% \tValidation Accuracy 57.052%\n",
      "Epoch: 1099 \tTraining Loss: 0.00672168 \tValidation Loss 0.00723690 \tTraining Accuracy 55.541% \tValidation Accuracy 55.470%\n",
      "Epoch: 1100 \tTraining Loss: 0.00671881 \tValidation Loss 0.00729429 \tTraining Accuracy 55.524% \tValidation Accuracy 55.294%\n",
      "Epoch: 1101 \tTraining Loss: 0.00671620 \tValidation Loss 0.00731263 \tTraining Accuracy 55.619% \tValidation Accuracy 55.540%\n",
      "Epoch: 1102 \tTraining Loss: 0.00672690 \tValidation Loss 0.00728006 \tTraining Accuracy 55.356% \tValidation Accuracy 56.068%\n",
      "Epoch: 1103 \tTraining Loss: 0.00671570 \tValidation Loss 0.00724762 \tTraining Accuracy 55.494% \tValidation Accuracy 56.384%\n",
      "Epoch: 1104 \tTraining Loss: 0.00671950 \tValidation Loss 0.00726326 \tTraining Accuracy 55.427% \tValidation Accuracy 55.856%\n",
      "Epoch: 1105 \tTraining Loss: 0.00671759 \tValidation Loss 0.00727972 \tTraining Accuracy 55.504% \tValidation Accuracy 54.414%\n",
      "Epoch: 1106 \tTraining Loss: 0.00672311 \tValidation Loss 0.00726266 \tTraining Accuracy 55.390% \tValidation Accuracy 55.575%\n",
      "Epoch: 1107 \tTraining Loss: 0.00672667 \tValidation Loss 0.00728592 \tTraining Accuracy 55.275% \tValidation Accuracy 55.751%\n",
      "Epoch: 1108 \tTraining Loss: 0.00671759 \tValidation Loss 0.00727011 \tTraining Accuracy 55.491% \tValidation Accuracy 55.927%\n",
      "Epoch: 1109 \tTraining Loss: 0.00672062 \tValidation Loss 0.00723003 \tTraining Accuracy 55.356% \tValidation Accuracy 56.490%\n",
      "Epoch: 1110 \tTraining Loss: 0.00672370 \tValidation Loss 0.00724487 \tTraining Accuracy 55.346% \tValidation Accuracy 56.032%\n",
      "Epoch: 1111 \tTraining Loss: 0.00672266 \tValidation Loss 0.00727847 \tTraining Accuracy 55.440% \tValidation Accuracy 55.223%\n",
      "Epoch: 1112 \tTraining Loss: 0.00671792 \tValidation Loss 0.00729204 \tTraining Accuracy 55.632% \tValidation Accuracy 56.032%\n",
      "Epoch: 1113 \tTraining Loss: 0.00671917 \tValidation Loss 0.00727322 \tTraining Accuracy 55.457% \tValidation Accuracy 56.032%\n",
      "Epoch: 1114 \tTraining Loss: 0.00671655 \tValidation Loss 0.00725401 \tTraining Accuracy 55.555% \tValidation Accuracy 56.384%\n",
      "Epoch: 1115 \tTraining Loss: 0.00672326 \tValidation Loss 0.00730837 \tTraining Accuracy 55.437% \tValidation Accuracy 54.485%\n",
      "Epoch: 1116 \tTraining Loss: 0.00670547 \tValidation Loss 0.00736467 \tTraining Accuracy 55.942% \tValidation Accuracy 55.540%\n",
      "Epoch: 1117 \tTraining Loss: 0.00670944 \tValidation Loss 0.00725023 \tTraining Accuracy 55.669% \tValidation Accuracy 56.349%\n",
      "Epoch: 1118 \tTraining Loss: 0.00670778 \tValidation Loss 0.00730421 \tTraining Accuracy 55.936% \tValidation Accuracy 55.259%\n",
      "Epoch: 1119 \tTraining Loss: 0.00672414 \tValidation Loss 0.00723904 \tTraining Accuracy 55.343% \tValidation Accuracy 55.786%\n",
      "Epoch: 1120 \tTraining Loss: 0.00671487 \tValidation Loss 0.00724259 \tTraining Accuracy 55.545% \tValidation Accuracy 56.454%\n",
      "Epoch: 1121 \tTraining Loss: 0.00672474 \tValidation Loss 0.00724118 \tTraining Accuracy 55.383% \tValidation Accuracy 56.701%\n",
      "Epoch: 1122 \tTraining Loss: 0.00671066 \tValidation Loss 0.00728421 \tTraining Accuracy 55.747% \tValidation Accuracy 55.364%\n",
      "Epoch: 1123 \tTraining Loss: 0.00671939 \tValidation Loss 0.00725965 \tTraining Accuracy 55.383% \tValidation Accuracy 54.625%\n",
      "Epoch: 1124 \tTraining Loss: 0.00671805 \tValidation Loss 0.00728079 \tTraining Accuracy 55.578% \tValidation Accuracy 55.997%\n",
      "Epoch: 1125 \tTraining Loss: 0.00671559 \tValidation Loss 0.00724523 \tTraining Accuracy 55.575% \tValidation Accuracy 56.454%\n",
      "Epoch: 1126 \tTraining Loss: 0.00671990 \tValidation Loss 0.00727707 \tTraining Accuracy 55.312% \tValidation Accuracy 56.419%\n",
      "Epoch: 1127 \tTraining Loss: 0.00670439 \tValidation Loss 0.00732985 \tTraining Accuracy 55.899% \tValidation Accuracy 55.153%\n",
      "Epoch: 1128 \tTraining Loss: 0.00671558 \tValidation Loss 0.00730473 \tTraining Accuracy 55.484% \tValidation Accuracy 54.836%\n",
      "Epoch: 1129 \tTraining Loss: 0.00671005 \tValidation Loss 0.00727265 \tTraining Accuracy 55.723% \tValidation Accuracy 56.103%\n",
      "Epoch: 1130 \tTraining Loss: 0.00672046 \tValidation Loss 0.00732019 \tTraining Accuracy 55.531% \tValidation Accuracy 54.907%\n",
      "Epoch: 1131 \tTraining Loss: 0.00671472 \tValidation Loss 0.00726568 \tTraining Accuracy 55.585% \tValidation Accuracy 55.821%\n",
      "Epoch: 1132 \tTraining Loss: 0.00671013 \tValidation Loss 0.00725111 \tTraining Accuracy 55.710% \tValidation Accuracy 55.083%\n",
      "Epoch: 1133 \tTraining Loss: 0.00671527 \tValidation Loss 0.00726785 \tTraining Accuracy 55.514% \tValidation Accuracy 55.364%\n",
      "Epoch: 1134 \tTraining Loss: 0.00671480 \tValidation Loss 0.00727701 \tTraining Accuracy 55.646% \tValidation Accuracy 56.279%\n",
      "Epoch: 1135 \tTraining Loss: 0.00671629 \tValidation Loss 0.00731236 \tTraining Accuracy 55.407% \tValidation Accuracy 54.625%\n",
      "Epoch: 1136 \tTraining Loss: 0.00671559 \tValidation Loss 0.00727362 \tTraining Accuracy 55.484% \tValidation Accuracy 56.103%\n",
      "Epoch: 1137 \tTraining Loss: 0.00671537 \tValidation Loss 0.00728484 \tTraining Accuracy 55.551% \tValidation Accuracy 55.927%\n",
      "Epoch: 1138 \tTraining Loss: 0.00671232 \tValidation Loss 0.00728288 \tTraining Accuracy 55.666% \tValidation Accuracy 55.610%\n",
      "Epoch: 1139 \tTraining Loss: 0.00670653 \tValidation Loss 0.00722358 \tTraining Accuracy 55.808% \tValidation Accuracy 56.701%\n",
      "Epoch: 1140 \tTraining Loss: 0.00671086 \tValidation Loss 0.00726408 \tTraining Accuracy 55.747% \tValidation Accuracy 55.540%\n",
      "Epoch: 1141 \tTraining Loss: 0.00670511 \tValidation Loss 0.00726372 \tTraining Accuracy 55.865% \tValidation Accuracy 56.103%\n",
      "Epoch: 1142 \tTraining Loss: 0.00670925 \tValidation Loss 0.00728949 \tTraining Accuracy 55.710% \tValidation Accuracy 55.470%\n",
      "Epoch: 1143 \tTraining Loss: 0.00670744 \tValidation Loss 0.00725885 \tTraining Accuracy 55.686% \tValidation Accuracy 56.173%\n",
      "Epoch: 1144 \tTraining Loss: 0.00670986 \tValidation Loss 0.00727933 \tTraining Accuracy 55.774% \tValidation Accuracy 55.399%\n",
      "Epoch: 1145 \tTraining Loss: 0.00671252 \tValidation Loss 0.00730450 \tTraining Accuracy 55.693% \tValidation Accuracy 55.856%\n",
      "Epoch: 1146 \tTraining Loss: 0.00670199 \tValidation Loss 0.00731486 \tTraining Accuracy 56.006% \tValidation Accuracy 55.610%\n",
      "Epoch: 1147 \tTraining Loss: 0.00670656 \tValidation Loss 0.00729361 \tTraining Accuracy 55.851% \tValidation Accuracy 55.575%\n",
      "Epoch: 1148 \tTraining Loss: 0.00670600 \tValidation Loss 0.00725976 \tTraining Accuracy 55.747% \tValidation Accuracy 55.681%\n",
      "Epoch: 1149 \tTraining Loss: 0.00671211 \tValidation Loss 0.00728283 \tTraining Accuracy 55.551% \tValidation Accuracy 55.399%\n",
      "Epoch: 1150 \tTraining Loss: 0.00670090 \tValidation Loss 0.00731781 \tTraining Accuracy 56.067% \tValidation Accuracy 55.610%\n",
      "Epoch: 1151 \tTraining Loss: 0.00671217 \tValidation Loss 0.00733731 \tTraining Accuracy 55.845% \tValidation Accuracy 55.083%\n",
      "Epoch: 1152 \tTraining Loss: 0.00670094 \tValidation Loss 0.00731007 \tTraining Accuracy 55.865% \tValidation Accuracy 55.364%\n",
      "Epoch: 1153 \tTraining Loss: 0.00670796 \tValidation Loss 0.00725333 \tTraining Accuracy 55.791% \tValidation Accuracy 55.962%\n",
      "Epoch: 1154 \tTraining Loss: 0.00669909 \tValidation Loss 0.00728079 \tTraining Accuracy 55.969% \tValidation Accuracy 55.540%\n",
      "Epoch: 1155 \tTraining Loss: 0.00670751 \tValidation Loss 0.00731756 \tTraining Accuracy 55.774% \tValidation Accuracy 55.399%\n",
      "Epoch: 1156 \tTraining Loss: 0.00669678 \tValidation Loss 0.00725036 \tTraining Accuracy 56.118% \tValidation Accuracy 56.349%\n",
      "Epoch: 1157 \tTraining Loss: 0.00670593 \tValidation Loss 0.00726024 \tTraining Accuracy 55.858% \tValidation Accuracy 55.364%\n",
      "Epoch: 1158 \tTraining Loss: 0.00670315 \tValidation Loss 0.00726180 \tTraining Accuracy 55.878% \tValidation Accuracy 56.243%\n",
      "Epoch: 1159 \tTraining Loss: 0.00669855 \tValidation Loss 0.00728457 \tTraining Accuracy 56.050% \tValidation Accuracy 56.630%\n",
      "Epoch: 1160 \tTraining Loss: 0.00670884 \tValidation Loss 0.00725407 \tTraining Accuracy 55.666% \tValidation Accuracy 56.982%\n",
      "Epoch: 1161 \tTraining Loss: 0.00670817 \tValidation Loss 0.00726211 \tTraining Accuracy 55.784% \tValidation Accuracy 56.525%\n",
      "Epoch: 1162 \tTraining Loss: 0.00670118 \tValidation Loss 0.00728359 \tTraining Accuracy 55.976% \tValidation Accuracy 55.645%\n",
      "Epoch: 1163 \tTraining Loss: 0.00670720 \tValidation Loss 0.00722990 \tTraining Accuracy 55.666% \tValidation Accuracy 56.877%\n",
      "Epoch: 1164 \tTraining Loss: 0.00670338 \tValidation Loss 0.00729557 \tTraining Accuracy 55.821% \tValidation Accuracy 55.610%\n",
      "Epoch: 1165 \tTraining Loss: 0.00670986 \tValidation Loss 0.00731310 \tTraining Accuracy 55.656% \tValidation Accuracy 56.103%\n",
      "Epoch: 1166 \tTraining Loss: 0.00669245 \tValidation Loss 0.00726206 \tTraining Accuracy 56.192% \tValidation Accuracy 56.806%\n",
      "Epoch: 1167 \tTraining Loss: 0.00670405 \tValidation Loss 0.00724536 \tTraining Accuracy 55.979% \tValidation Accuracy 56.490%\n",
      "Epoch: 1168 \tTraining Loss: 0.00670622 \tValidation Loss 0.00722990 \tTraining Accuracy 55.811% \tValidation Accuracy 56.454%\n",
      "Epoch: 1169 \tTraining Loss: 0.00670898 \tValidation Loss 0.00725151 \tTraining Accuracy 55.653% \tValidation Accuracy 56.384%\n",
      "Epoch: 1170 \tTraining Loss: 0.00670321 \tValidation Loss 0.00724281 \tTraining Accuracy 55.821% \tValidation Accuracy 56.068%\n",
      "Epoch: 1171 \tTraining Loss: 0.00670263 \tValidation Loss 0.00727671 \tTraining Accuracy 56.023% \tValidation Accuracy 56.243%\n",
      "Epoch: 1172 \tTraining Loss: 0.00669670 \tValidation Loss 0.00725605 \tTraining Accuracy 56.138% \tValidation Accuracy 56.419%\n",
      "Epoch: 1173 \tTraining Loss: 0.00669829 \tValidation Loss 0.00726769 \tTraining Accuracy 56.091% \tValidation Accuracy 55.892%\n",
      "Epoch: 1174 \tTraining Loss: 0.00670186 \tValidation Loss 0.00728660 \tTraining Accuracy 55.892% \tValidation Accuracy 55.505%\n",
      "Epoch: 1175 \tTraining Loss: 0.00670184 \tValidation Loss 0.00729361 \tTraining Accuracy 55.915% \tValidation Accuracy 55.470%\n",
      "Epoch: 1176 \tTraining Loss: 0.00669108 \tValidation Loss 0.00723870 \tTraining Accuracy 56.286% \tValidation Accuracy 56.173%\n",
      "Epoch: 1177 \tTraining Loss: 0.00670524 \tValidation Loss 0.00724863 \tTraining Accuracy 55.784% \tValidation Accuracy 56.103%\n",
      "Epoch: 1178 \tTraining Loss: 0.00670361 \tValidation Loss 0.00727081 \tTraining Accuracy 55.996% \tValidation Accuracy 55.329%\n",
      "Epoch: 1179 \tTraining Loss: 0.00669888 \tValidation Loss 0.00722616 \tTraining Accuracy 56.003% \tValidation Accuracy 56.384%\n",
      "Epoch: 1180 \tTraining Loss: 0.00669987 \tValidation Loss 0.00725527 \tTraining Accuracy 56.027% \tValidation Accuracy 56.032%\n",
      "Epoch: 1181 \tTraining Loss: 0.00670330 \tValidation Loss 0.00721649 \tTraining Accuracy 55.861% \tValidation Accuracy 56.912%\n",
      "Epoch: 1182 \tTraining Loss: 0.00669903 \tValidation Loss 0.00723850 \tTraining Accuracy 55.976% \tValidation Accuracy 55.962%\n",
      "Epoch: 1183 \tTraining Loss: 0.00669584 \tValidation Loss 0.00727375 \tTraining Accuracy 56.185% \tValidation Accuracy 56.314%\n",
      "Epoch: 1184 \tTraining Loss: 0.00670388 \tValidation Loss 0.00725380 \tTraining Accuracy 55.791% \tValidation Accuracy 55.786%\n",
      "Epoch: 1185 \tTraining Loss: 0.00669452 \tValidation Loss 0.00726994 \tTraining Accuracy 56.266% \tValidation Accuracy 55.962%\n",
      "Epoch: 1186 \tTraining Loss: 0.00670136 \tValidation Loss 0.00726508 \tTraining Accuracy 56.003% \tValidation Accuracy 55.997%\n",
      "Epoch: 1187 \tTraining Loss: 0.00669426 \tValidation Loss 0.00724230 \tTraining Accuracy 56.094% \tValidation Accuracy 56.595%\n",
      "Epoch: 1188 \tTraining Loss: 0.00669590 \tValidation Loss 0.00725522 \tTraining Accuracy 55.976% \tValidation Accuracy 56.349%\n",
      "Epoch: 1189 \tTraining Loss: 0.00669599 \tValidation Loss 0.00725573 \tTraining Accuracy 56.037% \tValidation Accuracy 55.645%\n",
      "Epoch: 1190 \tTraining Loss: 0.00669235 \tValidation Loss 0.00728314 \tTraining Accuracy 56.209% \tValidation Accuracy 55.364%\n",
      "Epoch: 1191 \tTraining Loss: 0.00669464 \tValidation Loss 0.00727852 \tTraining Accuracy 56.232% \tValidation Accuracy 55.962%\n",
      "Epoch: 1192 \tTraining Loss: 0.00668574 \tValidation Loss 0.00730050 \tTraining Accuracy 56.471% \tValidation Accuracy 55.962%\n",
      "Epoch: 1193 \tTraining Loss: 0.00669243 \tValidation Loss 0.00724062 \tTraining Accuracy 56.148% \tValidation Accuracy 56.243%\n",
      "Epoch: 1194 \tTraining Loss: 0.00668639 \tValidation Loss 0.00735741 \tTraining Accuracy 56.256% \tValidation Accuracy 54.766%\n",
      "Epoch: 1195 \tTraining Loss: 0.00669085 \tValidation Loss 0.00725036 \tTraining Accuracy 56.303% \tValidation Accuracy 55.153%\n",
      "Epoch: 1196 \tTraining Loss: 0.00669076 \tValidation Loss 0.00725226 \tTraining Accuracy 56.266% \tValidation Accuracy 53.289%\n",
      "Epoch: 1197 \tTraining Loss: 0.00670100 \tValidation Loss 0.00729053 \tTraining Accuracy 55.828% \tValidation Accuracy 55.821%\n",
      "Epoch: 1198 \tTraining Loss: 0.00668394 \tValidation Loss 0.00727159 \tTraining Accuracy 56.424% \tValidation Accuracy 56.384%\n",
      "Epoch: 1199 \tTraining Loss: 0.00669233 \tValidation Loss 0.00722835 \tTraining Accuracy 56.185% \tValidation Accuracy 55.962%\n",
      "Epoch: 1200 \tTraining Loss: 0.00669191 \tValidation Loss 0.00724817 \tTraining Accuracy 56.310% \tValidation Accuracy 55.364%\n",
      "Epoch: 1201 \tTraining Loss: 0.00668921 \tValidation Loss 0.00721279 \tTraining Accuracy 56.279% \tValidation Accuracy 56.947%\n",
      "Epoch: 1202 \tTraining Loss: 0.00667944 \tValidation Loss 0.00727131 \tTraining Accuracy 56.630% \tValidation Accuracy 56.173%\n",
      "Epoch: 1203 \tTraining Loss: 0.00669208 \tValidation Loss 0.00727085 \tTraining Accuracy 56.262% \tValidation Accuracy 55.927%\n",
      "Epoch: 1204 \tTraining Loss: 0.00669367 \tValidation Loss 0.00725344 \tTraining Accuracy 56.151% \tValidation Accuracy 57.334%\n",
      "Epoch: 1205 \tTraining Loss: 0.00668814 \tValidation Loss 0.00725042 \tTraining Accuracy 56.259% \tValidation Accuracy 55.434%\n",
      "Epoch: 1206 \tTraining Loss: 0.00668806 \tValidation Loss 0.00719584 \tTraining Accuracy 56.434% \tValidation Accuracy 57.263%\n",
      "Epoch: 1207 \tTraining Loss: 0.00669063 \tValidation Loss 0.00720407 \tTraining Accuracy 56.222% \tValidation Accuracy 55.997%\n",
      "Epoch: 1208 \tTraining Loss: 0.00669711 \tValidation Loss 0.00723032 \tTraining Accuracy 56.161% \tValidation Accuracy 56.068%\n",
      "Epoch: 1209 \tTraining Loss: 0.00668391 \tValidation Loss 0.00729296 \tTraining Accuracy 56.367% \tValidation Accuracy 55.786%\n",
      "Epoch: 1210 \tTraining Loss: 0.00669244 \tValidation Loss 0.00727636 \tTraining Accuracy 56.107% \tValidation Accuracy 56.208%\n",
      "Epoch: 1211 \tTraining Loss: 0.00668969 \tValidation Loss 0.00726672 \tTraining Accuracy 56.232% \tValidation Accuracy 55.786%\n",
      "Epoch: 1212 \tTraining Loss: 0.00669674 \tValidation Loss 0.00723052 \tTraining Accuracy 56.000% \tValidation Accuracy 56.771%\n",
      "Epoch: 1213 \tTraining Loss: 0.00668886 \tValidation Loss 0.00728697 \tTraining Accuracy 56.289% \tValidation Accuracy 55.786%\n",
      "Epoch: 1214 \tTraining Loss: 0.00668221 \tValidation Loss 0.00719931 \tTraining Accuracy 56.394% \tValidation Accuracy 55.927%\n",
      "Epoch: 1215 \tTraining Loss: 0.00669406 \tValidation Loss 0.00726076 \tTraining Accuracy 56.144% \tValidation Accuracy 56.173%\n",
      "Epoch: 1216 \tTraining Loss: 0.00669049 \tValidation Loss 0.00721383 \tTraining Accuracy 56.185% \tValidation Accuracy 57.158%\n",
      "Epoch: 1217 \tTraining Loss: 0.00668916 \tValidation Loss 0.00718799 \tTraining Accuracy 56.266% \tValidation Accuracy 57.510%\n",
      "Epoch: 1218 \tTraining Loss: 0.00668147 \tValidation Loss 0.00723946 \tTraining Accuracy 56.299% \tValidation Accuracy 56.419%\n",
      "Epoch: 1219 \tTraining Loss: 0.00668949 \tValidation Loss 0.00730095 \tTraining Accuracy 56.192% \tValidation Accuracy 56.736%\n",
      "Epoch: 1220 \tTraining Loss: 0.00668857 \tValidation Loss 0.00732071 \tTraining Accuracy 56.326% \tValidation Accuracy 55.610%\n",
      "Epoch: 1221 \tTraining Loss: 0.00667872 \tValidation Loss 0.00723091 \tTraining Accuracy 56.633% \tValidation Accuracy 56.947%\n",
      "Epoch: 1222 \tTraining Loss: 0.00669645 \tValidation Loss 0.00728211 \tTraining Accuracy 56.023% \tValidation Accuracy 55.716%\n",
      "Epoch: 1223 \tTraining Loss: 0.00668546 \tValidation Loss 0.00721681 \tTraining Accuracy 56.384% \tValidation Accuracy 57.299%\n",
      "Epoch: 1224 \tTraining Loss: 0.00668197 \tValidation Loss 0.00728119 \tTraining Accuracy 56.424% \tValidation Accuracy 56.279%\n",
      "Epoch: 1225 \tTraining Loss: 0.00668467 \tValidation Loss 0.00721493 \tTraining Accuracy 56.458% \tValidation Accuracy 56.208%\n",
      "Epoch: 1226 \tTraining Loss: 0.00668906 \tValidation Loss 0.00724031 \tTraining Accuracy 56.242% \tValidation Accuracy 55.997%\n",
      "Epoch: 1227 \tTraining Loss: 0.00668414 \tValidation Loss 0.00722230 \tTraining Accuracy 56.350% \tValidation Accuracy 56.243%\n",
      "Epoch: 1228 \tTraining Loss: 0.00667739 \tValidation Loss 0.00725809 \tTraining Accuracy 56.552% \tValidation Accuracy 56.103%\n",
      "Epoch: 1229 \tTraining Loss: 0.00668853 \tValidation Loss 0.00729198 \tTraining Accuracy 56.229% \tValidation Accuracy 56.630%\n",
      "Epoch: 1230 \tTraining Loss: 0.00667593 \tValidation Loss 0.00725773 \tTraining Accuracy 56.690% \tValidation Accuracy 56.243%\n",
      "Epoch: 1231 \tTraining Loss: 0.00668193 \tValidation Loss 0.00724234 \tTraining Accuracy 56.461% \tValidation Accuracy 55.962%\n",
      "Epoch: 1232 \tTraining Loss: 0.00667526 \tValidation Loss 0.00725688 \tTraining Accuracy 56.508% \tValidation Accuracy 55.223%\n",
      "Epoch: 1233 \tTraining Loss: 0.00668327 \tValidation Loss 0.00723425 \tTraining Accuracy 56.576% \tValidation Accuracy 56.103%\n",
      "Epoch: 1234 \tTraining Loss: 0.00668011 \tValidation Loss 0.00726124 \tTraining Accuracy 56.529% \tValidation Accuracy 56.630%\n",
      "Epoch: 1235 \tTraining Loss: 0.00668433 \tValidation Loss 0.00726043 \tTraining Accuracy 56.475% \tValidation Accuracy 56.384%\n",
      "Epoch: 1236 \tTraining Loss: 0.00668015 \tValidation Loss 0.00727119 \tTraining Accuracy 56.475% \tValidation Accuracy 55.751%\n",
      "Epoch: 1237 \tTraining Loss: 0.00668364 \tValidation Loss 0.00723462 \tTraining Accuracy 56.326% \tValidation Accuracy 56.701%\n",
      "Epoch: 1238 \tTraining Loss: 0.00668000 \tValidation Loss 0.00729056 \tTraining Accuracy 56.434% \tValidation Accuracy 55.786%\n",
      "Epoch: 1239 \tTraining Loss: 0.00667858 \tValidation Loss 0.00723296 \tTraining Accuracy 56.593% \tValidation Accuracy 56.771%\n",
      "Epoch: 1240 \tTraining Loss: 0.00667811 \tValidation Loss 0.00726033 \tTraining Accuracy 56.532% \tValidation Accuracy 55.505%\n",
      "Epoch: 1241 \tTraining Loss: 0.00668035 \tValidation Loss 0.00718536 \tTraining Accuracy 56.475% \tValidation Accuracy 57.123%\n",
      "Epoch: 1242 \tTraining Loss: 0.00667175 \tValidation Loss 0.00726326 \tTraining Accuracy 56.822% \tValidation Accuracy 56.736%\n",
      "Epoch: 1243 \tTraining Loss: 0.00667209 \tValidation Loss 0.00717065 \tTraining Accuracy 56.778% \tValidation Accuracy 56.560%\n",
      "Epoch: 1244 \tTraining Loss: 0.00668259 \tValidation Loss 0.00729512 \tTraining Accuracy 56.330% \tValidation Accuracy 55.751%\n",
      "Epoch: 1245 \tTraining Loss: 0.00667391 \tValidation Loss 0.00726173 \tTraining Accuracy 56.636% \tValidation Accuracy 55.821%\n",
      "Epoch: 1246 \tTraining Loss: 0.00667080 \tValidation Loss 0.00724285 \tTraining Accuracy 56.761% \tValidation Accuracy 55.997%\n",
      "Epoch: 1247 \tTraining Loss: 0.00667859 \tValidation Loss 0.00720816 \tTraining Accuracy 56.411% \tValidation Accuracy 55.786%\n",
      "Epoch: 1248 \tTraining Loss: 0.00667793 \tValidation Loss 0.00728121 \tTraining Accuracy 56.515% \tValidation Accuracy 56.982%\n",
      "Epoch: 1249 \tTraining Loss: 0.00667910 \tValidation Loss 0.00720942 \tTraining Accuracy 56.512% \tValidation Accuracy 56.877%\n",
      "Epoch: 1250 \tTraining Loss: 0.00667155 \tValidation Loss 0.00729524 \tTraining Accuracy 56.852% \tValidation Accuracy 55.962%\n",
      "Epoch: 1251 \tTraining Loss: 0.00667324 \tValidation Loss 0.00720992 \tTraining Accuracy 56.727% \tValidation Accuracy 56.912%\n",
      "Epoch: 1252 \tTraining Loss: 0.00667157 \tValidation Loss 0.00723924 \tTraining Accuracy 56.721% \tValidation Accuracy 55.892%\n",
      "Epoch: 1253 \tTraining Loss: 0.00667562 \tValidation Loss 0.00728314 \tTraining Accuracy 56.707% \tValidation Accuracy 55.716%\n",
      "Epoch: 1254 \tTraining Loss: 0.00666892 \tValidation Loss 0.00722526 \tTraining Accuracy 56.859% \tValidation Accuracy 56.068%\n",
      "Epoch: 1255 \tTraining Loss: 0.00666628 \tValidation Loss 0.00724677 \tTraining Accuracy 56.896% \tValidation Accuracy 56.701%\n",
      "Epoch: 1256 \tTraining Loss: 0.00667334 \tValidation Loss 0.00723347 \tTraining Accuracy 56.754% \tValidation Accuracy 56.947%\n",
      "Epoch: 1257 \tTraining Loss: 0.00667206 \tValidation Loss 0.00725532 \tTraining Accuracy 56.771% \tValidation Accuracy 56.771%\n",
      "Epoch: 1258 \tTraining Loss: 0.00667186 \tValidation Loss 0.00725853 \tTraining Accuracy 56.731% \tValidation Accuracy 55.856%\n",
      "Epoch: 1259 \tTraining Loss: 0.00667393 \tValidation Loss 0.00731923 \tTraining Accuracy 56.670% \tValidation Accuracy 55.399%\n",
      "Epoch: 1260 \tTraining Loss: 0.00667491 \tValidation Loss 0.00722063 \tTraining Accuracy 56.596% \tValidation Accuracy 57.123%\n",
      "Epoch: 1261 \tTraining Loss: 0.00667603 \tValidation Loss 0.00723953 \tTraining Accuracy 56.623% \tValidation Accuracy 56.419%\n",
      "Epoch: 1262 \tTraining Loss: 0.00666824 \tValidation Loss 0.00727821 \tTraining Accuracy 56.933% \tValidation Accuracy 57.404%\n",
      "Epoch: 1263 \tTraining Loss: 0.00667447 \tValidation Loss 0.00729332 \tTraining Accuracy 56.512% \tValidation Accuracy 56.314%\n",
      "Epoch: 1264 \tTraining Loss: 0.00667661 \tValidation Loss 0.00720208 \tTraining Accuracy 56.593% \tValidation Accuracy 57.088%\n",
      "Epoch: 1265 \tTraining Loss: 0.00666883 \tValidation Loss 0.00729162 \tTraining Accuracy 56.893% \tValidation Accuracy 56.173%\n",
      "Epoch: 1266 \tTraining Loss: 0.00666772 \tValidation Loss 0.00723899 \tTraining Accuracy 56.795% \tValidation Accuracy 56.103%\n",
      "Epoch: 1267 \tTraining Loss: 0.00667132 \tValidation Loss 0.00722681 \tTraining Accuracy 56.812% \tValidation Accuracy 56.103%\n",
      "Epoch: 1268 \tTraining Loss: 0.00667413 \tValidation Loss 0.00722212 \tTraining Accuracy 56.727% \tValidation Accuracy 56.877%\n",
      "Epoch: 1269 \tTraining Loss: 0.00667417 \tValidation Loss 0.00723478 \tTraining Accuracy 56.751% \tValidation Accuracy 56.279%\n",
      "Epoch: 1270 \tTraining Loss: 0.00667228 \tValidation Loss 0.00720373 \tTraining Accuracy 56.687% \tValidation Accuracy 56.419%\n",
      "Epoch: 1271 \tTraining Loss: 0.00667185 \tValidation Loss 0.00724147 \tTraining Accuracy 56.825% \tValidation Accuracy 55.645%\n",
      "Epoch: 1272 \tTraining Loss: 0.00666841 \tValidation Loss 0.00726610 \tTraining Accuracy 56.869% \tValidation Accuracy 56.771%\n",
      "Epoch: 1273 \tTraining Loss: 0.00668481 \tValidation Loss 0.00723530 \tTraining Accuracy 56.424% \tValidation Accuracy 56.208%\n",
      "Epoch: 1274 \tTraining Loss: 0.00667052 \tValidation Loss 0.00726747 \tTraining Accuracy 56.781% \tValidation Accuracy 55.962%\n",
      "Epoch: 1275 \tTraining Loss: 0.00666730 \tValidation Loss 0.00720031 \tTraining Accuracy 56.812% \tValidation Accuracy 57.158%\n",
      "Epoch: 1276 \tTraining Loss: 0.00667145 \tValidation Loss 0.00727676 \tTraining Accuracy 56.616% \tValidation Accuracy 55.892%\n",
      "Epoch: 1277 \tTraining Loss: 0.00667451 \tValidation Loss 0.00721812 \tTraining Accuracy 56.542% \tValidation Accuracy 57.123%\n",
      "Epoch: 1278 \tTraining Loss: 0.00666555 \tValidation Loss 0.00724324 \tTraining Accuracy 56.741% \tValidation Accuracy 56.841%\n",
      "Epoch: 1279 \tTraining Loss: 0.00667679 \tValidation Loss 0.00721635 \tTraining Accuracy 56.620% \tValidation Accuracy 56.419%\n",
      "Epoch: 1280 \tTraining Loss: 0.00666989 \tValidation Loss 0.00720084 \tTraining Accuracy 56.761% \tValidation Accuracy 56.947%\n",
      "Epoch: 1281 \tTraining Loss: 0.00666671 \tValidation Loss 0.00725008 \tTraining Accuracy 56.855% \tValidation Accuracy 56.736%\n",
      "Epoch: 1282 \tTraining Loss: 0.00666270 \tValidation Loss 0.00722283 \tTraining Accuracy 56.967% \tValidation Accuracy 57.193%\n",
      "Epoch: 1283 \tTraining Loss: 0.00666676 \tValidation Loss 0.00725796 \tTraining Accuracy 56.913% \tValidation Accuracy 56.560%\n",
      "Epoch: 1284 \tTraining Loss: 0.00667179 \tValidation Loss 0.00721501 \tTraining Accuracy 56.663% \tValidation Accuracy 56.877%\n",
      "Epoch: 1285 \tTraining Loss: 0.00666889 \tValidation Loss 0.00723005 \tTraining Accuracy 56.788% \tValidation Accuracy 57.299%\n",
      "Epoch: 1286 \tTraining Loss: 0.00666001 \tValidation Loss 0.00716944 \tTraining Accuracy 56.940% \tValidation Accuracy 56.806%\n",
      "Epoch: 1287 \tTraining Loss: 0.00667124 \tValidation Loss 0.00720157 \tTraining Accuracy 56.727% \tValidation Accuracy 56.877%\n",
      "Epoch: 1288 \tTraining Loss: 0.00666048 \tValidation Loss 0.00722297 \tTraining Accuracy 57.048% \tValidation Accuracy 57.052%\n",
      "Epoch: 1289 \tTraining Loss: 0.00667195 \tValidation Loss 0.00723213 \tTraining Accuracy 56.660% \tValidation Accuracy 57.439%\n",
      "Epoch: 1290 \tTraining Loss: 0.00666945 \tValidation Loss 0.00722189 \tTraining Accuracy 56.677% \tValidation Accuracy 56.595%\n",
      "Epoch: 1291 \tTraining Loss: 0.00666126 \tValidation Loss 0.00726694 \tTraining Accuracy 57.004% \tValidation Accuracy 57.545%\n",
      "Epoch: 1292 \tTraining Loss: 0.00666551 \tValidation Loss 0.00722876 \tTraining Accuracy 56.889% \tValidation Accuracy 56.314%\n",
      "Epoch: 1293 \tTraining Loss: 0.00666236 \tValidation Loss 0.00718753 \tTraining Accuracy 57.071% \tValidation Accuracy 57.615%\n",
      "Epoch: 1294 \tTraining Loss: 0.00666071 \tValidation Loss 0.00720224 \tTraining Accuracy 57.014% \tValidation Accuracy 57.650%\n",
      "Epoch: 1295 \tTraining Loss: 0.00666616 \tValidation Loss 0.00716449 \tTraining Accuracy 56.829% \tValidation Accuracy 57.967%\n",
      "Epoch: 1296 \tTraining Loss: 0.00666309 \tValidation Loss 0.00723902 \tTraining Accuracy 56.943% \tValidation Accuracy 56.806%\n",
      "Epoch: 1297 \tTraining Loss: 0.00666045 \tValidation Loss 0.00721940 \tTraining Accuracy 56.960% \tValidation Accuracy 56.630%\n",
      "Epoch: 1298 \tTraining Loss: 0.00666433 \tValidation Loss 0.00727353 \tTraining Accuracy 56.953% \tValidation Accuracy 56.349%\n",
      "Epoch: 1299 \tTraining Loss: 0.00665938 \tValidation Loss 0.00721152 \tTraining Accuracy 57.142% \tValidation Accuracy 57.580%\n",
      "Epoch: 1300 \tTraining Loss: 0.00666556 \tValidation Loss 0.00720232 \tTraining Accuracy 56.798% \tValidation Accuracy 57.228%\n",
      "Epoch: 1301 \tTraining Loss: 0.00665938 \tValidation Loss 0.00721468 \tTraining Accuracy 56.957% \tValidation Accuracy 56.806%\n",
      "Epoch: 1302 \tTraining Loss: 0.00666473 \tValidation Loss 0.00727251 \tTraining Accuracy 56.943% \tValidation Accuracy 56.877%\n",
      "Epoch: 1303 \tTraining Loss: 0.00667216 \tValidation Loss 0.00717693 \tTraining Accuracy 56.599% \tValidation Accuracy 56.384%\n",
      "Epoch: 1304 \tTraining Loss: 0.00666224 \tValidation Loss 0.00718893 \tTraining Accuracy 56.936% \tValidation Accuracy 56.806%\n",
      "Epoch: 1305 \tTraining Loss: 0.00666329 \tValidation Loss 0.00726283 \tTraining Accuracy 56.899% \tValidation Accuracy 56.208%\n",
      "Epoch: 1306 \tTraining Loss: 0.00666865 \tValidation Loss 0.00716989 \tTraining Accuracy 56.748% \tValidation Accuracy 56.912%\n",
      "Epoch: 1307 \tTraining Loss: 0.00666697 \tValidation Loss 0.00730370 \tTraining Accuracy 56.889% \tValidation Accuracy 56.068%\n",
      "Epoch: 1308 \tTraining Loss: 0.00666756 \tValidation Loss 0.00719898 \tTraining Accuracy 56.771% \tValidation Accuracy 57.158%\n",
      "Epoch: 1309 \tTraining Loss: 0.00665707 \tValidation Loss 0.00719118 \tTraining Accuracy 57.041% \tValidation Accuracy 56.701%\n",
      "Epoch: 1310 \tTraining Loss: 0.00665226 \tValidation Loss 0.00725091 \tTraining Accuracy 57.243% \tValidation Accuracy 56.806%\n",
      "Epoch: 1311 \tTraining Loss: 0.00666608 \tValidation Loss 0.00725900 \tTraining Accuracy 56.829% \tValidation Accuracy 56.384%\n",
      "Epoch: 1312 \tTraining Loss: 0.00666768 \tValidation Loss 0.00726512 \tTraining Accuracy 56.775% \tValidation Accuracy 57.193%\n",
      "Epoch: 1313 \tTraining Loss: 0.00666541 \tValidation Loss 0.00725319 \tTraining Accuracy 56.805% \tValidation Accuracy 56.349%\n",
      "Epoch: 1314 \tTraining Loss: 0.00665715 \tValidation Loss 0.00717675 \tTraining Accuracy 57.007% \tValidation Accuracy 57.861%\n",
      "Epoch: 1315 \tTraining Loss: 0.00666141 \tValidation Loss 0.00720316 \tTraining Accuracy 56.893% \tValidation Accuracy 58.037%\n",
      "Epoch: 1316 \tTraining Loss: 0.00665692 \tValidation Loss 0.00723684 \tTraining Accuracy 57.142% \tValidation Accuracy 57.158%\n",
      "Epoch: 1317 \tTraining Loss: 0.00665435 \tValidation Loss 0.00722208 \tTraining Accuracy 57.223% \tValidation Accuracy 56.454%\n",
      "Epoch: 1318 \tTraining Loss: 0.00665567 \tValidation Loss 0.00718924 \tTraining Accuracy 57.048% \tValidation Accuracy 57.123%\n",
      "Epoch: 1319 \tTraining Loss: 0.00665844 \tValidation Loss 0.00721407 \tTraining Accuracy 57.068% \tValidation Accuracy 56.736%\n",
      "Epoch: 1320 \tTraining Loss: 0.00665265 \tValidation Loss 0.00720262 \tTraining Accuracy 57.226% \tValidation Accuracy 56.243%\n",
      "Epoch: 1321 \tTraining Loss: 0.00665762 \tValidation Loss 0.00720713 \tTraining Accuracy 57.068% \tValidation Accuracy 56.947%\n",
      "Epoch: 1322 \tTraining Loss: 0.00665886 \tValidation Loss 0.00722659 \tTraining Accuracy 57.112% \tValidation Accuracy 55.786%\n",
      "Epoch: 1323 \tTraining Loss: 0.00665584 \tValidation Loss 0.00720487 \tTraining Accuracy 57.165% \tValidation Accuracy 57.052%\n",
      "Epoch: 1324 \tTraining Loss: 0.00666940 \tValidation Loss 0.00721752 \tTraining Accuracy 56.788% \tValidation Accuracy 56.560%\n",
      "Epoch: 1325 \tTraining Loss: 0.00665484 \tValidation Loss 0.00722882 \tTraining Accuracy 57.223% \tValidation Accuracy 56.525%\n",
      "Epoch: 1326 \tTraining Loss: 0.00665522 \tValidation Loss 0.00721738 \tTraining Accuracy 57.273% \tValidation Accuracy 56.665%\n",
      "Epoch: 1327 \tTraining Loss: 0.00665673 \tValidation Loss 0.00722590 \tTraining Accuracy 57.078% \tValidation Accuracy 57.263%\n",
      "Epoch: 1328 \tTraining Loss: 0.00666026 \tValidation Loss 0.00718498 \tTraining Accuracy 56.977% \tValidation Accuracy 58.354%\n",
      "Epoch: 1329 \tTraining Loss: 0.00665955 \tValidation Loss 0.00724710 \tTraining Accuracy 56.984% \tValidation Accuracy 57.123%\n",
      "Epoch: 1330 \tTraining Loss: 0.00665531 \tValidation Loss 0.00720068 \tTraining Accuracy 57.240% \tValidation Accuracy 56.384%\n",
      "Epoch: 1331 \tTraining Loss: 0.00665287 \tValidation Loss 0.00724821 \tTraining Accuracy 57.240% \tValidation Accuracy 56.243%\n",
      "Epoch: 1332 \tTraining Loss: 0.00666185 \tValidation Loss 0.00716982 \tTraining Accuracy 56.980% \tValidation Accuracy 56.912%\n",
      "Epoch: 1333 \tTraining Loss: 0.00665002 \tValidation Loss 0.00722233 \tTraining Accuracy 57.263% \tValidation Accuracy 56.806%\n",
      "Epoch: 1334 \tTraining Loss: 0.00665670 \tValidation Loss 0.00717544 \tTraining Accuracy 57.172% \tValidation Accuracy 57.228%\n",
      "Epoch: 1335 \tTraining Loss: 0.00666000 \tValidation Loss 0.00727414 \tTraining Accuracy 57.078% \tValidation Accuracy 55.645%\n",
      "Epoch: 1336 \tTraining Loss: 0.00665315 \tValidation Loss 0.00723818 \tTraining Accuracy 57.199% \tValidation Accuracy 56.419%\n",
      "Epoch: 1337 \tTraining Loss: 0.00665616 \tValidation Loss 0.00719921 \tTraining Accuracy 57.172% \tValidation Accuracy 57.545%\n",
      "Epoch: 1338 \tTraining Loss: 0.00665271 \tValidation Loss 0.00729720 \tTraining Accuracy 57.331% \tValidation Accuracy 56.032%\n",
      "Epoch: 1339 \tTraining Loss: 0.00665742 \tValidation Loss 0.00726391 \tTraining Accuracy 56.980% \tValidation Accuracy 56.243%\n",
      "Epoch: 1340 \tTraining Loss: 0.00664537 \tValidation Loss 0.00725259 \tTraining Accuracy 57.533% \tValidation Accuracy 56.138%\n",
      "Epoch: 1341 \tTraining Loss: 0.00664646 \tValidation Loss 0.00720388 \tTraining Accuracy 57.435% \tValidation Accuracy 57.686%\n",
      "Epoch: 1342 \tTraining Loss: 0.00665324 \tValidation Loss 0.00719781 \tTraining Accuracy 57.233% \tValidation Accuracy 56.595%\n",
      "Epoch: 1343 \tTraining Loss: 0.00665304 \tValidation Loss 0.00717242 \tTraining Accuracy 57.273% \tValidation Accuracy 56.912%\n",
      "Epoch: 1344 \tTraining Loss: 0.00665271 \tValidation Loss 0.00725776 \tTraining Accuracy 57.280% \tValidation Accuracy 56.630%\n",
      "Epoch: 1345 \tTraining Loss: 0.00665486 \tValidation Loss 0.00721684 \tTraining Accuracy 57.081% \tValidation Accuracy 56.912%\n",
      "Epoch: 1346 \tTraining Loss: 0.00665045 \tValidation Loss 0.00723996 \tTraining Accuracy 57.152% \tValidation Accuracy 56.419%\n",
      "Epoch: 1347 \tTraining Loss: 0.00664036 \tValidation Loss 0.00724733 \tTraining Accuracy 57.641% \tValidation Accuracy 57.228%\n",
      "Epoch: 1348 \tTraining Loss: 0.00665246 \tValidation Loss 0.00725020 \tTraining Accuracy 57.270% \tValidation Accuracy 56.490%\n",
      "Epoch: 1349 \tTraining Loss: 0.00666181 \tValidation Loss 0.00721816 \tTraining Accuracy 56.977% \tValidation Accuracy 56.771%\n",
      "Epoch: 1350 \tTraining Loss: 0.00665055 \tValidation Loss 0.00724330 \tTraining Accuracy 57.243% \tValidation Accuracy 57.088%\n",
      "Epoch: 1351 \tTraining Loss: 0.00664502 \tValidation Loss 0.00727440 \tTraining Accuracy 57.502% \tValidation Accuracy 56.982%\n",
      "Epoch: 1352 \tTraining Loss: 0.00664926 \tValidation Loss 0.00718450 \tTraining Accuracy 57.341% \tValidation Accuracy 57.193%\n",
      "Epoch: 1353 \tTraining Loss: 0.00664946 \tValidation Loss 0.00722684 \tTraining Accuracy 57.260% \tValidation Accuracy 56.877%\n",
      "Epoch: 1354 \tTraining Loss: 0.00664675 \tValidation Loss 0.00726368 \tTraining Accuracy 57.401% \tValidation Accuracy 56.103%\n",
      "Epoch: 1355 \tTraining Loss: 0.00664885 \tValidation Loss 0.00727411 \tTraining Accuracy 57.418% \tValidation Accuracy 56.454%\n",
      "Epoch: 1356 \tTraining Loss: 0.00663986 \tValidation Loss 0.00722750 \tTraining Accuracy 57.661% \tValidation Accuracy 56.841%\n",
      "Epoch: 1357 \tTraining Loss: 0.00666390 \tValidation Loss 0.00719074 \tTraining Accuracy 56.930% \tValidation Accuracy 56.454%\n",
      "Epoch: 1358 \tTraining Loss: 0.00664252 \tValidation Loss 0.00724234 \tTraining Accuracy 57.597% \tValidation Accuracy 56.877%\n",
      "Epoch: 1359 \tTraining Loss: 0.00664732 \tValidation Loss 0.00721265 \tTraining Accuracy 57.381% \tValidation Accuracy 56.419%\n",
      "Epoch: 1360 \tTraining Loss: 0.00664747 \tValidation Loss 0.00728417 \tTraining Accuracy 57.260% \tValidation Accuracy 56.208%\n",
      "Epoch: 1361 \tTraining Loss: 0.00664376 \tValidation Loss 0.00719685 \tTraining Accuracy 57.378% \tValidation Accuracy 57.897%\n",
      "Epoch: 1362 \tTraining Loss: 0.00664513 \tValidation Loss 0.00726546 \tTraining Accuracy 57.368% \tValidation Accuracy 57.158%\n",
      "Epoch: 1363 \tTraining Loss: 0.00664507 \tValidation Loss 0.00717581 \tTraining Accuracy 57.445% \tValidation Accuracy 57.967%\n",
      "Epoch: 1364 \tTraining Loss: 0.00665465 \tValidation Loss 0.00722778 \tTraining Accuracy 57.189% \tValidation Accuracy 56.947%\n",
      "Epoch: 1365 \tTraining Loss: 0.00664777 \tValidation Loss 0.00724397 \tTraining Accuracy 57.192% \tValidation Accuracy 56.982%\n",
      "Epoch: 1366 \tTraining Loss: 0.00663492 \tValidation Loss 0.00713613 \tTraining Accuracy 57.647% \tValidation Accuracy 56.947%\n",
      "Epoch: 1367 \tTraining Loss: 0.00663772 \tValidation Loss 0.00724820 \tTraining Accuracy 57.651% \tValidation Accuracy 56.032%\n",
      "Epoch: 1368 \tTraining Loss: 0.00664801 \tValidation Loss 0.00726740 \tTraining Accuracy 57.364% \tValidation Accuracy 56.912%\n",
      "Epoch: 1369 \tTraining Loss: 0.00664932 \tValidation Loss 0.00725080 \tTraining Accuracy 57.233% \tValidation Accuracy 56.630%\n",
      "Epoch: 1370 \tTraining Loss: 0.00664488 \tValidation Loss 0.00721806 \tTraining Accuracy 57.398% \tValidation Accuracy 57.439%\n",
      "Epoch: 1371 \tTraining Loss: 0.00664616 \tValidation Loss 0.00716157 \tTraining Accuracy 57.415% \tValidation Accuracy 58.037%\n",
      "Epoch: 1372 \tTraining Loss: 0.00664797 \tValidation Loss 0.00720083 \tTraining Accuracy 57.364% \tValidation Accuracy 56.490%\n",
      "Epoch: 1373 \tTraining Loss: 0.00664881 \tValidation Loss 0.00719446 \tTraining Accuracy 57.351% \tValidation Accuracy 57.861%\n",
      "Epoch: 1374 \tTraining Loss: 0.00664723 \tValidation Loss 0.00720767 \tTraining Accuracy 57.354% \tValidation Accuracy 58.143%\n",
      "Epoch: 1375 \tTraining Loss: 0.00664948 \tValidation Loss 0.00720626 \tTraining Accuracy 57.233% \tValidation Accuracy 56.173%\n",
      "Epoch: 1376 \tTraining Loss: 0.00663791 \tValidation Loss 0.00720398 \tTraining Accuracy 57.566% \tValidation Accuracy 57.052%\n",
      "Epoch: 1377 \tTraining Loss: 0.00664958 \tValidation Loss 0.00721377 \tTraining Accuracy 57.186% \tValidation Accuracy 56.841%\n",
      "Epoch: 1378 \tTraining Loss: 0.00664080 \tValidation Loss 0.00724524 \tTraining Accuracy 57.566% \tValidation Accuracy 56.665%\n",
      "Epoch: 1379 \tTraining Loss: 0.00663256 \tValidation Loss 0.00721321 \tTraining Accuracy 57.809% \tValidation Accuracy 57.052%\n",
      "Epoch: 1380 \tTraining Loss: 0.00664391 \tValidation Loss 0.00720038 \tTraining Accuracy 57.486% \tValidation Accuracy 56.841%\n",
      "Epoch: 1381 \tTraining Loss: 0.00663422 \tValidation Loss 0.00722294 \tTraining Accuracy 57.819% \tValidation Accuracy 56.384%\n",
      "Epoch: 1382 \tTraining Loss: 0.00664079 \tValidation Loss 0.00722067 \tTraining Accuracy 57.566% \tValidation Accuracy 57.791%\n",
      "Epoch: 1383 \tTraining Loss: 0.00663912 \tValidation Loss 0.00723829 \tTraining Accuracy 57.580% \tValidation Accuracy 57.404%\n",
      "Epoch: 1384 \tTraining Loss: 0.00664133 \tValidation Loss 0.00719951 \tTraining Accuracy 57.499% \tValidation Accuracy 56.525%\n",
      "Epoch: 1385 \tTraining Loss: 0.00664678 \tValidation Loss 0.00722707 \tTraining Accuracy 57.472% \tValidation Accuracy 56.419%\n",
      "Epoch: 1386 \tTraining Loss: 0.00663792 \tValidation Loss 0.00718824 \tTraining Accuracy 57.587% \tValidation Accuracy 57.369%\n",
      "Epoch: 1387 \tTraining Loss: 0.00664073 \tValidation Loss 0.00726657 \tTraining Accuracy 57.486% \tValidation Accuracy 55.927%\n",
      "Epoch: 1388 \tTraining Loss: 0.00663873 \tValidation Loss 0.00719427 \tTraining Accuracy 57.701% \tValidation Accuracy 57.650%\n",
      "Epoch: 1389 \tTraining Loss: 0.00664444 \tValidation Loss 0.00721931 \tTraining Accuracy 57.428% \tValidation Accuracy 57.439%\n",
      "Epoch: 1390 \tTraining Loss: 0.00664320 \tValidation Loss 0.00724716 \tTraining Accuracy 57.405% \tValidation Accuracy 57.404%\n",
      "Epoch: 1391 \tTraining Loss: 0.00664423 \tValidation Loss 0.00719144 \tTraining Accuracy 57.516% \tValidation Accuracy 57.756%\n",
      "Epoch: 1392 \tTraining Loss: 0.00664189 \tValidation Loss 0.00721941 \tTraining Accuracy 57.442% \tValidation Accuracy 57.017%\n",
      "Epoch: 1393 \tTraining Loss: 0.00664400 \tValidation Loss 0.00718710 \tTraining Accuracy 57.432% \tValidation Accuracy 58.319%\n",
      "Epoch: 1394 \tTraining Loss: 0.00664133 \tValidation Loss 0.00723108 \tTraining Accuracy 57.590% \tValidation Accuracy 57.123%\n",
      "Epoch: 1395 \tTraining Loss: 0.00663294 \tValidation Loss 0.00720396 \tTraining Accuracy 57.614% \tValidation Accuracy 57.263%\n",
      "Epoch: 1396 \tTraining Loss: 0.00662429 \tValidation Loss 0.00715784 \tTraining Accuracy 57.883% \tValidation Accuracy 58.037%\n",
      "Epoch: 1397 \tTraining Loss: 0.00663564 \tValidation Loss 0.00723668 \tTraining Accuracy 57.668% \tValidation Accuracy 57.052%\n",
      "Epoch: 1398 \tTraining Loss: 0.00662932 \tValidation Loss 0.00718406 \tTraining Accuracy 57.843% \tValidation Accuracy 57.123%\n",
      "Epoch: 1399 \tTraining Loss: 0.00663693 \tValidation Loss 0.00718653 \tTraining Accuracy 57.482% \tValidation Accuracy 58.600%\n",
      "Epoch: 1400 \tTraining Loss: 0.00663415 \tValidation Loss 0.00720304 \tTraining Accuracy 57.614% \tValidation Accuracy 58.319%\n",
      "Epoch: 1401 \tTraining Loss: 0.00663578 \tValidation Loss 0.00719095 \tTraining Accuracy 57.637% \tValidation Accuracy 56.982%\n",
      "Epoch: 1402 \tTraining Loss: 0.00663511 \tValidation Loss 0.00719603 \tTraining Accuracy 57.668% \tValidation Accuracy 57.158%\n",
      "Epoch: 1403 \tTraining Loss: 0.00663440 \tValidation Loss 0.00725229 \tTraining Accuracy 57.769% \tValidation Accuracy 56.314%\n",
      "Epoch: 1404 \tTraining Loss: 0.00664091 \tValidation Loss 0.00723058 \tTraining Accuracy 57.546% \tValidation Accuracy 57.650%\n",
      "Epoch: 1405 \tTraining Loss: 0.00663985 \tValidation Loss 0.00721016 \tTraining Accuracy 57.422% \tValidation Accuracy 57.263%\n",
      "Epoch: 1406 \tTraining Loss: 0.00663422 \tValidation Loss 0.00719919 \tTraining Accuracy 57.684% \tValidation Accuracy 57.123%\n",
      "Epoch: 1407 \tTraining Loss: 0.00663585 \tValidation Loss 0.00724460 \tTraining Accuracy 57.789% \tValidation Accuracy 56.138%\n",
      "Epoch: 1408 \tTraining Loss: 0.00664110 \tValidation Loss 0.00721212 \tTraining Accuracy 57.374% \tValidation Accuracy 57.439%\n",
      "Epoch: 1409 \tTraining Loss: 0.00663621 \tValidation Loss 0.00721339 \tTraining Accuracy 57.728% \tValidation Accuracy 56.771%\n",
      "Epoch: 1410 \tTraining Loss: 0.00663279 \tValidation Loss 0.00726535 \tTraining Accuracy 57.759% \tValidation Accuracy 56.877%\n",
      "Epoch: 1411 \tTraining Loss: 0.00663226 \tValidation Loss 0.00723800 \tTraining Accuracy 57.698% \tValidation Accuracy 56.419%\n",
      "Epoch: 1412 \tTraining Loss: 0.00663435 \tValidation Loss 0.00722121 \tTraining Accuracy 57.695% \tValidation Accuracy 57.263%\n",
      "Epoch: 1413 \tTraining Loss: 0.00663441 \tValidation Loss 0.00718011 \tTraining Accuracy 57.735% \tValidation Accuracy 57.123%\n",
      "Epoch: 1414 \tTraining Loss: 0.00663037 \tValidation Loss 0.00716838 \tTraining Accuracy 57.721% \tValidation Accuracy 57.545%\n",
      "Epoch: 1415 \tTraining Loss: 0.00663671 \tValidation Loss 0.00720752 \tTraining Accuracy 57.583% \tValidation Accuracy 56.771%\n",
      "Epoch: 1416 \tTraining Loss: 0.00662823 \tValidation Loss 0.00726737 \tTraining Accuracy 57.860% \tValidation Accuracy 55.610%\n",
      "Epoch: 1417 \tTraining Loss: 0.00663386 \tValidation Loss 0.00724360 \tTraining Accuracy 57.732% \tValidation Accuracy 56.173%\n",
      "Epoch: 1418 \tTraining Loss: 0.00662925 \tValidation Loss 0.00718701 \tTraining Accuracy 57.836% \tValidation Accuracy 57.510%\n",
      "Epoch: 1419 \tTraining Loss: 0.00663583 \tValidation Loss 0.00719741 \tTraining Accuracy 57.691% \tValidation Accuracy 57.615%\n",
      "Epoch: 1420 \tTraining Loss: 0.00662723 \tValidation Loss 0.00718248 \tTraining Accuracy 57.947% \tValidation Accuracy 57.721%\n",
      "Epoch: 1421 \tTraining Loss: 0.00663147 \tValidation Loss 0.00722935 \tTraining Accuracy 57.863% \tValidation Accuracy 57.158%\n",
      "Epoch: 1422 \tTraining Loss: 0.00662930 \tValidation Loss 0.00725983 \tTraining Accuracy 57.880% \tValidation Accuracy 56.877%\n",
      "Epoch: 1423 \tTraining Loss: 0.00663005 \tValidation Loss 0.00723054 \tTraining Accuracy 57.806% \tValidation Accuracy 57.615%\n",
      "Epoch: 1424 \tTraining Loss: 0.00662425 \tValidation Loss 0.00725302 \tTraining Accuracy 57.984% \tValidation Accuracy 57.510%\n",
      "Epoch: 1425 \tTraining Loss: 0.00662430 \tValidation Loss 0.00722079 \tTraining Accuracy 57.924% \tValidation Accuracy 57.404%\n",
      "Epoch: 1426 \tTraining Loss: 0.00662811 \tValidation Loss 0.00729060 \tTraining Accuracy 57.897% \tValidation Accuracy 56.595%\n",
      "Epoch: 1427 \tTraining Loss: 0.00663410 \tValidation Loss 0.00725285 \tTraining Accuracy 57.765% \tValidation Accuracy 56.877%\n",
      "Epoch: 1428 \tTraining Loss: 0.00662726 \tValidation Loss 0.00722247 \tTraining Accuracy 57.944% \tValidation Accuracy 57.861%\n",
      "Epoch: 1429 \tTraining Loss: 0.00663017 \tValidation Loss 0.00717925 \tTraining Accuracy 57.880% \tValidation Accuracy 57.756%\n",
      "Epoch: 1430 \tTraining Loss: 0.00662884 \tValidation Loss 0.00720021 \tTraining Accuracy 57.809% \tValidation Accuracy 57.545%\n",
      "Epoch: 1431 \tTraining Loss: 0.00662533 \tValidation Loss 0.00721704 \tTraining Accuracy 57.876% \tValidation Accuracy 57.158%\n",
      "Epoch: 1432 \tTraining Loss: 0.00663076 \tValidation Loss 0.00723608 \tTraining Accuracy 57.799% \tValidation Accuracy 57.791%\n",
      "Epoch: 1433 \tTraining Loss: 0.00663087 \tValidation Loss 0.00724367 \tTraining Accuracy 57.836% \tValidation Accuracy 56.877%\n",
      "Epoch: 1434 \tTraining Loss: 0.00661992 \tValidation Loss 0.00726902 \tTraining Accuracy 58.207% \tValidation Accuracy 56.806%\n",
      "Epoch: 1435 \tTraining Loss: 0.00662511 \tValidation Loss 0.00721031 \tTraining Accuracy 57.940% \tValidation Accuracy 57.791%\n",
      "Epoch: 1436 \tTraining Loss: 0.00662864 \tValidation Loss 0.00715005 \tTraining Accuracy 57.856% \tValidation Accuracy 57.580%\n",
      "Epoch: 1437 \tTraining Loss: 0.00663453 \tValidation Loss 0.00728533 \tTraining Accuracy 57.607% \tValidation Accuracy 56.349%\n",
      "Epoch: 1438 \tTraining Loss: 0.00662451 \tValidation Loss 0.00717471 \tTraining Accuracy 57.981% \tValidation Accuracy 57.123%\n",
      "Epoch: 1439 \tTraining Loss: 0.00662088 \tValidation Loss 0.00719424 \tTraining Accuracy 58.015% \tValidation Accuracy 57.263%\n",
      "Epoch: 1440 \tTraining Loss: 0.00662923 \tValidation Loss 0.00721947 \tTraining Accuracy 57.688% \tValidation Accuracy 57.017%\n",
      "Epoch: 1441 \tTraining Loss: 0.00662229 \tValidation Loss 0.00722474 \tTraining Accuracy 57.880% \tValidation Accuracy 56.490%\n",
      "Epoch: 1442 \tTraining Loss: 0.00662035 \tValidation Loss 0.00718304 \tTraining Accuracy 58.247% \tValidation Accuracy 57.650%\n",
      "Epoch: 1443 \tTraining Loss: 0.00662197 \tValidation Loss 0.00715935 \tTraining Accuracy 58.069% \tValidation Accuracy 57.756%\n",
      "Epoch: 1444 \tTraining Loss: 0.00661194 \tValidation Loss 0.00716029 \tTraining Accuracy 58.301% \tValidation Accuracy 57.334%\n",
      "Epoch: 1445 \tTraining Loss: 0.00662607 \tValidation Loss 0.00726770 \tTraining Accuracy 57.755% \tValidation Accuracy 56.806%\n",
      "Epoch: 1446 \tTraining Loss: 0.00662533 \tValidation Loss 0.00722547 \tTraining Accuracy 57.930% \tValidation Accuracy 57.721%\n",
      "Epoch: 1447 \tTraining Loss: 0.00662539 \tValidation Loss 0.00725363 \tTraining Accuracy 57.880% \tValidation Accuracy 57.088%\n",
      "Epoch: 1448 \tTraining Loss: 0.00662513 \tValidation Loss 0.00722805 \tTraining Accuracy 58.008% \tValidation Accuracy 56.349%\n",
      "Epoch: 1449 \tTraining Loss: 0.00661669 \tValidation Loss 0.00717142 \tTraining Accuracy 58.173% \tValidation Accuracy 57.052%\n",
      "Epoch: 1450 \tTraining Loss: 0.00662938 \tValidation Loss 0.00719093 \tTraining Accuracy 57.951% \tValidation Accuracy 57.474%\n",
      "Epoch: 1451 \tTraining Loss: 0.00662049 \tValidation Loss 0.00716101 \tTraining Accuracy 58.102% \tValidation Accuracy 57.721%\n",
      "Epoch: 1452 \tTraining Loss: 0.00661209 \tValidation Loss 0.00720315 \tTraining Accuracy 58.294% \tValidation Accuracy 57.826%\n",
      "Epoch: 1453 \tTraining Loss: 0.00662134 \tValidation Loss 0.00721007 \tTraining Accuracy 58.075% \tValidation Accuracy 56.419%\n",
      "Epoch: 1454 \tTraining Loss: 0.00662150 \tValidation Loss 0.00718574 \tTraining Accuracy 58.011% \tValidation Accuracy 56.947%\n",
      "Epoch: 1455 \tTraining Loss: 0.00661166 \tValidation Loss 0.00725314 \tTraining Accuracy 58.294% \tValidation Accuracy 56.841%\n",
      "Epoch: 1456 \tTraining Loss: 0.00662122 \tValidation Loss 0.00719862 \tTraining Accuracy 58.170% \tValidation Accuracy 57.580%\n",
      "Epoch: 1457 \tTraining Loss: 0.00661712 \tValidation Loss 0.00719701 \tTraining Accuracy 58.075% \tValidation Accuracy 57.580%\n",
      "Epoch: 1458 \tTraining Loss: 0.00661564 \tValidation Loss 0.00719112 \tTraining Accuracy 58.220% \tValidation Accuracy 57.334%\n",
      "Epoch: 1459 \tTraining Loss: 0.00660627 \tValidation Loss 0.00718145 \tTraining Accuracy 58.419% \tValidation Accuracy 58.213%\n",
      "Epoch: 1460 \tTraining Loss: 0.00661786 \tValidation Loss 0.00717005 \tTraining Accuracy 58.183% \tValidation Accuracy 58.706%\n",
      "Epoch: 1461 \tTraining Loss: 0.00661705 \tValidation Loss 0.00715277 \tTraining Accuracy 58.160% \tValidation Accuracy 58.987%\n",
      "Epoch: 1462 \tTraining Loss: 0.00662143 \tValidation Loss 0.00718420 \tTraining Accuracy 58.197% \tValidation Accuracy 57.686%\n",
      "Epoch: 1463 \tTraining Loss: 0.00661950 \tValidation Loss 0.00720939 \tTraining Accuracy 58.079% \tValidation Accuracy 56.595%\n",
      "Epoch: 1464 \tTraining Loss: 0.00662203 \tValidation Loss 0.00719539 \tTraining Accuracy 58.038% \tValidation Accuracy 57.545%\n",
      "Epoch: 1465 \tTraining Loss: 0.00662674 \tValidation Loss 0.00719176 \tTraining Accuracy 57.836% \tValidation Accuracy 58.002%\n",
      "Epoch: 1466 \tTraining Loss: 0.00662666 \tValidation Loss 0.00717389 \tTraining Accuracy 57.940% \tValidation Accuracy 57.474%\n",
      "Epoch: 1467 \tTraining Loss: 0.00662009 \tValidation Loss 0.00720431 \tTraining Accuracy 58.015% \tValidation Accuracy 56.841%\n",
      "Epoch: 1468 \tTraining Loss: 0.00661488 \tValidation Loss 0.00724352 \tTraining Accuracy 58.247% \tValidation Accuracy 57.580%\n",
      "Epoch: 1469 \tTraining Loss: 0.00661637 \tValidation Loss 0.00717411 \tTraining Accuracy 58.106% \tValidation Accuracy 57.510%\n",
      "Epoch: 1470 \tTraining Loss: 0.00661922 \tValidation Loss 0.00719869 \tTraining Accuracy 58.092% \tValidation Accuracy 58.248%\n",
      "Epoch: 1471 \tTraining Loss: 0.00661915 \tValidation Loss 0.00717331 \tTraining Accuracy 58.109% \tValidation Accuracy 58.072%\n",
      "Epoch: 1472 \tTraining Loss: 0.00661272 \tValidation Loss 0.00722223 \tTraining Accuracy 58.271% \tValidation Accuracy 57.439%\n",
      "Epoch: 1473 \tTraining Loss: 0.00662210 \tValidation Loss 0.00714922 \tTraining Accuracy 58.018% \tValidation Accuracy 58.213%\n",
      "Epoch: 1474 \tTraining Loss: 0.00661799 \tValidation Loss 0.00721218 \tTraining Accuracy 58.325% \tValidation Accuracy 58.108%\n",
      "Epoch: 1475 \tTraining Loss: 0.00661808 \tValidation Loss 0.00724444 \tTraining Accuracy 58.119% \tValidation Accuracy 56.384%\n",
      "Epoch: 1476 \tTraining Loss: 0.00661776 \tValidation Loss 0.00720339 \tTraining Accuracy 58.250% \tValidation Accuracy 56.525%\n",
      "Epoch: 1477 \tTraining Loss: 0.00661589 \tValidation Loss 0.00719798 \tTraining Accuracy 58.237% \tValidation Accuracy 57.404%\n",
      "Epoch: 1478 \tTraining Loss: 0.00660611 \tValidation Loss 0.00719613 \tTraining Accuracy 58.395% \tValidation Accuracy 57.404%\n",
      "Epoch: 1479 \tTraining Loss: 0.00661478 \tValidation Loss 0.00723890 \tTraining Accuracy 58.203% \tValidation Accuracy 57.580%\n",
      "Epoch: 1480 \tTraining Loss: 0.00662146 \tValidation Loss 0.00717124 \tTraining Accuracy 58.025% \tValidation Accuracy 57.299%\n",
      "Epoch: 1481 \tTraining Loss: 0.00660935 \tValidation Loss 0.00721042 \tTraining Accuracy 58.331% \tValidation Accuracy 57.299%\n",
      "Epoch: 1482 \tTraining Loss: 0.00661792 \tValidation Loss 0.00718028 \tTraining Accuracy 58.062% \tValidation Accuracy 58.635%\n",
      "Epoch: 1483 \tTraining Loss: 0.00660739 \tValidation Loss 0.00715125 \tTraining Accuracy 58.540% \tValidation Accuracy 57.686%\n",
      "Epoch: 1484 \tTraining Loss: 0.00661326 \tValidation Loss 0.00720065 \tTraining Accuracy 58.250% \tValidation Accuracy 57.580%\n",
      "Epoch: 1485 \tTraining Loss: 0.00662029 \tValidation Loss 0.00711939 \tTraining Accuracy 58.160% \tValidation Accuracy 58.002%\n",
      "Epoch: 1486 \tTraining Loss: 0.00661870 \tValidation Loss 0.00714469 \tTraining Accuracy 58.112% \tValidation Accuracy 58.846%\n",
      "Epoch: 1487 \tTraining Loss: 0.00661098 \tValidation Loss 0.00717692 \tTraining Accuracy 58.311% \tValidation Accuracy 57.474%\n",
      "Epoch: 1488 \tTraining Loss: 0.00660833 \tValidation Loss 0.00716617 \tTraining Accuracy 58.399% \tValidation Accuracy 58.459%\n",
      "Epoch: 1489 \tTraining Loss: 0.00661392 \tValidation Loss 0.00717325 \tTraining Accuracy 58.193% \tValidation Accuracy 56.982%\n",
      "Epoch: 1490 \tTraining Loss: 0.00661181 \tValidation Loss 0.00720407 \tTraining Accuracy 58.308% \tValidation Accuracy 57.263%\n",
      "Epoch: 1491 \tTraining Loss: 0.00660870 \tValidation Loss 0.00720787 \tTraining Accuracy 58.355% \tValidation Accuracy 58.143%\n",
      "Epoch: 1492 \tTraining Loss: 0.00660969 \tValidation Loss 0.00716327 \tTraining Accuracy 58.352% \tValidation Accuracy 58.284%\n",
      "Epoch: 1493 \tTraining Loss: 0.00661428 \tValidation Loss 0.00718345 \tTraining Accuracy 58.321% \tValidation Accuracy 57.404%\n",
      "Epoch: 1494 \tTraining Loss: 0.00661333 \tValidation Loss 0.00721161 \tTraining Accuracy 58.254% \tValidation Accuracy 57.369%\n",
      "Epoch: 1495 \tTraining Loss: 0.00661119 \tValidation Loss 0.00718967 \tTraining Accuracy 58.271% \tValidation Accuracy 57.650%\n",
      "Epoch: 1496 \tTraining Loss: 0.00660239 \tValidation Loss 0.00725316 \tTraining Accuracy 58.544% \tValidation Accuracy 57.545%\n",
      "Epoch: 1497 \tTraining Loss: 0.00660939 \tValidation Loss 0.00719226 \tTraining Accuracy 58.422% \tValidation Accuracy 58.072%\n",
      "Epoch: 1498 \tTraining Loss: 0.00661005 \tValidation Loss 0.00718985 \tTraining Accuracy 58.240% \tValidation Accuracy 57.615%\n",
      "Epoch: 1499 \tTraining Loss: 0.00660217 \tValidation Loss 0.00720419 \tTraining Accuracy 58.557% \tValidation Accuracy 57.404%\n",
      "Epoch: 1500 \tTraining Loss: 0.00660877 \tValidation Loss 0.00721249 \tTraining Accuracy 58.382% \tValidation Accuracy 57.123%\n",
      "Epoch: 1501 \tTraining Loss: 0.00659875 \tValidation Loss 0.00722799 \tTraining Accuracy 58.625% \tValidation Accuracy 57.510%\n",
      "Epoch: 1502 \tTraining Loss: 0.00661291 \tValidation Loss 0.00723133 \tTraining Accuracy 58.217% \tValidation Accuracy 57.158%\n",
      "Epoch: 1503 \tTraining Loss: 0.00660187 \tValidation Loss 0.00717724 \tTraining Accuracy 58.557% \tValidation Accuracy 58.389%\n",
      "Epoch: 1504 \tTraining Loss: 0.00660269 \tValidation Loss 0.00718322 \tTraining Accuracy 58.513% \tValidation Accuracy 58.248%\n",
      "Epoch: 1505 \tTraining Loss: 0.00661198 \tValidation Loss 0.00718411 \tTraining Accuracy 58.291% \tValidation Accuracy 57.299%\n",
      "Epoch: 1506 \tTraining Loss: 0.00660556 \tValidation Loss 0.00720408 \tTraining Accuracy 58.466% \tValidation Accuracy 57.791%\n",
      "Epoch: 1507 \tTraining Loss: 0.00661012 \tValidation Loss 0.00716343 \tTraining Accuracy 58.277% \tValidation Accuracy 58.248%\n",
      "Epoch: 1508 \tTraining Loss: 0.00660960 \tValidation Loss 0.00720034 \tTraining Accuracy 58.372% \tValidation Accuracy 58.600%\n",
      "Epoch: 1509 \tTraining Loss: 0.00660830 \tValidation Loss 0.00714069 \tTraining Accuracy 58.432% \tValidation Accuracy 58.530%\n",
      "Epoch: 1510 \tTraining Loss: 0.00660854 \tValidation Loss 0.00717670 \tTraining Accuracy 58.392% \tValidation Accuracy 58.530%\n",
      "Epoch: 1511 \tTraining Loss: 0.00660800 \tValidation Loss 0.00718685 \tTraining Accuracy 58.355% \tValidation Accuracy 57.228%\n",
      "Epoch: 1512 \tTraining Loss: 0.00660761 \tValidation Loss 0.00717395 \tTraining Accuracy 58.432% \tValidation Accuracy 57.756%\n",
      "Epoch: 1513 \tTraining Loss: 0.00660202 \tValidation Loss 0.00717490 \tTraining Accuracy 58.641% \tValidation Accuracy 56.665%\n",
      "Epoch: 1514 \tTraining Loss: 0.00661090 \tValidation Loss 0.00717623 \tTraining Accuracy 58.281% \tValidation Accuracy 58.143%\n",
      "Epoch: 1515 \tTraining Loss: 0.00660483 \tValidation Loss 0.00715921 \tTraining Accuracy 58.547% \tValidation Accuracy 58.284%\n",
      "Epoch: 1516 \tTraining Loss: 0.00660837 \tValidation Loss 0.00720425 \tTraining Accuracy 58.372% \tValidation Accuracy 57.439%\n",
      "Epoch: 1517 \tTraining Loss: 0.00660010 \tValidation Loss 0.00715051 \tTraining Accuracy 58.672% \tValidation Accuracy 57.545%\n",
      "Epoch: 1518 \tTraining Loss: 0.00660781 \tValidation Loss 0.00723106 \tTraining Accuracy 58.328% \tValidation Accuracy 57.580%\n",
      "Epoch: 1519 \tTraining Loss: 0.00659150 \tValidation Loss 0.00716294 \tTraining Accuracy 58.887% \tValidation Accuracy 57.580%\n",
      "Epoch: 1520 \tTraining Loss: 0.00660290 \tValidation Loss 0.00719365 \tTraining Accuracy 58.490% \tValidation Accuracy 58.108%\n",
      "Epoch: 1521 \tTraining Loss: 0.00659901 \tValidation Loss 0.00718976 \tTraining Accuracy 58.668% \tValidation Accuracy 58.248%\n",
      "Epoch: 1522 \tTraining Loss: 0.00660668 \tValidation Loss 0.00710923 \tTraining Accuracy 58.540% \tValidation Accuracy 59.057%\n",
      "Epoch: 1523 \tTraining Loss: 0.00659802 \tValidation Loss 0.00714895 \tTraining Accuracy 58.668% \tValidation Accuracy 57.967%\n",
      "Epoch: 1524 \tTraining Loss: 0.00659979 \tValidation Loss 0.00716028 \tTraining Accuracy 58.695% \tValidation Accuracy 58.178%\n",
      "Epoch: 1525 \tTraining Loss: 0.00660417 \tValidation Loss 0.00720596 \tTraining Accuracy 58.503% \tValidation Accuracy 58.002%\n",
      "Epoch: 1526 \tTraining Loss: 0.00659926 \tValidation Loss 0.00719763 \tTraining Accuracy 58.618% \tValidation Accuracy 57.721%\n",
      "Epoch: 1527 \tTraining Loss: 0.00660608 \tValidation Loss 0.00716737 \tTraining Accuracy 58.453% \tValidation Accuracy 58.952%\n",
      "Epoch: 1528 \tTraining Loss: 0.00659917 \tValidation Loss 0.00720491 \tTraining Accuracy 58.662% \tValidation Accuracy 58.178%\n",
      "Epoch: 1529 \tTraining Loss: 0.00660329 \tValidation Loss 0.00727384 \tTraining Accuracy 58.483% \tValidation Accuracy 57.474%\n",
      "Epoch: 1530 \tTraining Loss: 0.00660052 \tValidation Loss 0.00715266 \tTraining Accuracy 58.561% \tValidation Accuracy 58.459%\n",
      "Epoch: 1531 \tTraining Loss: 0.00660456 \tValidation Loss 0.00717010 \tTraining Accuracy 58.422% \tValidation Accuracy 58.319%\n",
      "Epoch: 1532 \tTraining Loss: 0.00659840 \tValidation Loss 0.00713261 \tTraining Accuracy 58.689% \tValidation Accuracy 58.530%\n",
      "Epoch: 1533 \tTraining Loss: 0.00660744 \tValidation Loss 0.00721071 \tTraining Accuracy 58.446% \tValidation Accuracy 57.123%\n",
      "Epoch: 1534 \tTraining Loss: 0.00660438 \tValidation Loss 0.00719525 \tTraining Accuracy 58.530% \tValidation Accuracy 58.881%\n",
      "Epoch: 1535 \tTraining Loss: 0.00660316 \tValidation Loss 0.00724164 \tTraining Accuracy 58.503% \tValidation Accuracy 58.600%\n",
      "Epoch: 1536 \tTraining Loss: 0.00659525 \tValidation Loss 0.00721006 \tTraining Accuracy 58.840% \tValidation Accuracy 58.072%\n",
      "Epoch: 1537 \tTraining Loss: 0.00660247 \tValidation Loss 0.00709591 \tTraining Accuracy 58.554% \tValidation Accuracy 59.761%\n",
      "Epoch: 1538 \tTraining Loss: 0.00659664 \tValidation Loss 0.00714514 \tTraining Accuracy 58.709% \tValidation Accuracy 58.881%\n",
      "Epoch: 1539 \tTraining Loss: 0.00660569 \tValidation Loss 0.00715644 \tTraining Accuracy 58.412% \tValidation Accuracy 58.530%\n",
      "Epoch: 1540 \tTraining Loss: 0.00659172 \tValidation Loss 0.00716897 \tTraining Accuracy 58.881% \tValidation Accuracy 57.721%\n",
      "Epoch: 1541 \tTraining Loss: 0.00659637 \tValidation Loss 0.00716900 \tTraining Accuracy 58.749% \tValidation Accuracy 58.248%\n",
      "Epoch: 1542 \tTraining Loss: 0.00659678 \tValidation Loss 0.00718292 \tTraining Accuracy 58.776% \tValidation Accuracy 57.088%\n",
      "Epoch: 1543 \tTraining Loss: 0.00659735 \tValidation Loss 0.00718619 \tTraining Accuracy 58.665% \tValidation Accuracy 58.213%\n",
      "Epoch: 1544 \tTraining Loss: 0.00659120 \tValidation Loss 0.00718995 \tTraining Accuracy 58.753% \tValidation Accuracy 58.459%\n",
      "Epoch: 1545 \tTraining Loss: 0.00660131 \tValidation Loss 0.00718738 \tTraining Accuracy 58.517% \tValidation Accuracy 58.319%\n",
      "Epoch: 1546 \tTraining Loss: 0.00660029 \tValidation Loss 0.00721038 \tTraining Accuracy 58.682% \tValidation Accuracy 58.459%\n",
      "Epoch: 1547 \tTraining Loss: 0.00659537 \tValidation Loss 0.00713596 \tTraining Accuracy 58.891% \tValidation Accuracy 58.952%\n",
      "Epoch: 1548 \tTraining Loss: 0.00659741 \tValidation Loss 0.00712592 \tTraining Accuracy 58.726% \tValidation Accuracy 58.635%\n",
      "Epoch: 1549 \tTraining Loss: 0.00658924 \tValidation Loss 0.00721069 \tTraining Accuracy 58.911% \tValidation Accuracy 57.404%\n",
      "Epoch: 1550 \tTraining Loss: 0.00660118 \tValidation Loss 0.00716744 \tTraining Accuracy 58.577% \tValidation Accuracy 57.474%\n",
      "Epoch: 1551 \tTraining Loss: 0.00660604 \tValidation Loss 0.00716694 \tTraining Accuracy 58.352% \tValidation Accuracy 58.459%\n",
      "Epoch: 1552 \tTraining Loss: 0.00660165 \tValidation Loss 0.00712350 \tTraining Accuracy 58.571% \tValidation Accuracy 59.198%\n",
      "Epoch: 1553 \tTraining Loss: 0.00659876 \tValidation Loss 0.00712417 \tTraining Accuracy 58.564% \tValidation Accuracy 58.495%\n",
      "Epoch: 1554 \tTraining Loss: 0.00659547 \tValidation Loss 0.00718115 \tTraining Accuracy 58.726% \tValidation Accuracy 57.334%\n",
      "Epoch: 1555 \tTraining Loss: 0.00659224 \tValidation Loss 0.00718604 \tTraining Accuracy 58.857% \tValidation Accuracy 58.178%\n",
      "Epoch: 1556 \tTraining Loss: 0.00659531 \tValidation Loss 0.00720146 \tTraining Accuracy 58.773% \tValidation Accuracy 56.490%\n",
      "Epoch: 1557 \tTraining Loss: 0.00660257 \tValidation Loss 0.00715837 \tTraining Accuracy 58.496% \tValidation Accuracy 58.248%\n",
      "Epoch: 1558 \tTraining Loss: 0.00659237 \tValidation Loss 0.00718389 \tTraining Accuracy 58.840% \tValidation Accuracy 58.037%\n",
      "Epoch: 1559 \tTraining Loss: 0.00659479 \tValidation Loss 0.00716714 \tTraining Accuracy 58.638% \tValidation Accuracy 58.530%\n",
      "Epoch: 1560 \tTraining Loss: 0.00659144 \tValidation Loss 0.00714105 \tTraining Accuracy 58.840% \tValidation Accuracy 58.424%\n",
      "Epoch: 1561 \tTraining Loss: 0.00659837 \tValidation Loss 0.00721303 \tTraining Accuracy 58.628% \tValidation Accuracy 57.721%\n",
      "Epoch: 1562 \tTraining Loss: 0.00659439 \tValidation Loss 0.00716841 \tTraining Accuracy 58.780% \tValidation Accuracy 58.389%\n",
      "Epoch: 1563 \tTraining Loss: 0.00659308 \tValidation Loss 0.00718123 \tTraining Accuracy 58.790% \tValidation Accuracy 58.213%\n",
      "Epoch: 1564 \tTraining Loss: 0.00658921 \tValidation Loss 0.00713821 \tTraining Accuracy 58.908% \tValidation Accuracy 57.615%\n",
      "Epoch: 1565 \tTraining Loss: 0.00659702 \tValidation Loss 0.00715903 \tTraining Accuracy 58.665% \tValidation Accuracy 57.861%\n",
      "Epoch: 1566 \tTraining Loss: 0.00658402 \tValidation Loss 0.00718883 \tTraining Accuracy 58.965% \tValidation Accuracy 57.791%\n",
      "Epoch: 1567 \tTraining Loss: 0.00659017 \tValidation Loss 0.00721034 \tTraining Accuracy 58.908% \tValidation Accuracy 58.600%\n",
      "Epoch: 1568 \tTraining Loss: 0.00659795 \tValidation Loss 0.00714764 \tTraining Accuracy 58.618% \tValidation Accuracy 58.248%\n",
      "Epoch: 1569 \tTraining Loss: 0.00659403 \tValidation Loss 0.00719118 \tTraining Accuracy 58.641% \tValidation Accuracy 57.580%\n",
      "Epoch: 1570 \tTraining Loss: 0.00658766 \tValidation Loss 0.00717684 \tTraining Accuracy 58.992% \tValidation Accuracy 58.354%\n",
      "Epoch: 1571 \tTraining Loss: 0.00659691 \tValidation Loss 0.00722210 \tTraining Accuracy 58.769% \tValidation Accuracy 56.665%\n",
      "Epoch: 1572 \tTraining Loss: 0.00658533 \tValidation Loss 0.00713171 \tTraining Accuracy 59.090% \tValidation Accuracy 58.213%\n",
      "Epoch: 1573 \tTraining Loss: 0.00659653 \tValidation Loss 0.00715395 \tTraining Accuracy 58.763% \tValidation Accuracy 57.791%\n",
      "Epoch: 1574 \tTraining Loss: 0.00658639 \tValidation Loss 0.00716112 \tTraining Accuracy 58.972% \tValidation Accuracy 58.530%\n",
      "Epoch: 1575 \tTraining Loss: 0.00659219 \tValidation Loss 0.00718225 \tTraining Accuracy 58.790% \tValidation Accuracy 58.248%\n",
      "Epoch: 1576 \tTraining Loss: 0.00659085 \tValidation Loss 0.00718104 \tTraining Accuracy 58.897% \tValidation Accuracy 57.721%\n",
      "Epoch: 1577 \tTraining Loss: 0.00658755 \tValidation Loss 0.00719445 \tTraining Accuracy 58.992% \tValidation Accuracy 57.088%\n",
      "Epoch: 1578 \tTraining Loss: 0.00659673 \tValidation Loss 0.00719313 \tTraining Accuracy 58.631% \tValidation Accuracy 58.459%\n",
      "Epoch: 1579 \tTraining Loss: 0.00658542 \tValidation Loss 0.00721860 \tTraining Accuracy 58.914% \tValidation Accuracy 57.088%\n",
      "Epoch: 1580 \tTraining Loss: 0.00659475 \tValidation Loss 0.00715517 \tTraining Accuracy 58.820% \tValidation Accuracy 58.108%\n",
      "Epoch: 1581 \tTraining Loss: 0.00658958 \tValidation Loss 0.00720823 \tTraining Accuracy 58.894% \tValidation Accuracy 58.108%\n",
      "Epoch: 1582 \tTraining Loss: 0.00659494 \tValidation Loss 0.00711858 \tTraining Accuracy 58.823% \tValidation Accuracy 58.635%\n",
      "Epoch: 1583 \tTraining Loss: 0.00658500 \tValidation Loss 0.00713134 \tTraining Accuracy 58.965% \tValidation Accuracy 58.600%\n",
      "Epoch: 1584 \tTraining Loss: 0.00658522 \tValidation Loss 0.00716476 \tTraining Accuracy 59.116% \tValidation Accuracy 57.897%\n",
      "Epoch: 1585 \tTraining Loss: 0.00659475 \tValidation Loss 0.00716654 \tTraining Accuracy 58.722% \tValidation Accuracy 57.545%\n",
      "Epoch: 1586 \tTraining Loss: 0.00658284 \tValidation Loss 0.00714323 \tTraining Accuracy 58.958% \tValidation Accuracy 58.459%\n",
      "Epoch: 1587 \tTraining Loss: 0.00659186 \tValidation Loss 0.00717288 \tTraining Accuracy 58.742% \tValidation Accuracy 57.791%\n",
      "Epoch: 1588 \tTraining Loss: 0.00658615 \tValidation Loss 0.00720243 \tTraining Accuracy 58.992% \tValidation Accuracy 58.776%\n",
      "Epoch: 1589 \tTraining Loss: 0.00658530 \tValidation Loss 0.00717106 \tTraining Accuracy 59.039% \tValidation Accuracy 58.670%\n",
      "Epoch: 1590 \tTraining Loss: 0.00658499 \tValidation Loss 0.00714336 \tTraining Accuracy 58.914% \tValidation Accuracy 58.952%\n",
      "Epoch: 1591 \tTraining Loss: 0.00659228 \tValidation Loss 0.00719928 \tTraining Accuracy 58.793% \tValidation Accuracy 57.299%\n",
      "Epoch: 1592 \tTraining Loss: 0.00657902 \tValidation Loss 0.00715132 \tTraining Accuracy 59.197% \tValidation Accuracy 58.881%\n",
      "Epoch: 1593 \tTraining Loss: 0.00658821 \tValidation Loss 0.00720600 \tTraining Accuracy 58.988% \tValidation Accuracy 58.037%\n",
      "Epoch: 1594 \tTraining Loss: 0.00658592 \tValidation Loss 0.00714314 \tTraining Accuracy 59.009% \tValidation Accuracy 58.108%\n",
      "Epoch: 1595 \tTraining Loss: 0.00657998 \tValidation Loss 0.00717483 \tTraining Accuracy 59.130% \tValidation Accuracy 58.776%\n",
      "Epoch: 1596 \tTraining Loss: 0.00658251 \tValidation Loss 0.00714396 \tTraining Accuracy 59.042% \tValidation Accuracy 57.615%\n",
      "Epoch: 1597 \tTraining Loss: 0.00658301 \tValidation Loss 0.00717819 \tTraining Accuracy 59.160% \tValidation Accuracy 57.299%\n",
      "Epoch: 1598 \tTraining Loss: 0.00657991 \tValidation Loss 0.00717985 \tTraining Accuracy 59.234% \tValidation Accuracy 58.530%\n",
      "Epoch: 1599 \tTraining Loss: 0.00657607 \tValidation Loss 0.00715143 \tTraining Accuracy 59.258% \tValidation Accuracy 58.389%\n",
      "Epoch: 1600 \tTraining Loss: 0.00659190 \tValidation Loss 0.00718179 \tTraining Accuracy 58.908% \tValidation Accuracy 58.670%\n",
      "Epoch: 1601 \tTraining Loss: 0.00659415 \tValidation Loss 0.00715382 \tTraining Accuracy 58.722% \tValidation Accuracy 58.670%\n",
      "Epoch: 1602 \tTraining Loss: 0.00658638 \tValidation Loss 0.00713690 \tTraining Accuracy 59.009% \tValidation Accuracy 58.670%\n",
      "Epoch: 1603 \tTraining Loss: 0.00658096 \tValidation Loss 0.00717124 \tTraining Accuracy 59.073% \tValidation Accuracy 59.093%\n",
      "Epoch: 1604 \tTraining Loss: 0.00659298 \tValidation Loss 0.00716633 \tTraining Accuracy 58.800% \tValidation Accuracy 58.424%\n",
      "Epoch: 1605 \tTraining Loss: 0.00657613 \tValidation Loss 0.00717285 \tTraining Accuracy 59.332% \tValidation Accuracy 57.545%\n",
      "Epoch: 1606 \tTraining Loss: 0.00657743 \tValidation Loss 0.00718275 \tTraining Accuracy 59.234% \tValidation Accuracy 58.354%\n",
      "Epoch: 1607 \tTraining Loss: 0.00658565 \tValidation Loss 0.00717773 \tTraining Accuracy 59.059% \tValidation Accuracy 58.284%\n",
      "Epoch: 1608 \tTraining Loss: 0.00658312 \tValidation Loss 0.00718475 \tTraining Accuracy 58.975% \tValidation Accuracy 58.635%\n",
      "Epoch: 1609 \tTraining Loss: 0.00657985 \tValidation Loss 0.00719369 \tTraining Accuracy 59.015% \tValidation Accuracy 57.545%\n",
      "Epoch: 1610 \tTraining Loss: 0.00658640 \tValidation Loss 0.00716516 \tTraining Accuracy 58.897% \tValidation Accuracy 58.284%\n",
      "Epoch: 1611 \tTraining Loss: 0.00658097 \tValidation Loss 0.00713873 \tTraining Accuracy 59.130% \tValidation Accuracy 58.917%\n",
      "Epoch: 1612 \tTraining Loss: 0.00657277 \tValidation Loss 0.00718441 \tTraining Accuracy 59.416% \tValidation Accuracy 58.424%\n",
      "Epoch: 1613 \tTraining Loss: 0.00657936 \tValidation Loss 0.00722472 \tTraining Accuracy 59.090% \tValidation Accuracy 58.495%\n",
      "Epoch: 1614 \tTraining Loss: 0.00658725 \tValidation Loss 0.00710969 \tTraining Accuracy 58.988% \tValidation Accuracy 58.213%\n",
      "Epoch: 1615 \tTraining Loss: 0.00657704 \tValidation Loss 0.00718910 \tTraining Accuracy 59.278% \tValidation Accuracy 57.932%\n",
      "Epoch: 1616 \tTraining Loss: 0.00658625 \tValidation Loss 0.00721118 \tTraining Accuracy 58.938% \tValidation Accuracy 57.510%\n",
      "Epoch: 1617 \tTraining Loss: 0.00657106 \tValidation Loss 0.00716104 \tTraining Accuracy 59.356% \tValidation Accuracy 58.459%\n",
      "Epoch: 1618 \tTraining Loss: 0.00657681 \tValidation Loss 0.00715459 \tTraining Accuracy 59.177% \tValidation Accuracy 58.881%\n",
      "Epoch: 1619 \tTraining Loss: 0.00658690 \tValidation Loss 0.00718460 \tTraining Accuracy 58.854% \tValidation Accuracy 58.002%\n",
      "Epoch: 1620 \tTraining Loss: 0.00657725 \tValidation Loss 0.00714315 \tTraining Accuracy 59.194% \tValidation Accuracy 58.741%\n",
      "Epoch: 1621 \tTraining Loss: 0.00658607 \tValidation Loss 0.00718227 \tTraining Accuracy 59.029% \tValidation Accuracy 57.510%\n",
      "Epoch: 1622 \tTraining Loss: 0.00657983 \tValidation Loss 0.00717345 \tTraining Accuracy 59.130% \tValidation Accuracy 58.389%\n",
      "Epoch: 1623 \tTraining Loss: 0.00657673 \tValidation Loss 0.00716291 \tTraining Accuracy 59.288% \tValidation Accuracy 58.213%\n",
      "Epoch: 1624 \tTraining Loss: 0.00658031 \tValidation Loss 0.00707892 \tTraining Accuracy 59.174% \tValidation Accuracy 59.444%\n",
      "Epoch: 1625 \tTraining Loss: 0.00657975 \tValidation Loss 0.00720523 \tTraining Accuracy 59.238% \tValidation Accuracy 57.861%\n",
      "Epoch: 1626 \tTraining Loss: 0.00657872 \tValidation Loss 0.00723882 \tTraining Accuracy 59.201% \tValidation Accuracy 57.861%\n",
      "Epoch: 1627 \tTraining Loss: 0.00657359 \tValidation Loss 0.00719802 \tTraining Accuracy 59.339% \tValidation Accuracy 58.495%\n",
      "Epoch: 1628 \tTraining Loss: 0.00656939 \tValidation Loss 0.00718283 \tTraining Accuracy 59.386% \tValidation Accuracy 58.811%\n",
      "Epoch: 1629 \tTraining Loss: 0.00657172 \tValidation Loss 0.00718710 \tTraining Accuracy 59.501% \tValidation Accuracy 58.178%\n",
      "Epoch: 1630 \tTraining Loss: 0.00658705 \tValidation Loss 0.00717526 \tTraining Accuracy 58.860% \tValidation Accuracy 57.580%\n",
      "Epoch: 1631 \tTraining Loss: 0.00657428 \tValidation Loss 0.00716737 \tTraining Accuracy 59.312% \tValidation Accuracy 58.108%\n",
      "Epoch: 1632 \tTraining Loss: 0.00657759 \tValidation Loss 0.00714791 \tTraining Accuracy 59.302% \tValidation Accuracy 57.474%\n",
      "Epoch: 1633 \tTraining Loss: 0.00656573 \tValidation Loss 0.00715142 \tTraining Accuracy 59.511% \tValidation Accuracy 58.002%\n",
      "Epoch: 1634 \tTraining Loss: 0.00657106 \tValidation Loss 0.00718466 \tTraining Accuracy 59.271% \tValidation Accuracy 58.459%\n",
      "Epoch: 1635 \tTraining Loss: 0.00658509 \tValidation Loss 0.00716701 \tTraining Accuracy 58.941% \tValidation Accuracy 58.917%\n",
      "Epoch: 1636 \tTraining Loss: 0.00657366 \tValidation Loss 0.00709875 \tTraining Accuracy 59.309% \tValidation Accuracy 58.143%\n",
      "Epoch: 1637 \tTraining Loss: 0.00656842 \tValidation Loss 0.00716395 \tTraining Accuracy 59.410% \tValidation Accuracy 57.932%\n",
      "Epoch: 1638 \tTraining Loss: 0.00657532 \tValidation Loss 0.00712770 \tTraining Accuracy 59.251% \tValidation Accuracy 58.284%\n",
      "Epoch: 1639 \tTraining Loss: 0.00656789 \tValidation Loss 0.00716177 \tTraining Accuracy 59.517% \tValidation Accuracy 58.565%\n",
      "Epoch: 1640 \tTraining Loss: 0.00658148 \tValidation Loss 0.00715425 \tTraining Accuracy 59.137% \tValidation Accuracy 58.284%\n",
      "Epoch: 1641 \tTraining Loss: 0.00657324 \tValidation Loss 0.00715134 \tTraining Accuracy 59.282% \tValidation Accuracy 58.459%\n",
      "Epoch: 1642 \tTraining Loss: 0.00656969 \tValidation Loss 0.00717076 \tTraining Accuracy 59.447% \tValidation Accuracy 57.686%\n",
      "Epoch: 1643 \tTraining Loss: 0.00657379 \tValidation Loss 0.00712817 \tTraining Accuracy 59.356% \tValidation Accuracy 58.565%\n",
      "Epoch: 1644 \tTraining Loss: 0.00657128 \tValidation Loss 0.00712664 \tTraining Accuracy 59.352% \tValidation Accuracy 58.635%\n",
      "Epoch: 1645 \tTraining Loss: 0.00656897 \tValidation Loss 0.00716272 \tTraining Accuracy 59.568% \tValidation Accuracy 58.600%\n",
      "Epoch: 1646 \tTraining Loss: 0.00658186 \tValidation Loss 0.00711017 \tTraining Accuracy 59.147% \tValidation Accuracy 59.057%\n",
      "Epoch: 1647 \tTraining Loss: 0.00657587 \tValidation Loss 0.00714510 \tTraining Accuracy 59.278% \tValidation Accuracy 58.248%\n",
      "Epoch: 1648 \tTraining Loss: 0.00657995 \tValidation Loss 0.00714720 \tTraining Accuracy 59.120% \tValidation Accuracy 58.846%\n",
      "Epoch: 1649 \tTraining Loss: 0.00657086 \tValidation Loss 0.00718401 \tTraining Accuracy 59.433% \tValidation Accuracy 58.459%\n",
      "Epoch: 1650 \tTraining Loss: 0.00656769 \tValidation Loss 0.00719809 \tTraining Accuracy 59.447% \tValidation Accuracy 58.635%\n",
      "Epoch: 1651 \tTraining Loss: 0.00655705 \tValidation Loss 0.00718183 \tTraining Accuracy 59.925% \tValidation Accuracy 59.022%\n",
      "Epoch: 1652 \tTraining Loss: 0.00657020 \tValidation Loss 0.00717089 \tTraining Accuracy 59.339% \tValidation Accuracy 58.213%\n",
      "Epoch: 1653 \tTraining Loss: 0.00657311 \tValidation Loss 0.00711125 \tTraining Accuracy 59.362% \tValidation Accuracy 59.057%\n",
      "Epoch: 1654 \tTraining Loss: 0.00657454 \tValidation Loss 0.00714432 \tTraining Accuracy 59.389% \tValidation Accuracy 58.776%\n",
      "Epoch: 1655 \tTraining Loss: 0.00656816 \tValidation Loss 0.00711660 \tTraining Accuracy 59.517% \tValidation Accuracy 58.881%\n",
      "Epoch: 1656 \tTraining Loss: 0.00657210 \tValidation Loss 0.00715023 \tTraining Accuracy 59.285% \tValidation Accuracy 59.057%\n",
      "Epoch: 1657 \tTraining Loss: 0.00656460 \tValidation Loss 0.00720019 \tTraining Accuracy 59.595% \tValidation Accuracy 58.108%\n",
      "Epoch: 1658 \tTraining Loss: 0.00657207 \tValidation Loss 0.00713956 \tTraining Accuracy 59.369% \tValidation Accuracy 58.213%\n",
      "Epoch: 1659 \tTraining Loss: 0.00657224 \tValidation Loss 0.00709706 \tTraining Accuracy 59.251% \tValidation Accuracy 58.952%\n",
      "Epoch: 1660 \tTraining Loss: 0.00657581 \tValidation Loss 0.00719517 \tTraining Accuracy 59.271% \tValidation Accuracy 58.424%\n",
      "Epoch: 1661 \tTraining Loss: 0.00657036 \tValidation Loss 0.00718121 \tTraining Accuracy 59.423% \tValidation Accuracy 58.213%\n",
      "Epoch: 1662 \tTraining Loss: 0.00656697 \tValidation Loss 0.00713519 \tTraining Accuracy 59.467% \tValidation Accuracy 58.002%\n",
      "Epoch: 1663 \tTraining Loss: 0.00656762 \tValidation Loss 0.00711485 \tTraining Accuracy 59.437% \tValidation Accuracy 58.530%\n",
      "Epoch: 1664 \tTraining Loss: 0.00657663 \tValidation Loss 0.00717538 \tTraining Accuracy 59.181% \tValidation Accuracy 59.128%\n",
      "Epoch: 1665 \tTraining Loss: 0.00656479 \tValidation Loss 0.00718341 \tTraining Accuracy 59.608% \tValidation Accuracy 58.917%\n",
      "Epoch: 1666 \tTraining Loss: 0.00657160 \tValidation Loss 0.00716261 \tTraining Accuracy 59.315% \tValidation Accuracy 58.600%\n",
      "Epoch: 1667 \tTraining Loss: 0.00656181 \tValidation Loss 0.00714871 \tTraining Accuracy 59.784% \tValidation Accuracy 58.143%\n",
      "Epoch: 1668 \tTraining Loss: 0.00655413 \tValidation Loss 0.00720133 \tTraining Accuracy 59.854% \tValidation Accuracy 58.424%\n",
      "Epoch: 1669 \tTraining Loss: 0.00656943 \tValidation Loss 0.00711911 \tTraining Accuracy 59.379% \tValidation Accuracy 57.932%\n",
      "Epoch: 1670 \tTraining Loss: 0.00656788 \tValidation Loss 0.00722715 \tTraining Accuracy 59.447% \tValidation Accuracy 58.213%\n",
      "Epoch: 1671 \tTraining Loss: 0.00656575 \tValidation Loss 0.00714732 \tTraining Accuracy 59.480% \tValidation Accuracy 58.495%\n",
      "Epoch: 1672 \tTraining Loss: 0.00656370 \tValidation Loss 0.00717476 \tTraining Accuracy 59.649% \tValidation Accuracy 58.178%\n",
      "Epoch: 1673 \tTraining Loss: 0.00656160 \tValidation Loss 0.00720462 \tTraining Accuracy 59.585% \tValidation Accuracy 57.686%\n",
      "Epoch: 1674 \tTraining Loss: 0.00657269 \tValidation Loss 0.00714210 \tTraining Accuracy 59.302% \tValidation Accuracy 58.037%\n",
      "Epoch: 1675 \tTraining Loss: 0.00656295 \tValidation Loss 0.00717943 \tTraining Accuracy 59.619% \tValidation Accuracy 58.002%\n",
      "Epoch: 1676 \tTraining Loss: 0.00655979 \tValidation Loss 0.00713284 \tTraining Accuracy 59.760% \tValidation Accuracy 58.917%\n",
      "Epoch: 1677 \tTraining Loss: 0.00656474 \tValidation Loss 0.00713089 \tTraining Accuracy 59.507% \tValidation Accuracy 59.057%\n",
      "Epoch: 1678 \tTraining Loss: 0.00655613 \tValidation Loss 0.00714483 \tTraining Accuracy 59.686% \tValidation Accuracy 58.917%\n",
      "Epoch: 1679 \tTraining Loss: 0.00656115 \tValidation Loss 0.00716017 \tTraining Accuracy 59.602% \tValidation Accuracy 58.776%\n",
      "Epoch: 1680 \tTraining Loss: 0.00656413 \tValidation Loss 0.00719793 \tTraining Accuracy 59.555% \tValidation Accuracy 58.565%\n",
      "Epoch: 1681 \tTraining Loss: 0.00655728 \tValidation Loss 0.00719040 \tTraining Accuracy 59.672% \tValidation Accuracy 58.284%\n",
      "Epoch: 1682 \tTraining Loss: 0.00656310 \tValidation Loss 0.00712416 \tTraining Accuracy 59.646% \tValidation Accuracy 58.741%\n",
      "Epoch: 1683 \tTraining Loss: 0.00656216 \tValidation Loss 0.00718643 \tTraining Accuracy 59.598% \tValidation Accuracy 57.756%\n",
      "Epoch: 1684 \tTraining Loss: 0.00656158 \tValidation Loss 0.00714948 \tTraining Accuracy 59.679% \tValidation Accuracy 58.811%\n",
      "Epoch: 1685 \tTraining Loss: 0.00655889 \tValidation Loss 0.00720086 \tTraining Accuracy 59.770% \tValidation Accuracy 57.967%\n",
      "Epoch: 1686 \tTraining Loss: 0.00656132 \tValidation Loss 0.00712090 \tTraining Accuracy 59.622% \tValidation Accuracy 59.163%\n",
      "Epoch: 1687 \tTraining Loss: 0.00655902 \tValidation Loss 0.00714259 \tTraining Accuracy 59.763% \tValidation Accuracy 58.072%\n",
      "Epoch: 1688 \tTraining Loss: 0.00655135 \tValidation Loss 0.00716962 \tTraining Accuracy 59.868% \tValidation Accuracy 58.565%\n",
      "Epoch: 1689 \tTraining Loss: 0.00655889 \tValidation Loss 0.00714869 \tTraining Accuracy 59.790% \tValidation Accuracy 58.495%\n",
      "Epoch: 1690 \tTraining Loss: 0.00656122 \tValidation Loss 0.00717379 \tTraining Accuracy 59.720% \tValidation Accuracy 58.178%\n",
      "Epoch: 1691 \tTraining Loss: 0.00655393 \tValidation Loss 0.00719110 \tTraining Accuracy 59.851% \tValidation Accuracy 58.354%\n",
      "Epoch: 1692 \tTraining Loss: 0.00656384 \tValidation Loss 0.00716381 \tTraining Accuracy 59.605% \tValidation Accuracy 58.143%\n",
      "Epoch: 1693 \tTraining Loss: 0.00655828 \tValidation Loss 0.00717303 \tTraining Accuracy 59.588% \tValidation Accuracy 58.037%\n",
      "Epoch: 1694 \tTraining Loss: 0.00655962 \tValidation Loss 0.00716426 \tTraining Accuracy 59.683% \tValidation Accuracy 58.846%\n",
      "Epoch: 1695 \tTraining Loss: 0.00656612 \tValidation Loss 0.00711999 \tTraining Accuracy 59.430% \tValidation Accuracy 58.952%\n",
      "Epoch: 1696 \tTraining Loss: 0.00655577 \tValidation Loss 0.00716414 \tTraining Accuracy 59.683% \tValidation Accuracy 58.495%\n",
      "Epoch: 1697 \tTraining Loss: 0.00655712 \tValidation Loss 0.00714956 \tTraining Accuracy 59.844% \tValidation Accuracy 59.268%\n",
      "Epoch: 1698 \tTraining Loss: 0.00655836 \tValidation Loss 0.00718419 \tTraining Accuracy 59.811% \tValidation Accuracy 58.002%\n",
      "Epoch: 1699 \tTraining Loss: 0.00656419 \tValidation Loss 0.00712149 \tTraining Accuracy 59.629% \tValidation Accuracy 59.268%\n",
      "Epoch: 1700 \tTraining Loss: 0.00654257 \tValidation Loss 0.00714517 \tTraining Accuracy 60.202% \tValidation Accuracy 58.424%\n",
      "Epoch: 1701 \tTraining Loss: 0.00655720 \tValidation Loss 0.00717181 \tTraining Accuracy 59.784% \tValidation Accuracy 58.846%\n",
      "Epoch: 1702 \tTraining Loss: 0.00655186 \tValidation Loss 0.00713785 \tTraining Accuracy 59.902% \tValidation Accuracy 58.635%\n",
      "Epoch: 1703 \tTraining Loss: 0.00656196 \tValidation Loss 0.00719157 \tTraining Accuracy 59.581% \tValidation Accuracy 58.248%\n",
      "Epoch: 1704 \tTraining Loss: 0.00655194 \tValidation Loss 0.00714856 \tTraining Accuracy 59.908% \tValidation Accuracy 58.143%\n",
      "Epoch: 1705 \tTraining Loss: 0.00656081 \tValidation Loss 0.00715951 \tTraining Accuracy 59.797% \tValidation Accuracy 57.686%\n",
      "Epoch: 1706 \tTraining Loss: 0.00655651 \tValidation Loss 0.00714817 \tTraining Accuracy 59.696% \tValidation Accuracy 58.354%\n",
      "Epoch: 1707 \tTraining Loss: 0.00655743 \tValidation Loss 0.00712460 \tTraining Accuracy 59.757% \tValidation Accuracy 58.952%\n",
      "Epoch: 1708 \tTraining Loss: 0.00655751 \tValidation Loss 0.00716240 \tTraining Accuracy 59.801% \tValidation Accuracy 58.952%\n",
      "Epoch: 1709 \tTraining Loss: 0.00655590 \tValidation Loss 0.00715075 \tTraining Accuracy 59.854% \tValidation Accuracy 58.495%\n",
      "Epoch: 1710 \tTraining Loss: 0.00655558 \tValidation Loss 0.00712786 \tTraining Accuracy 59.824% \tValidation Accuracy 59.128%\n",
      "Epoch: 1711 \tTraining Loss: 0.00655823 \tValidation Loss 0.00711362 \tTraining Accuracy 59.629% \tValidation Accuracy 59.268%\n",
      "Epoch: 1712 \tTraining Loss: 0.00655343 \tValidation Loss 0.00714497 \tTraining Accuracy 59.811% \tValidation Accuracy 58.670%\n",
      "Epoch: 1713 \tTraining Loss: 0.00656505 \tValidation Loss 0.00712366 \tTraining Accuracy 59.531% \tValidation Accuracy 58.952%\n",
      "Epoch: 1714 \tTraining Loss: 0.00656673 \tValidation Loss 0.00713061 \tTraining Accuracy 59.484% \tValidation Accuracy 59.163%\n",
      "Epoch: 1715 \tTraining Loss: 0.00655912 \tValidation Loss 0.00715200 \tTraining Accuracy 59.642% \tValidation Accuracy 59.022%\n",
      "Epoch: 1716 \tTraining Loss: 0.00655979 \tValidation Loss 0.00715202 \tTraining Accuracy 59.646% \tValidation Accuracy 58.565%\n",
      "Epoch: 1717 \tTraining Loss: 0.00655487 \tValidation Loss 0.00722524 \tTraining Accuracy 59.817% \tValidation Accuracy 57.650%\n",
      "Epoch: 1718 \tTraining Loss: 0.00655558 \tValidation Loss 0.00711957 \tTraining Accuracy 59.706% \tValidation Accuracy 58.600%\n",
      "Epoch: 1719 \tTraining Loss: 0.00654996 \tValidation Loss 0.00713271 \tTraining Accuracy 60.013% \tValidation Accuracy 59.128%\n",
      "Epoch: 1720 \tTraining Loss: 0.00654872 \tValidation Loss 0.00715924 \tTraining Accuracy 59.854% \tValidation Accuracy 58.108%\n",
      "Epoch: 1721 \tTraining Loss: 0.00654527 \tValidation Loss 0.00716940 \tTraining Accuracy 60.040% \tValidation Accuracy 57.756%\n",
      "Epoch: 1722 \tTraining Loss: 0.00655246 \tValidation Loss 0.00724027 \tTraining Accuracy 59.939% \tValidation Accuracy 57.756%\n",
      "Epoch: 1723 \tTraining Loss: 0.00654618 \tValidation Loss 0.00712494 \tTraining Accuracy 60.087% \tValidation Accuracy 59.022%\n",
      "Epoch: 1724 \tTraining Loss: 0.00654809 \tValidation Loss 0.00716621 \tTraining Accuracy 59.996% \tValidation Accuracy 58.072%\n",
      "Epoch: 1725 \tTraining Loss: 0.00655059 \tValidation Loss 0.00718730 \tTraining Accuracy 59.811% \tValidation Accuracy 58.037%\n",
      "Epoch: 1726 \tTraining Loss: 0.00655821 \tValidation Loss 0.00714451 \tTraining Accuracy 59.676% \tValidation Accuracy 59.093%\n",
      "Epoch: 1727 \tTraining Loss: 0.00654858 \tValidation Loss 0.00718366 \tTraining Accuracy 59.952% \tValidation Accuracy 58.354%\n",
      "Epoch: 1728 \tTraining Loss: 0.00654888 \tValidation Loss 0.00712905 \tTraining Accuracy 59.966% \tValidation Accuracy 59.479%\n",
      "Epoch: 1729 \tTraining Loss: 0.00655228 \tValidation Loss 0.00712579 \tTraining Accuracy 59.888% \tValidation Accuracy 58.917%\n",
      "Epoch: 1730 \tTraining Loss: 0.00655424 \tValidation Loss 0.00717038 \tTraining Accuracy 59.902% \tValidation Accuracy 58.108%\n",
      "Epoch: 1731 \tTraining Loss: 0.00654708 \tValidation Loss 0.00718473 \tTraining Accuracy 60.063% \tValidation Accuracy 57.967%\n",
      "Epoch: 1732 \tTraining Loss: 0.00654908 \tValidation Loss 0.00718833 \tTraining Accuracy 60.047% \tValidation Accuracy 58.530%\n",
      "Epoch: 1733 \tTraining Loss: 0.00654784 \tValidation Loss 0.00718645 \tTraining Accuracy 60.020% \tValidation Accuracy 58.917%\n",
      "Epoch: 1734 \tTraining Loss: 0.00655473 \tValidation Loss 0.00715591 \tTraining Accuracy 59.780% \tValidation Accuracy 58.495%\n",
      "Epoch: 1735 \tTraining Loss: 0.00654242 \tValidation Loss 0.00711620 \tTraining Accuracy 60.117% \tValidation Accuracy 59.163%\n",
      "Epoch: 1736 \tTraining Loss: 0.00654781 \tValidation Loss 0.00710028 \tTraining Accuracy 60.131% \tValidation Accuracy 58.811%\n",
      "Epoch: 1737 \tTraining Loss: 0.00654554 \tValidation Loss 0.00715772 \tTraining Accuracy 60.020% \tValidation Accuracy 58.706%\n",
      "Epoch: 1738 \tTraining Loss: 0.00654740 \tValidation Loss 0.00712543 \tTraining Accuracy 60.020% \tValidation Accuracy 58.741%\n",
      "Epoch: 1739 \tTraining Loss: 0.00655127 \tValidation Loss 0.00717965 \tTraining Accuracy 59.982% \tValidation Accuracy 58.248%\n",
      "Epoch: 1740 \tTraining Loss: 0.00654694 \tValidation Loss 0.00720282 \tTraining Accuracy 59.915% \tValidation Accuracy 57.299%\n",
      "Epoch: 1741 \tTraining Loss: 0.00653965 \tValidation Loss 0.00716721 \tTraining Accuracy 60.218% \tValidation Accuracy 58.389%\n",
      "Epoch: 1742 \tTraining Loss: 0.00653133 \tValidation Loss 0.00721349 \tTraining Accuracy 60.441% \tValidation Accuracy 57.861%\n",
      "Epoch: 1743 \tTraining Loss: 0.00654541 \tValidation Loss 0.00718121 \tTraining Accuracy 60.148% \tValidation Accuracy 58.389%\n",
      "Epoch: 1744 \tTraining Loss: 0.00654619 \tValidation Loss 0.00714404 \tTraining Accuracy 60.104% \tValidation Accuracy 57.615%\n",
      "Epoch: 1745 \tTraining Loss: 0.00653719 \tValidation Loss 0.00714355 \tTraining Accuracy 60.336% \tValidation Accuracy 59.409%\n",
      "Epoch: 1746 \tTraining Loss: 0.00653823 \tValidation Loss 0.00719476 \tTraining Accuracy 60.225% \tValidation Accuracy 58.741%\n",
      "Epoch: 1747 \tTraining Loss: 0.00654796 \tValidation Loss 0.00714735 \tTraining Accuracy 60.104% \tValidation Accuracy 58.811%\n",
      "Epoch: 1748 \tTraining Loss: 0.00654794 \tValidation Loss 0.00717437 \tTraining Accuracy 60.124% \tValidation Accuracy 59.198%\n",
      "Epoch: 1749 \tTraining Loss: 0.00653762 \tValidation Loss 0.00715145 \tTraining Accuracy 60.299% \tValidation Accuracy 58.846%\n",
      "Epoch: 1750 \tTraining Loss: 0.00653476 \tValidation Loss 0.00711854 \tTraining Accuracy 60.340% \tValidation Accuracy 59.022%\n",
      "Epoch: 1751 \tTraining Loss: 0.00655376 \tValidation Loss 0.00714705 \tTraining Accuracy 59.858% \tValidation Accuracy 59.022%\n",
      "Epoch: 1752 \tTraining Loss: 0.00653809 \tValidation Loss 0.00715043 \tTraining Accuracy 60.222% \tValidation Accuracy 59.304%\n",
      "Epoch: 1753 \tTraining Loss: 0.00654465 \tValidation Loss 0.00716627 \tTraining Accuracy 60.168% \tValidation Accuracy 58.143%\n",
      "Epoch: 1754 \tTraining Loss: 0.00654140 \tValidation Loss 0.00715052 \tTraining Accuracy 60.094% \tValidation Accuracy 59.163%\n",
      "Epoch: 1755 \tTraining Loss: 0.00654249 \tValidation Loss 0.00709519 \tTraining Accuracy 60.164% \tValidation Accuracy 59.550%\n",
      "Epoch: 1756 \tTraining Loss: 0.00654962 \tValidation Loss 0.00717545 \tTraining Accuracy 59.949% \tValidation Accuracy 58.248%\n",
      "Epoch: 1757 \tTraining Loss: 0.00654036 \tValidation Loss 0.00708983 \tTraining Accuracy 60.259% \tValidation Accuracy 59.796%\n",
      "Epoch: 1758 \tTraining Loss: 0.00655055 \tValidation Loss 0.00709241 \tTraining Accuracy 59.912% \tValidation Accuracy 59.726%\n",
      "Epoch: 1759 \tTraining Loss: 0.00653858 \tValidation Loss 0.00712919 \tTraining Accuracy 60.286% \tValidation Accuracy 60.288%\n",
      "Epoch: 1760 \tTraining Loss: 0.00654276 \tValidation Loss 0.00713197 \tTraining Accuracy 60.117% \tValidation Accuracy 58.952%\n",
      "Epoch: 1761 \tTraining Loss: 0.00653902 \tValidation Loss 0.00717998 \tTraining Accuracy 60.370% \tValidation Accuracy 58.846%\n",
      "Epoch: 1762 \tTraining Loss: 0.00654303 \tValidation Loss 0.00716227 \tTraining Accuracy 60.202% \tValidation Accuracy 58.248%\n",
      "Epoch: 1763 \tTraining Loss: 0.00654425 \tValidation Loss 0.00713275 \tTraining Accuracy 60.164% \tValidation Accuracy 57.932%\n",
      "Epoch: 1764 \tTraining Loss: 0.00654154 \tValidation Loss 0.00712079 \tTraining Accuracy 60.242% \tValidation Accuracy 59.198%\n",
      "Epoch: 1765 \tTraining Loss: 0.00653344 \tValidation Loss 0.00712619 \tTraining Accuracy 60.474% \tValidation Accuracy 58.987%\n",
      "Epoch: 1766 \tTraining Loss: 0.00654559 \tValidation Loss 0.00716293 \tTraining Accuracy 60.020% \tValidation Accuracy 57.826%\n",
      "Epoch: 1767 \tTraining Loss: 0.00654313 \tValidation Loss 0.00709620 \tTraining Accuracy 60.050% \tValidation Accuracy 60.042%\n",
      "Epoch: 1768 \tTraining Loss: 0.00653754 \tValidation Loss 0.00717609 \tTraining Accuracy 60.309% \tValidation Accuracy 57.510%\n",
      "Epoch: 1769 \tTraining Loss: 0.00653951 \tValidation Loss 0.00717636 \tTraining Accuracy 60.276% \tValidation Accuracy 58.354%\n",
      "Epoch: 1770 \tTraining Loss: 0.00654487 \tValidation Loss 0.00716934 \tTraining Accuracy 60.009% \tValidation Accuracy 58.741%\n",
      "Epoch: 1771 \tTraining Loss: 0.00653775 \tValidation Loss 0.00712554 \tTraining Accuracy 60.387% \tValidation Accuracy 59.022%\n",
      "Epoch: 1772 \tTraining Loss: 0.00653699 \tValidation Loss 0.00719440 \tTraining Accuracy 60.336% \tValidation Accuracy 58.741%\n",
      "Epoch: 1773 \tTraining Loss: 0.00654309 \tValidation Loss 0.00717652 \tTraining Accuracy 60.063% \tValidation Accuracy 58.037%\n",
      "Epoch: 1774 \tTraining Loss: 0.00654011 \tValidation Loss 0.00714825 \tTraining Accuracy 60.205% \tValidation Accuracy 58.565%\n",
      "Epoch: 1775 \tTraining Loss: 0.00654688 \tValidation Loss 0.00720122 \tTraining Accuracy 60.016% \tValidation Accuracy 57.334%\n",
      "Epoch: 1776 \tTraining Loss: 0.00653596 \tValidation Loss 0.00715545 \tTraining Accuracy 60.360% \tValidation Accuracy 58.706%\n",
      "Epoch: 1777 \tTraining Loss: 0.00653747 \tValidation Loss 0.00716185 \tTraining Accuracy 60.299% \tValidation Accuracy 58.881%\n",
      "Epoch: 1778 \tTraining Loss: 0.00653642 \tValidation Loss 0.00710811 \tTraining Accuracy 60.340% \tValidation Accuracy 58.952%\n",
      "Epoch: 1779 \tTraining Loss: 0.00653763 \tValidation Loss 0.00720125 \tTraining Accuracy 60.158% \tValidation Accuracy 58.037%\n",
      "Epoch: 1780 \tTraining Loss: 0.00653715 \tValidation Loss 0.00714744 \tTraining Accuracy 60.195% \tValidation Accuracy 59.515%\n",
      "Epoch: 1781 \tTraining Loss: 0.00653464 \tValidation Loss 0.00711618 \tTraining Accuracy 60.417% \tValidation Accuracy 59.198%\n",
      "Epoch: 1782 \tTraining Loss: 0.00653364 \tValidation Loss 0.00712567 \tTraining Accuracy 60.474% \tValidation Accuracy 58.776%\n",
      "Epoch: 1783 \tTraining Loss: 0.00652975 \tValidation Loss 0.00714390 \tTraining Accuracy 60.340% \tValidation Accuracy 58.389%\n",
      "Epoch: 1784 \tTraining Loss: 0.00653405 \tValidation Loss 0.00712014 \tTraining Accuracy 60.323% \tValidation Accuracy 59.620%\n",
      "Epoch: 1785 \tTraining Loss: 0.00653340 \tValidation Loss 0.00717517 \tTraining Accuracy 60.353% \tValidation Accuracy 58.987%\n",
      "Epoch: 1786 \tTraining Loss: 0.00653427 \tValidation Loss 0.00714620 \tTraining Accuracy 60.444% \tValidation Accuracy 59.233%\n",
      "Epoch: 1787 \tTraining Loss: 0.00652875 \tValidation Loss 0.00717045 \tTraining Accuracy 60.538% \tValidation Accuracy 58.459%\n",
      "Epoch: 1788 \tTraining Loss: 0.00653459 \tValidation Loss 0.00715218 \tTraining Accuracy 60.383% \tValidation Accuracy 58.846%\n",
      "Epoch: 1789 \tTraining Loss: 0.00653838 \tValidation Loss 0.00712581 \tTraining Accuracy 60.222% \tValidation Accuracy 58.811%\n",
      "Epoch: 1790 \tTraining Loss: 0.00653655 \tValidation Loss 0.00717992 \tTraining Accuracy 60.269% \tValidation Accuracy 59.515%\n",
      "Epoch: 1791 \tTraining Loss: 0.00653651 \tValidation Loss 0.00716092 \tTraining Accuracy 60.367% \tValidation Accuracy 58.881%\n",
      "Epoch: 1792 \tTraining Loss: 0.00653227 \tValidation Loss 0.00716347 \tTraining Accuracy 60.437% \tValidation Accuracy 58.811%\n",
      "Epoch: 1793 \tTraining Loss: 0.00653653 \tValidation Loss 0.00712320 \tTraining Accuracy 60.316% \tValidation Accuracy 59.902%\n",
      "Epoch: 1794 \tTraining Loss: 0.00653836 \tValidation Loss 0.00718714 \tTraining Accuracy 60.154% \tValidation Accuracy 57.510%\n",
      "Epoch: 1795 \tTraining Loss: 0.00653536 \tValidation Loss 0.00722986 \tTraining Accuracy 60.353% \tValidation Accuracy 57.826%\n",
      "Epoch: 1796 \tTraining Loss: 0.00653754 \tValidation Loss 0.00711631 \tTraining Accuracy 60.303% \tValidation Accuracy 58.987%\n",
      "Epoch: 1797 \tTraining Loss: 0.00653327 \tValidation Loss 0.00717976 \tTraining Accuracy 60.367% \tValidation Accuracy 59.444%\n",
      "Epoch: 1798 \tTraining Loss: 0.00653392 \tValidation Loss 0.00711604 \tTraining Accuracy 60.357% \tValidation Accuracy 58.706%\n",
      "Epoch: 1799 \tTraining Loss: 0.00652774 \tValidation Loss 0.00709610 \tTraining Accuracy 60.636% \tValidation Accuracy 59.409%\n",
      "Epoch: 1800 \tTraining Loss: 0.00653147 \tValidation Loss 0.00711907 \tTraining Accuracy 60.400% \tValidation Accuracy 59.128%\n",
      "Epoch: 1801 \tTraining Loss: 0.00653076 \tValidation Loss 0.00713173 \tTraining Accuracy 60.515% \tValidation Accuracy 58.670%\n",
      "Epoch: 1802 \tTraining Loss: 0.00653053 \tValidation Loss 0.00712523 \tTraining Accuracy 60.538% \tValidation Accuracy 59.339%\n",
      "Epoch: 1803 \tTraining Loss: 0.00653126 \tValidation Loss 0.00711545 \tTraining Accuracy 60.383% \tValidation Accuracy 58.635%\n",
      "Epoch: 1804 \tTraining Loss: 0.00652833 \tValidation Loss 0.00714234 \tTraining Accuracy 60.498% \tValidation Accuracy 58.987%\n",
      "Epoch: 1805 \tTraining Loss: 0.00653518 \tValidation Loss 0.00714557 \tTraining Accuracy 60.249% \tValidation Accuracy 59.198%\n",
      "Epoch: 1806 \tTraining Loss: 0.00652764 \tValidation Loss 0.00715936 \tTraining Accuracy 60.495% \tValidation Accuracy 58.284%\n",
      "Epoch: 1807 \tTraining Loss: 0.00652775 \tValidation Loss 0.00716194 \tTraining Accuracy 60.464% \tValidation Accuracy 58.178%\n",
      "Epoch: 1808 \tTraining Loss: 0.00652936 \tValidation Loss 0.00713585 \tTraining Accuracy 60.417% \tValidation Accuracy 58.389%\n",
      "Epoch: 1809 \tTraining Loss: 0.00653012 \tValidation Loss 0.00711342 \tTraining Accuracy 60.437% \tValidation Accuracy 59.515%\n",
      "Epoch: 1810 \tTraining Loss: 0.00652116 \tValidation Loss 0.00712045 \tTraining Accuracy 60.737% \tValidation Accuracy 59.902%\n",
      "Epoch: 1811 \tTraining Loss: 0.00653017 \tValidation Loss 0.00715462 \tTraining Accuracy 60.495% \tValidation Accuracy 59.304%\n",
      "Epoch: 1812 \tTraining Loss: 0.00652528 \tValidation Loss 0.00712115 \tTraining Accuracy 60.673% \tValidation Accuracy 58.917%\n",
      "Epoch: 1813 \tTraining Loss: 0.00651967 \tValidation Loss 0.00716388 \tTraining Accuracy 60.784% \tValidation Accuracy 58.917%\n",
      "Epoch: 1814 \tTraining Loss: 0.00652142 \tValidation Loss 0.00708839 \tTraining Accuracy 60.707% \tValidation Accuracy 59.972%\n",
      "Epoch: 1815 \tTraining Loss: 0.00651740 \tValidation Loss 0.00715208 \tTraining Accuracy 60.835% \tValidation Accuracy 59.057%\n",
      "Epoch: 1816 \tTraining Loss: 0.00652363 \tValidation Loss 0.00716853 \tTraining Accuracy 60.609% \tValidation Accuracy 59.022%\n",
      "Epoch: 1817 \tTraining Loss: 0.00652503 \tValidation Loss 0.00713647 \tTraining Accuracy 60.623% \tValidation Accuracy 58.776%\n",
      "Epoch: 1818 \tTraining Loss: 0.00652163 \tValidation Loss 0.00720238 \tTraining Accuracy 60.926% \tValidation Accuracy 59.057%\n",
      "Epoch: 1819 \tTraining Loss: 0.00652873 \tValidation Loss 0.00714968 \tTraining Accuracy 60.660% \tValidation Accuracy 59.268%\n",
      "Epoch: 1820 \tTraining Loss: 0.00652498 \tValidation Loss 0.00715570 \tTraining Accuracy 60.731% \tValidation Accuracy 58.881%\n",
      "Epoch: 1821 \tTraining Loss: 0.00652612 \tValidation Loss 0.00719207 \tTraining Accuracy 60.518% \tValidation Accuracy 58.284%\n",
      "Epoch: 1822 \tTraining Loss: 0.00652235 \tValidation Loss 0.00716269 \tTraining Accuracy 60.697% \tValidation Accuracy 58.776%\n",
      "Epoch: 1823 \tTraining Loss: 0.00652940 \tValidation Loss 0.00710723 \tTraining Accuracy 60.437% \tValidation Accuracy 59.304%\n",
      "Epoch: 1824 \tTraining Loss: 0.00651542 \tValidation Loss 0.00716999 \tTraining Accuracy 60.859% \tValidation Accuracy 59.655%\n",
      "Epoch: 1825 \tTraining Loss: 0.00651675 \tValidation Loss 0.00712480 \tTraining Accuracy 60.912% \tValidation Accuracy 59.022%\n",
      "Epoch: 1826 \tTraining Loss: 0.00652858 \tValidation Loss 0.00712369 \tTraining Accuracy 60.525% \tValidation Accuracy 58.881%\n",
      "Epoch: 1827 \tTraining Loss: 0.00651485 \tValidation Loss 0.00712088 \tTraining Accuracy 60.929% \tValidation Accuracy 59.198%\n",
      "Epoch: 1828 \tTraining Loss: 0.00651968 \tValidation Loss 0.00715507 \tTraining Accuracy 60.801% \tValidation Accuracy 59.304%\n",
      "Epoch: 1829 \tTraining Loss: 0.00651999 \tValidation Loss 0.00719937 \tTraining Accuracy 60.771% \tValidation Accuracy 58.459%\n",
      "Epoch: 1830 \tTraining Loss: 0.00651647 \tValidation Loss 0.00715609 \tTraining Accuracy 60.845% \tValidation Accuracy 59.057%\n",
      "Epoch: 1831 \tTraining Loss: 0.00652818 \tValidation Loss 0.00714091 \tTraining Accuracy 60.468% \tValidation Accuracy 58.881%\n",
      "Epoch: 1832 \tTraining Loss: 0.00651666 \tValidation Loss 0.00706133 \tTraining Accuracy 60.902% \tValidation Accuracy 59.690%\n",
      "Epoch: 1833 \tTraining Loss: 0.00652579 \tValidation Loss 0.00709148 \tTraining Accuracy 60.572% \tValidation Accuracy 59.233%\n",
      "Epoch: 1834 \tTraining Loss: 0.00652549 \tValidation Loss 0.00716786 \tTraining Accuracy 60.623% \tValidation Accuracy 58.495%\n",
      "Epoch: 1835 \tTraining Loss: 0.00651849 \tValidation Loss 0.00715362 \tTraining Accuracy 60.764% \tValidation Accuracy 59.128%\n",
      "Epoch: 1836 \tTraining Loss: 0.00652415 \tValidation Loss 0.00713907 \tTraining Accuracy 60.596% \tValidation Accuracy 58.952%\n",
      "Epoch: 1837 \tTraining Loss: 0.00651895 \tValidation Loss 0.00713620 \tTraining Accuracy 60.825% \tValidation Accuracy 57.826%\n",
      "Epoch: 1838 \tTraining Loss: 0.00651299 \tValidation Loss 0.00715488 \tTraining Accuracy 60.865% \tValidation Accuracy 59.304%\n",
      "Epoch: 1839 \tTraining Loss: 0.00651925 \tValidation Loss 0.00716549 \tTraining Accuracy 60.822% \tValidation Accuracy 58.600%\n",
      "Epoch: 1840 \tTraining Loss: 0.00651594 \tValidation Loss 0.00708048 \tTraining Accuracy 60.950% \tValidation Accuracy 58.952%\n",
      "Epoch: 1841 \tTraining Loss: 0.00652183 \tValidation Loss 0.00712681 \tTraining Accuracy 60.781% \tValidation Accuracy 59.233%\n",
      "Epoch: 1842 \tTraining Loss: 0.00652463 \tValidation Loss 0.00717317 \tTraining Accuracy 60.596% \tValidation Accuracy 59.057%\n",
      "Epoch: 1843 \tTraining Loss: 0.00651774 \tValidation Loss 0.00714027 \tTraining Accuracy 60.899% \tValidation Accuracy 59.198%\n",
      "Epoch: 1844 \tTraining Loss: 0.00652108 \tValidation Loss 0.00714086 \tTraining Accuracy 60.687% \tValidation Accuracy 59.304%\n",
      "Epoch: 1845 \tTraining Loss: 0.00652234 \tValidation Loss 0.00713381 \tTraining Accuracy 60.582% \tValidation Accuracy 58.389%\n",
      "Epoch: 1846 \tTraining Loss: 0.00651874 \tValidation Loss 0.00712678 \tTraining Accuracy 60.693% \tValidation Accuracy 59.585%\n",
      "Epoch: 1847 \tTraining Loss: 0.00651239 \tValidation Loss 0.00715834 \tTraining Accuracy 60.980% \tValidation Accuracy 60.007%\n",
      "Epoch: 1848 \tTraining Loss: 0.00651875 \tValidation Loss 0.00717386 \tTraining Accuracy 60.859% \tValidation Accuracy 58.706%\n",
      "Epoch: 1849 \tTraining Loss: 0.00652079 \tValidation Loss 0.00711222 \tTraining Accuracy 60.886% \tValidation Accuracy 59.198%\n",
      "Epoch: 1850 \tTraining Loss: 0.00651358 \tValidation Loss 0.00713874 \tTraining Accuracy 60.869% \tValidation Accuracy 58.776%\n",
      "Epoch: 1851 \tTraining Loss: 0.00651352 \tValidation Loss 0.00715221 \tTraining Accuracy 60.916% \tValidation Accuracy 58.741%\n",
      "Epoch: 1852 \tTraining Loss: 0.00651532 \tValidation Loss 0.00715626 \tTraining Accuracy 60.889% \tValidation Accuracy 59.655%\n",
      "Epoch: 1853 \tTraining Loss: 0.00651487 \tValidation Loss 0.00717283 \tTraining Accuracy 60.825% \tValidation Accuracy 59.479%\n",
      "Epoch: 1854 \tTraining Loss: 0.00650988 \tValidation Loss 0.00711794 \tTraining Accuracy 61.128% \tValidation Accuracy 59.444%\n",
      "Epoch: 1855 \tTraining Loss: 0.00651524 \tValidation Loss 0.00711430 \tTraining Accuracy 60.828% \tValidation Accuracy 59.866%\n",
      "Epoch: 1856 \tTraining Loss: 0.00651376 \tValidation Loss 0.00714494 \tTraining Accuracy 60.963% \tValidation Accuracy 59.479%\n",
      "Epoch: 1857 \tTraining Loss: 0.00651733 \tValidation Loss 0.00715075 \tTraining Accuracy 60.795% \tValidation Accuracy 58.495%\n",
      "Epoch: 1858 \tTraining Loss: 0.00651292 \tValidation Loss 0.00713133 \tTraining Accuracy 60.943% \tValidation Accuracy 59.093%\n",
      "Epoch: 1859 \tTraining Loss: 0.00651499 \tValidation Loss 0.00714534 \tTraining Accuracy 60.939% \tValidation Accuracy 58.881%\n",
      "Epoch: 1860 \tTraining Loss: 0.00651128 \tValidation Loss 0.00713797 \tTraining Accuracy 60.970% \tValidation Accuracy 59.620%\n",
      "Epoch: 1861 \tTraining Loss: 0.00650899 \tValidation Loss 0.00711479 \tTraining Accuracy 61.098% \tValidation Accuracy 59.515%\n",
      "Epoch: 1862 \tTraining Loss: 0.00651546 \tValidation Loss 0.00710813 \tTraining Accuracy 60.798% \tValidation Accuracy 59.374%\n",
      "Epoch: 1863 \tTraining Loss: 0.00650805 \tValidation Loss 0.00709841 \tTraining Accuracy 61.064% \tValidation Accuracy 59.726%\n",
      "Epoch: 1864 \tTraining Loss: 0.00650404 \tValidation Loss 0.00716186 \tTraining Accuracy 61.078% \tValidation Accuracy 58.741%\n",
      "Epoch: 1865 \tTraining Loss: 0.00650417 \tValidation Loss 0.00713786 \tTraining Accuracy 61.303% \tValidation Accuracy 59.198%\n",
      "Epoch: 1866 \tTraining Loss: 0.00650772 \tValidation Loss 0.00710896 \tTraining Accuracy 60.993% \tValidation Accuracy 59.831%\n",
      "Epoch: 1867 \tTraining Loss: 0.00650743 \tValidation Loss 0.00712954 \tTraining Accuracy 61.098% \tValidation Accuracy 59.128%\n",
      "Epoch: 1868 \tTraining Loss: 0.00651498 \tValidation Loss 0.00713316 \tTraining Accuracy 60.936% \tValidation Accuracy 59.022%\n",
      "Epoch: 1869 \tTraining Loss: 0.00650920 \tValidation Loss 0.00715191 \tTraining Accuracy 61.000% \tValidation Accuracy 59.233%\n",
      "Epoch: 1870 \tTraining Loss: 0.00651510 \tValidation Loss 0.00722151 \tTraining Accuracy 60.835% \tValidation Accuracy 58.706%\n",
      "Epoch: 1871 \tTraining Loss: 0.00651541 \tValidation Loss 0.00713991 \tTraining Accuracy 60.855% \tValidation Accuracy 59.444%\n",
      "Epoch: 1872 \tTraining Loss: 0.00650402 \tValidation Loss 0.00709101 \tTraining Accuracy 61.219% \tValidation Accuracy 58.987%\n",
      "Epoch: 1873 \tTraining Loss: 0.00650648 \tValidation Loss 0.00714697 \tTraining Accuracy 61.118% \tValidation Accuracy 59.409%\n",
      "Epoch: 1874 \tTraining Loss: 0.00650214 \tValidation Loss 0.00721018 \tTraining Accuracy 61.226% \tValidation Accuracy 58.530%\n",
      "Epoch: 1875 \tTraining Loss: 0.00651876 \tValidation Loss 0.00712218 \tTraining Accuracy 60.832% \tValidation Accuracy 59.937%\n",
      "Epoch: 1876 \tTraining Loss: 0.00650769 \tValidation Loss 0.00716758 \tTraining Accuracy 61.101% \tValidation Accuracy 58.706%\n",
      "Epoch: 1877 \tTraining Loss: 0.00650809 \tValidation Loss 0.00710448 \tTraining Accuracy 61.037% \tValidation Accuracy 59.866%\n",
      "Epoch: 1878 \tTraining Loss: 0.00650190 \tValidation Loss 0.00713581 \tTraining Accuracy 61.317% \tValidation Accuracy 60.007%\n",
      "Epoch: 1879 \tTraining Loss: 0.00650543 \tValidation Loss 0.00712819 \tTraining Accuracy 61.155% \tValidation Accuracy 59.233%\n",
      "Epoch: 1880 \tTraining Loss: 0.00650393 \tValidation Loss 0.00712751 \tTraining Accuracy 61.152% \tValidation Accuracy 59.198%\n",
      "Epoch: 1881 \tTraining Loss: 0.00650380 \tValidation Loss 0.00712192 \tTraining Accuracy 61.287% \tValidation Accuracy 59.339%\n",
      "Epoch: 1882 \tTraining Loss: 0.00650709 \tValidation Loss 0.00712174 \tTraining Accuracy 61.044% \tValidation Accuracy 58.776%\n",
      "Epoch: 1883 \tTraining Loss: 0.00650391 \tValidation Loss 0.00717780 \tTraining Accuracy 61.135% \tValidation Accuracy 58.635%\n",
      "Epoch: 1884 \tTraining Loss: 0.00650141 \tValidation Loss 0.00716552 \tTraining Accuracy 61.118% \tValidation Accuracy 58.917%\n",
      "Epoch: 1885 \tTraining Loss: 0.00650460 \tValidation Loss 0.00714021 \tTraining Accuracy 61.233% \tValidation Accuracy 58.917%\n",
      "Epoch: 1886 \tTraining Loss: 0.00650280 \tValidation Loss 0.00719198 \tTraining Accuracy 61.091% \tValidation Accuracy 59.409%\n",
      "Epoch: 1887 \tTraining Loss: 0.00650427 \tValidation Loss 0.00711163 \tTraining Accuracy 61.132% \tValidation Accuracy 58.495%\n",
      "Epoch: 1888 \tTraining Loss: 0.00650183 \tValidation Loss 0.00715332 \tTraining Accuracy 61.381% \tValidation Accuracy 58.811%\n",
      "Epoch: 1889 \tTraining Loss: 0.00650439 \tValidation Loss 0.00709749 \tTraining Accuracy 61.307% \tValidation Accuracy 59.620%\n",
      "Epoch: 1890 \tTraining Loss: 0.00650548 \tValidation Loss 0.00718811 \tTraining Accuracy 61.128% \tValidation Accuracy 58.917%\n",
      "Epoch: 1891 \tTraining Loss: 0.00649969 \tValidation Loss 0.00709981 \tTraining Accuracy 61.293% \tValidation Accuracy 59.198%\n",
      "Epoch: 1892 \tTraining Loss: 0.00650157 \tValidation Loss 0.00710395 \tTraining Accuracy 61.435% \tValidation Accuracy 59.866%\n",
      "Epoch: 1893 \tTraining Loss: 0.00649619 \tValidation Loss 0.00713035 \tTraining Accuracy 61.482% \tValidation Accuracy 58.706%\n",
      "Epoch: 1894 \tTraining Loss: 0.00649665 \tValidation Loss 0.00717988 \tTraining Accuracy 61.458% \tValidation Accuracy 59.233%\n",
      "Epoch: 1895 \tTraining Loss: 0.00650509 \tValidation Loss 0.00720063 \tTraining Accuracy 61.121% \tValidation Accuracy 59.093%\n",
      "Epoch: 1896 \tTraining Loss: 0.00650239 \tValidation Loss 0.00712091 \tTraining Accuracy 61.162% \tValidation Accuracy 58.952%\n",
      "Epoch: 1897 \tTraining Loss: 0.00649638 \tValidation Loss 0.00719706 \tTraining Accuracy 61.175% \tValidation Accuracy 58.178%\n",
      "Epoch: 1898 \tTraining Loss: 0.00650195 \tValidation Loss 0.00712433 \tTraining Accuracy 61.199% \tValidation Accuracy 59.479%\n",
      "Epoch: 1899 \tTraining Loss: 0.00648677 \tValidation Loss 0.00715290 \tTraining Accuracy 61.617% \tValidation Accuracy 59.304%\n",
      "Epoch: 1900 \tTraining Loss: 0.00649794 \tValidation Loss 0.00719165 \tTraining Accuracy 61.374% \tValidation Accuracy 59.093%\n",
      "Epoch: 1901 \tTraining Loss: 0.00649076 \tValidation Loss 0.00711144 \tTraining Accuracy 61.566% \tValidation Accuracy 60.218%\n",
      "Epoch: 1902 \tTraining Loss: 0.00649077 \tValidation Loss 0.00713223 \tTraining Accuracy 61.509% \tValidation Accuracy 59.022%\n",
      "Epoch: 1903 \tTraining Loss: 0.00649589 \tValidation Loss 0.00714475 \tTraining Accuracy 61.475% \tValidation Accuracy 59.902%\n",
      "Epoch: 1904 \tTraining Loss: 0.00650307 \tValidation Loss 0.00706867 \tTraining Accuracy 61.222% \tValidation Accuracy 59.831%\n",
      "Epoch: 1905 \tTraining Loss: 0.00649707 \tValidation Loss 0.00713464 \tTraining Accuracy 61.344% \tValidation Accuracy 59.304%\n",
      "Epoch: 1906 \tTraining Loss: 0.00649314 \tValidation Loss 0.00711856 \tTraining Accuracy 61.536% \tValidation Accuracy 59.093%\n",
      "Epoch: 1907 \tTraining Loss: 0.00649746 \tValidation Loss 0.00715917 \tTraining Accuracy 61.334% \tValidation Accuracy 59.093%\n",
      "Epoch: 1908 \tTraining Loss: 0.00649053 \tValidation Loss 0.00710903 \tTraining Accuracy 61.688% \tValidation Accuracy 59.374%\n",
      "Epoch: 1909 \tTraining Loss: 0.00649656 \tValidation Loss 0.00713691 \tTraining Accuracy 61.354% \tValidation Accuracy 58.846%\n",
      "Epoch: 1910 \tTraining Loss: 0.00648776 \tValidation Loss 0.00714651 \tTraining Accuracy 61.694% \tValidation Accuracy 60.218%\n",
      "Epoch: 1911 \tTraining Loss: 0.00648622 \tValidation Loss 0.00716877 \tTraining Accuracy 61.778% \tValidation Accuracy 58.635%\n",
      "Epoch: 1912 \tTraining Loss: 0.00648920 \tValidation Loss 0.00716677 \tTraining Accuracy 61.691% \tValidation Accuracy 59.937%\n",
      "Epoch: 1913 \tTraining Loss: 0.00649130 \tValidation Loss 0.00716889 \tTraining Accuracy 61.573% \tValidation Accuracy 59.128%\n",
      "Epoch: 1914 \tTraining Loss: 0.00648886 \tValidation Loss 0.00719585 \tTraining Accuracy 61.684% \tValidation Accuracy 58.108%\n",
      "Epoch: 1915 \tTraining Loss: 0.00648564 \tValidation Loss 0.00715647 \tTraining Accuracy 61.688% \tValidation Accuracy 59.022%\n",
      "Epoch: 1916 \tTraining Loss: 0.00649225 \tValidation Loss 0.00715199 \tTraining Accuracy 61.708% \tValidation Accuracy 58.213%\n",
      "Epoch: 1917 \tTraining Loss: 0.00648321 \tValidation Loss 0.00712031 \tTraining Accuracy 61.765% \tValidation Accuracy 60.429%\n",
      "Epoch: 1918 \tTraining Loss: 0.00649707 \tValidation Loss 0.00716242 \tTraining Accuracy 61.415% \tValidation Accuracy 58.706%\n",
      "Epoch: 1919 \tTraining Loss: 0.00649957 \tValidation Loss 0.00713023 \tTraining Accuracy 61.185% \tValidation Accuracy 59.022%\n",
      "Epoch: 1920 \tTraining Loss: 0.00648571 \tValidation Loss 0.00720145 \tTraining Accuracy 61.758% \tValidation Accuracy 58.530%\n",
      "Epoch: 1921 \tTraining Loss: 0.00649134 \tValidation Loss 0.00710529 \tTraining Accuracy 61.613% \tValidation Accuracy 59.479%\n",
      "Epoch: 1922 \tTraining Loss: 0.00649204 \tValidation Loss 0.00716758 \tTraining Accuracy 61.506% \tValidation Accuracy 59.233%\n",
      "Epoch: 1923 \tTraining Loss: 0.00649628 \tValidation Loss 0.00717895 \tTraining Accuracy 61.320% \tValidation Accuracy 58.354%\n",
      "Epoch: 1924 \tTraining Loss: 0.00648486 \tValidation Loss 0.00717759 \tTraining Accuracy 61.721% \tValidation Accuracy 58.600%\n",
      "Epoch: 1925 \tTraining Loss: 0.00648993 \tValidation Loss 0.00720125 \tTraining Accuracy 61.576% \tValidation Accuracy 58.284%\n",
      "Epoch: 1926 \tTraining Loss: 0.00648301 \tValidation Loss 0.00713344 \tTraining Accuracy 61.735% \tValidation Accuracy 58.389%\n",
      "Epoch: 1927 \tTraining Loss: 0.00648697 \tValidation Loss 0.00719350 \tTraining Accuracy 61.789% \tValidation Accuracy 58.002%\n",
      "Epoch: 1928 \tTraining Loss: 0.00648782 \tValidation Loss 0.00715341 \tTraining Accuracy 61.644% \tValidation Accuracy 59.831%\n",
      "Epoch: 1929 \tTraining Loss: 0.00648482 \tValidation Loss 0.00719562 \tTraining Accuracy 61.674% \tValidation Accuracy 57.756%\n",
      "Epoch: 1930 \tTraining Loss: 0.00648775 \tValidation Loss 0.00716367 \tTraining Accuracy 61.610% \tValidation Accuracy 58.459%\n",
      "Epoch: 1931 \tTraining Loss: 0.00649022 \tValidation Loss 0.00715167 \tTraining Accuracy 61.532% \tValidation Accuracy 58.530%\n",
      "Epoch: 1932 \tTraining Loss: 0.00648505 \tValidation Loss 0.00716742 \tTraining Accuracy 61.607% \tValidation Accuracy 59.831%\n",
      "Epoch: 1933 \tTraining Loss: 0.00648801 \tValidation Loss 0.00711980 \tTraining Accuracy 61.637% \tValidation Accuracy 58.811%\n",
      "Epoch: 1934 \tTraining Loss: 0.00648056 \tValidation Loss 0.00717004 \tTraining Accuracy 61.903% \tValidation Accuracy 59.093%\n",
      "Epoch: 1935 \tTraining Loss: 0.00648260 \tValidation Loss 0.00715190 \tTraining Accuracy 61.704% \tValidation Accuracy 59.057%\n",
      "Epoch: 1936 \tTraining Loss: 0.00647678 \tValidation Loss 0.00715002 \tTraining Accuracy 61.957% \tValidation Accuracy 58.846%\n",
      "Epoch: 1937 \tTraining Loss: 0.00649010 \tValidation Loss 0.00719206 \tTraining Accuracy 61.580% \tValidation Accuracy 59.339%\n",
      "Epoch: 1938 \tTraining Loss: 0.00647877 \tValidation Loss 0.00717946 \tTraining Accuracy 61.923% \tValidation Accuracy 59.409%\n",
      "Epoch: 1939 \tTraining Loss: 0.00648090 \tValidation Loss 0.00715872 \tTraining Accuracy 61.805% \tValidation Accuracy 59.866%\n",
      "Epoch: 1940 \tTraining Loss: 0.00647417 \tValidation Loss 0.00720292 \tTraining Accuracy 61.920% \tValidation Accuracy 57.615%\n",
      "Epoch: 1941 \tTraining Loss: 0.00647422 \tValidation Loss 0.00715013 \tTraining Accuracy 61.981% \tValidation Accuracy 59.444%\n",
      "Epoch: 1942 \tTraining Loss: 0.00647787 \tValidation Loss 0.00713415 \tTraining Accuracy 61.964% \tValidation Accuracy 58.284%\n",
      "Epoch: 1943 \tTraining Loss: 0.00647912 \tValidation Loss 0.00714248 \tTraining Accuracy 61.853% \tValidation Accuracy 60.007%\n",
      "Epoch: 1944 \tTraining Loss: 0.00648753 \tValidation Loss 0.00709820 \tTraining Accuracy 61.755% \tValidation Accuracy 59.304%\n",
      "Epoch: 1945 \tTraining Loss: 0.00648908 \tValidation Loss 0.00714030 \tTraining Accuracy 61.559% \tValidation Accuracy 59.093%\n",
      "Epoch: 1946 \tTraining Loss: 0.00647161 \tValidation Loss 0.00713405 \tTraining Accuracy 62.018% \tValidation Accuracy 59.374%\n",
      "Epoch: 1947 \tTraining Loss: 0.00647859 \tValidation Loss 0.00716239 \tTraining Accuracy 61.907% \tValidation Accuracy 59.093%\n",
      "Epoch: 1948 \tTraining Loss: 0.00648187 \tValidation Loss 0.00713507 \tTraining Accuracy 61.816% \tValidation Accuracy 59.866%\n",
      "Epoch: 1949 \tTraining Loss: 0.00647811 \tValidation Loss 0.00712950 \tTraining Accuracy 61.873% \tValidation Accuracy 59.057%\n",
      "Epoch: 1950 \tTraining Loss: 0.00647114 \tValidation Loss 0.00711440 \tTraining Accuracy 62.122% \tValidation Accuracy 60.113%\n",
      "Epoch: 1951 \tTraining Loss: 0.00647971 \tValidation Loss 0.00718334 \tTraining Accuracy 61.907% \tValidation Accuracy 58.776%\n",
      "Epoch: 1952 \tTraining Loss: 0.00647228 \tValidation Loss 0.00712508 \tTraining Accuracy 62.173% \tValidation Accuracy 58.706%\n",
      "Epoch: 1953 \tTraining Loss: 0.00647494 \tValidation Loss 0.00710547 \tTraining Accuracy 61.893% \tValidation Accuracy 59.761%\n",
      "Epoch: 1954 \tTraining Loss: 0.00647974 \tValidation Loss 0.00714714 \tTraining Accuracy 61.809% \tValidation Accuracy 59.479%\n",
      "Epoch: 1955 \tTraining Loss: 0.00647263 \tValidation Loss 0.00717387 \tTraining Accuracy 62.065% \tValidation Accuracy 57.861%\n",
      "Epoch: 1956 \tTraining Loss: 0.00647674 \tValidation Loss 0.00717610 \tTraining Accuracy 61.923% \tValidation Accuracy 58.741%\n",
      "Epoch: 1957 \tTraining Loss: 0.00647275 \tValidation Loss 0.00715547 \tTraining Accuracy 62.001% \tValidation Accuracy 58.248%\n",
      "Epoch: 1958 \tTraining Loss: 0.00647751 \tValidation Loss 0.00714360 \tTraining Accuracy 62.014% \tValidation Accuracy 58.917%\n",
      "Epoch: 1959 \tTraining Loss: 0.00647305 \tValidation Loss 0.00711901 \tTraining Accuracy 61.991% \tValidation Accuracy 59.585%\n",
      "Epoch: 1960 \tTraining Loss: 0.00646799 \tValidation Loss 0.00715362 \tTraining Accuracy 62.243% \tValidation Accuracy 59.022%\n",
      "Epoch: 1961 \tTraining Loss: 0.00646139 \tValidation Loss 0.00718206 \tTraining Accuracy 62.425% \tValidation Accuracy 58.952%\n",
      "Epoch: 1962 \tTraining Loss: 0.00647053 \tValidation Loss 0.00713867 \tTraining Accuracy 62.078% \tValidation Accuracy 58.670%\n",
      "Epoch: 1963 \tTraining Loss: 0.00648070 \tValidation Loss 0.00713096 \tTraining Accuracy 61.805% \tValidation Accuracy 59.093%\n",
      "Epoch: 1964 \tTraining Loss: 0.00647470 \tValidation Loss 0.00710309 \tTraining Accuracy 62.088% \tValidation Accuracy 59.339%\n",
      "Epoch: 1965 \tTraining Loss: 0.00646462 \tValidation Loss 0.00715274 \tTraining Accuracy 62.173% \tValidation Accuracy 58.530%\n",
      "Epoch: 1966 \tTraining Loss: 0.00647659 \tValidation Loss 0.00717249 \tTraining Accuracy 61.910% \tValidation Accuracy 58.881%\n",
      "Epoch: 1967 \tTraining Loss: 0.00647452 \tValidation Loss 0.00718005 \tTraining Accuracy 62.035% \tValidation Accuracy 58.917%\n",
      "Epoch: 1968 \tTraining Loss: 0.00646746 \tValidation Loss 0.00713754 \tTraining Accuracy 62.082% \tValidation Accuracy 58.741%\n",
      "Epoch: 1969 \tTraining Loss: 0.00647521 \tValidation Loss 0.00715687 \tTraining Accuracy 61.960% \tValidation Accuracy 58.776%\n",
      "Epoch: 1970 \tTraining Loss: 0.00646334 \tValidation Loss 0.00717252 \tTraining Accuracy 62.314% \tValidation Accuracy 58.811%\n",
      "Epoch: 1971 \tTraining Loss: 0.00646409 \tValidation Loss 0.00711765 \tTraining Accuracy 62.402% \tValidation Accuracy 59.268%\n",
      "Epoch: 1972 \tTraining Loss: 0.00646028 \tValidation Loss 0.00711196 \tTraining Accuracy 62.341% \tValidation Accuracy 59.057%\n",
      "Epoch: 1973 \tTraining Loss: 0.00647053 \tValidation Loss 0.00717075 \tTraining Accuracy 62.186% \tValidation Accuracy 58.917%\n",
      "Epoch: 1974 \tTraining Loss: 0.00646480 \tValidation Loss 0.00719168 \tTraining Accuracy 62.254% \tValidation Accuracy 57.826%\n",
      "Epoch: 1975 \tTraining Loss: 0.00645969 \tValidation Loss 0.00716852 \tTraining Accuracy 62.523% \tValidation Accuracy 59.620%\n",
      "Epoch: 1976 \tTraining Loss: 0.00646312 \tValidation Loss 0.00712249 \tTraining Accuracy 62.459% \tValidation Accuracy 58.811%\n",
      "Epoch: 1977 \tTraining Loss: 0.00646197 \tValidation Loss 0.00712957 \tTraining Accuracy 62.385% \tValidation Accuracy 58.741%\n",
      "Epoch: 1978 \tTraining Loss: 0.00646872 \tValidation Loss 0.00724112 \tTraining Accuracy 62.126% \tValidation Accuracy 58.565%\n",
      "Epoch: 1979 \tTraining Loss: 0.00646341 \tValidation Loss 0.00717741 \tTraining Accuracy 62.463% \tValidation Accuracy 58.143%\n",
      "Epoch: 1980 \tTraining Loss: 0.00645306 \tValidation Loss 0.00719121 \tTraining Accuracy 62.624% \tValidation Accuracy 58.670%\n",
      "Epoch: 1981 \tTraining Loss: 0.00646117 \tValidation Loss 0.00714741 \tTraining Accuracy 62.361% \tValidation Accuracy 59.339%\n",
      "Epoch: 1982 \tTraining Loss: 0.00646868 \tValidation Loss 0.00713438 \tTraining Accuracy 62.095% \tValidation Accuracy 58.776%\n",
      "Epoch: 1983 \tTraining Loss: 0.00647014 \tValidation Loss 0.00714855 \tTraining Accuracy 61.994% \tValidation Accuracy 58.072%\n",
      "Epoch: 1984 \tTraining Loss: 0.00645603 \tValidation Loss 0.00713346 \tTraining Accuracy 62.543% \tValidation Accuracy 59.304%\n",
      "Epoch: 1985 \tTraining Loss: 0.00646298 \tValidation Loss 0.00720840 \tTraining Accuracy 62.237% \tValidation Accuracy 59.198%\n",
      "Epoch: 1986 \tTraining Loss: 0.00646528 \tValidation Loss 0.00716600 \tTraining Accuracy 62.331% \tValidation Accuracy 58.284%\n",
      "Epoch: 1987 \tTraining Loss: 0.00646009 \tValidation Loss 0.00718316 \tTraining Accuracy 62.577% \tValidation Accuracy 59.093%\n",
      "Epoch: 1988 \tTraining Loss: 0.00645749 \tValidation Loss 0.00715896 \tTraining Accuracy 62.341% \tValidation Accuracy 59.515%\n",
      "Epoch: 1989 \tTraining Loss: 0.00646175 \tValidation Loss 0.00715700 \tTraining Accuracy 62.321% \tValidation Accuracy 58.670%\n",
      "Epoch: 1990 \tTraining Loss: 0.00646320 \tValidation Loss 0.00714865 \tTraining Accuracy 62.331% \tValidation Accuracy 60.148%\n",
      "Epoch: 1991 \tTraining Loss: 0.00645393 \tValidation Loss 0.00710942 \tTraining Accuracy 62.634% \tValidation Accuracy 59.515%\n",
      "Epoch: 1992 \tTraining Loss: 0.00646373 \tValidation Loss 0.00711592 \tTraining Accuracy 62.334% \tValidation Accuracy 58.424%\n",
      "Epoch: 1993 \tTraining Loss: 0.00646614 \tValidation Loss 0.00714270 \tTraining Accuracy 62.092% \tValidation Accuracy 59.057%\n",
      "Epoch: 1994 \tTraining Loss: 0.00646232 \tValidation Loss 0.00715018 \tTraining Accuracy 62.304% \tValidation Accuracy 58.846%\n",
      "Epoch: 1995 \tTraining Loss: 0.00645295 \tValidation Loss 0.00717201 \tTraining Accuracy 62.577% \tValidation Accuracy 59.479%\n",
      "Epoch: 1996 \tTraining Loss: 0.00646090 \tValidation Loss 0.00717286 \tTraining Accuracy 62.402% \tValidation Accuracy 59.198%\n",
      "Epoch: 1997 \tTraining Loss: 0.00645784 \tValidation Loss 0.00712946 \tTraining Accuracy 62.422% \tValidation Accuracy 59.233%\n",
      "Epoch: 1998 \tTraining Loss: 0.00645960 \tValidation Loss 0.00718248 \tTraining Accuracy 62.493% \tValidation Accuracy 58.284%\n",
      "Epoch: 1999 \tTraining Loss: 0.00645109 \tValidation Loss 0.00716729 \tTraining Accuracy 62.641% \tValidation Accuracy 59.022%\n",
      "Epoch: 2000 \tTraining Loss: 0.00645670 \tValidation Loss 0.00716559 \tTraining Accuracy 62.591% \tValidation Accuracy 58.811%\n",
      "Epoch: 2001 \tTraining Loss: 0.00645669 \tValidation Loss 0.00717287 \tTraining Accuracy 62.483% \tValidation Accuracy 58.846%\n",
      "Epoch: 2002 \tTraining Loss: 0.00645692 \tValidation Loss 0.00718024 \tTraining Accuracy 62.348% \tValidation Accuracy 58.037%\n",
      "Epoch: 2003 \tTraining Loss: 0.00645545 \tValidation Loss 0.00717965 \tTraining Accuracy 62.334% \tValidation Accuracy 58.846%\n",
      "Epoch: 2004 \tTraining Loss: 0.00645108 \tValidation Loss 0.00714690 \tTraining Accuracy 62.661% \tValidation Accuracy 58.565%\n",
      "Epoch: 2005 \tTraining Loss: 0.00645027 \tValidation Loss 0.00712184 \tTraining Accuracy 62.675% \tValidation Accuracy 58.635%\n",
      "Epoch: 2006 \tTraining Loss: 0.00645701 \tValidation Loss 0.00713863 \tTraining Accuracy 62.436% \tValidation Accuracy 59.022%\n",
      "Epoch: 2007 \tTraining Loss: 0.00645565 \tValidation Loss 0.00718548 \tTraining Accuracy 62.527% \tValidation Accuracy 59.233%\n",
      "Epoch: 2008 \tTraining Loss: 0.00645620 \tValidation Loss 0.00717315 \tTraining Accuracy 62.452% \tValidation Accuracy 58.530%\n",
      "Epoch: 2009 \tTraining Loss: 0.00644689 \tValidation Loss 0.00712279 \tTraining Accuracy 62.857% \tValidation Accuracy 59.972%\n",
      "Epoch: 2010 \tTraining Loss: 0.00645044 \tValidation Loss 0.00714974 \tTraining Accuracy 62.671% \tValidation Accuracy 58.987%\n",
      "Epoch: 2011 \tTraining Loss: 0.00645326 \tValidation Loss 0.00716762 \tTraining Accuracy 62.523% \tValidation Accuracy 58.600%\n",
      "Epoch: 2012 \tTraining Loss: 0.00644629 \tValidation Loss 0.00710022 \tTraining Accuracy 62.732% \tValidation Accuracy 59.304%\n",
      "Epoch: 2013 \tTraining Loss: 0.00644446 \tValidation Loss 0.00712281 \tTraining Accuracy 62.833% \tValidation Accuracy 59.163%\n",
      "Epoch: 2014 \tTraining Loss: 0.00645313 \tValidation Loss 0.00714057 \tTraining Accuracy 62.493% \tValidation Accuracy 59.163%\n",
      "Epoch: 2015 \tTraining Loss: 0.00645494 \tValidation Loss 0.00711873 \tTraining Accuracy 62.601% \tValidation Accuracy 59.655%\n",
      "Epoch: 2016 \tTraining Loss: 0.00645044 \tValidation Loss 0.00710500 \tTraining Accuracy 62.698% \tValidation Accuracy 59.444%\n",
      "Epoch: 2017 \tTraining Loss: 0.00644927 \tValidation Loss 0.00714157 \tTraining Accuracy 62.810% \tValidation Accuracy 59.128%\n",
      "Epoch: 2018 \tTraining Loss: 0.00645218 \tValidation Loss 0.00712707 \tTraining Accuracy 62.587% \tValidation Accuracy 59.374%\n",
      "Epoch: 2019 \tTraining Loss: 0.00643506 \tValidation Loss 0.00713756 \tTraining Accuracy 63.069% \tValidation Accuracy 59.831%\n",
      "Epoch: 2020 \tTraining Loss: 0.00644948 \tValidation Loss 0.00710684 \tTraining Accuracy 62.729% \tValidation Accuracy 60.429%\n",
      "Epoch: 2021 \tTraining Loss: 0.00644227 \tValidation Loss 0.00711376 \tTraining Accuracy 63.052% \tValidation Accuracy 59.022%\n",
      "Epoch: 2022 \tTraining Loss: 0.00644810 \tValidation Loss 0.00713618 \tTraining Accuracy 62.725% \tValidation Accuracy 58.495%\n",
      "Epoch: 2023 \tTraining Loss: 0.00645115 \tValidation Loss 0.00710313 \tTraining Accuracy 62.665% \tValidation Accuracy 59.339%\n",
      "Epoch: 2024 \tTraining Loss: 0.00644959 \tValidation Loss 0.00714349 \tTraining Accuracy 62.756% \tValidation Accuracy 58.846%\n",
      "Epoch: 2025 \tTraining Loss: 0.00643743 \tValidation Loss 0.00711497 \tTraining Accuracy 62.867% \tValidation Accuracy 59.620%\n",
      "Epoch: 2026 \tTraining Loss: 0.00645020 \tValidation Loss 0.00720352 \tTraining Accuracy 62.719% \tValidation Accuracy 59.057%\n",
      "Epoch: 2027 \tTraining Loss: 0.00644479 \tValidation Loss 0.00713070 \tTraining Accuracy 62.793% \tValidation Accuracy 58.635%\n",
      "Epoch: 2028 \tTraining Loss: 0.00644293 \tValidation Loss 0.00710471 \tTraining Accuracy 62.759% \tValidation Accuracy 59.022%\n",
      "Epoch: 2029 \tTraining Loss: 0.00644717 \tValidation Loss 0.00718170 \tTraining Accuracy 62.725% \tValidation Accuracy 58.776%\n",
      "Epoch: 2030 \tTraining Loss: 0.00644304 \tValidation Loss 0.00719737 \tTraining Accuracy 62.867% \tValidation Accuracy 58.635%\n",
      "Epoch: 2031 \tTraining Loss: 0.00643994 \tValidation Loss 0.00708964 \tTraining Accuracy 62.914% \tValidation Accuracy 58.917%\n",
      "Epoch: 2032 \tTraining Loss: 0.00643709 \tValidation Loss 0.00714395 \tTraining Accuracy 62.904% \tValidation Accuracy 58.846%\n",
      "Epoch: 2033 \tTraining Loss: 0.00644551 \tValidation Loss 0.00710556 \tTraining Accuracy 62.725% \tValidation Accuracy 59.585%\n",
      "Epoch: 2034 \tTraining Loss: 0.00643607 \tValidation Loss 0.00715160 \tTraining Accuracy 63.200% \tValidation Accuracy 58.389%\n",
      "Epoch: 2035 \tTraining Loss: 0.00643565 \tValidation Loss 0.00709826 \tTraining Accuracy 62.998% \tValidation Accuracy 59.093%\n",
      "Epoch: 2036 \tTraining Loss: 0.00643641 \tValidation Loss 0.00714667 \tTraining Accuracy 63.045% \tValidation Accuracy 59.409%\n",
      "Epoch: 2037 \tTraining Loss: 0.00643722 \tValidation Loss 0.00712021 \tTraining Accuracy 63.002% \tValidation Accuracy 59.796%\n",
      "Epoch: 2038 \tTraining Loss: 0.00644482 \tValidation Loss 0.00709348 \tTraining Accuracy 62.894% \tValidation Accuracy 60.042%\n",
      "Epoch: 2039 \tTraining Loss: 0.00643425 \tValidation Loss 0.00718961 \tTraining Accuracy 63.227% \tValidation Accuracy 59.057%\n",
      "Epoch: 2040 \tTraining Loss: 0.00644392 \tValidation Loss 0.00710585 \tTraining Accuracy 62.833% \tValidation Accuracy 59.796%\n",
      "Epoch: 2041 \tTraining Loss: 0.00643438 \tValidation Loss 0.00719597 \tTraining Accuracy 63.045% \tValidation Accuracy 59.268%\n",
      "Epoch: 2042 \tTraining Loss: 0.00645218 \tValidation Loss 0.00714257 \tTraining Accuracy 62.624% \tValidation Accuracy 59.726%\n",
      "Epoch: 2043 \tTraining Loss: 0.00643318 \tValidation Loss 0.00712146 \tTraining Accuracy 63.089% \tValidation Accuracy 59.339%\n",
      "Epoch: 2044 \tTraining Loss: 0.00642828 \tValidation Loss 0.00710212 \tTraining Accuracy 63.281% \tValidation Accuracy 59.620%\n",
      "Epoch: 2045 \tTraining Loss: 0.00643730 \tValidation Loss 0.00714474 \tTraining Accuracy 62.894% \tValidation Accuracy 59.515%\n",
      "Epoch: 2046 \tTraining Loss: 0.00644267 \tValidation Loss 0.00709385 \tTraining Accuracy 62.722% \tValidation Accuracy 59.479%\n",
      "Epoch: 2047 \tTraining Loss: 0.00642990 \tValidation Loss 0.00714920 \tTraining Accuracy 63.352% \tValidation Accuracy 58.530%\n",
      "Epoch: 2048 \tTraining Loss: 0.00642971 \tValidation Loss 0.00712165 \tTraining Accuracy 63.288% \tValidation Accuracy 59.093%\n",
      "Epoch: 2049 \tTraining Loss: 0.00643546 \tValidation Loss 0.00715684 \tTraining Accuracy 63.056% \tValidation Accuracy 58.741%\n",
      "Epoch: 2050 \tTraining Loss: 0.00644038 \tValidation Loss 0.00718906 \tTraining Accuracy 62.874% \tValidation Accuracy 59.057%\n",
      "Epoch: 2051 \tTraining Loss: 0.00643385 \tValidation Loss 0.00717699 \tTraining Accuracy 63.069% \tValidation Accuracy 58.635%\n",
      "Epoch: 2052 \tTraining Loss: 0.00643864 \tValidation Loss 0.00709322 \tTraining Accuracy 62.924% \tValidation Accuracy 59.057%\n",
      "Epoch: 2053 \tTraining Loss: 0.00643221 \tValidation Loss 0.00713343 \tTraining Accuracy 63.238% \tValidation Accuracy 59.726%\n",
      "Epoch: 2054 \tTraining Loss: 0.00643363 \tValidation Loss 0.00714949 \tTraining Accuracy 63.069% \tValidation Accuracy 58.670%\n",
      "Epoch: 2055 \tTraining Loss: 0.00644133 \tValidation Loss 0.00712692 \tTraining Accuracy 62.789% \tValidation Accuracy 60.324%\n",
      "Epoch: 2056 \tTraining Loss: 0.00642908 \tValidation Loss 0.00716004 \tTraining Accuracy 63.349% \tValidation Accuracy 59.057%\n",
      "Epoch: 2057 \tTraining Loss: 0.00643300 \tValidation Loss 0.00712219 \tTraining Accuracy 63.133% \tValidation Accuracy 59.268%\n",
      "Epoch: 2058 \tTraining Loss: 0.00642137 \tValidation Loss 0.00711009 \tTraining Accuracy 63.416% \tValidation Accuracy 59.057%\n",
      "Epoch: 2059 \tTraining Loss: 0.00642569 \tValidation Loss 0.00713699 \tTraining Accuracy 63.224% \tValidation Accuracy 59.550%\n",
      "Epoch: 2060 \tTraining Loss: 0.00642497 \tValidation Loss 0.00716050 \tTraining Accuracy 63.453% \tValidation Accuracy 58.495%\n",
      "Epoch: 2061 \tTraining Loss: 0.00643266 \tValidation Loss 0.00710488 \tTraining Accuracy 63.106% \tValidation Accuracy 59.761%\n",
      "Epoch: 2062 \tTraining Loss: 0.00642636 \tValidation Loss 0.00714891 \tTraining Accuracy 63.217% \tValidation Accuracy 57.967%\n",
      "Epoch: 2063 \tTraining Loss: 0.00643080 \tValidation Loss 0.00714430 \tTraining Accuracy 63.136% \tValidation Accuracy 59.374%\n",
      "Epoch: 2064 \tTraining Loss: 0.00642726 \tValidation Loss 0.00712872 \tTraining Accuracy 63.291% \tValidation Accuracy 58.037%\n",
      "Epoch: 2065 \tTraining Loss: 0.00642759 \tValidation Loss 0.00709794 \tTraining Accuracy 63.261% \tValidation Accuracy 59.761%\n",
      "Epoch: 2066 \tTraining Loss: 0.00644060 \tValidation Loss 0.00712477 \tTraining Accuracy 63.002% \tValidation Accuracy 59.726%\n",
      "Epoch: 2067 \tTraining Loss: 0.00643686 \tValidation Loss 0.00714001 \tTraining Accuracy 63.059% \tValidation Accuracy 59.866%\n",
      "Epoch: 2068 \tTraining Loss: 0.00642742 \tValidation Loss 0.00712894 \tTraining Accuracy 63.298% \tValidation Accuracy 59.902%\n",
      "Epoch: 2069 \tTraining Loss: 0.00642789 \tValidation Loss 0.00717034 \tTraining Accuracy 63.369% \tValidation Accuracy 59.761%\n",
      "Epoch: 2070 \tTraining Loss: 0.00643020 \tValidation Loss 0.00708925 \tTraining Accuracy 63.207% \tValidation Accuracy 58.987%\n",
      "Epoch: 2071 \tTraining Loss: 0.00642949 \tValidation Loss 0.00716897 \tTraining Accuracy 63.258% \tValidation Accuracy 59.057%\n",
      "Epoch: 2072 \tTraining Loss: 0.00642850 \tValidation Loss 0.00714559 \tTraining Accuracy 63.305% \tValidation Accuracy 58.846%\n",
      "Epoch: 2073 \tTraining Loss: 0.00642877 \tValidation Loss 0.00715414 \tTraining Accuracy 63.329% \tValidation Accuracy 59.831%\n",
      "Epoch: 2074 \tTraining Loss: 0.00642896 \tValidation Loss 0.00712180 \tTraining Accuracy 63.160% \tValidation Accuracy 59.761%\n",
      "Epoch: 2075 \tTraining Loss: 0.00643248 \tValidation Loss 0.00711979 \tTraining Accuracy 63.076% \tValidation Accuracy 59.409%\n",
      "Epoch: 2076 \tTraining Loss: 0.00641422 \tValidation Loss 0.00712978 \tTraining Accuracy 63.608% \tValidation Accuracy 58.846%\n",
      "Epoch: 2077 \tTraining Loss: 0.00642766 \tValidation Loss 0.00717260 \tTraining Accuracy 63.369% \tValidation Accuracy 59.198%\n",
      "Epoch: 2078 \tTraining Loss: 0.00641948 \tValidation Loss 0.00715420 \tTraining Accuracy 63.514% \tValidation Accuracy 59.515%\n",
      "Epoch: 2079 \tTraining Loss: 0.00641959 \tValidation Loss 0.00712058 \tTraining Accuracy 63.554% \tValidation Accuracy 59.831%\n",
      "Epoch: 2080 \tTraining Loss: 0.00642532 \tValidation Loss 0.00718275 \tTraining Accuracy 63.329% \tValidation Accuracy 58.459%\n",
      "Epoch: 2081 \tTraining Loss: 0.00642021 \tValidation Loss 0.00711618 \tTraining Accuracy 63.548% \tValidation Accuracy 60.324%\n",
      "Epoch: 2082 \tTraining Loss: 0.00643421 \tValidation Loss 0.00715173 \tTraining Accuracy 63.069% \tValidation Accuracy 59.268%\n",
      "Epoch: 2083 \tTraining Loss: 0.00641138 \tValidation Loss 0.00713488 \tTraining Accuracy 63.709% \tValidation Accuracy 59.620%\n",
      "Epoch: 2084 \tTraining Loss: 0.00641940 \tValidation Loss 0.00708568 \tTraining Accuracy 63.473% \tValidation Accuracy 60.042%\n",
      "Epoch: 2085 \tTraining Loss: 0.00642257 \tValidation Loss 0.00714877 \tTraining Accuracy 63.403% \tValidation Accuracy 59.198%\n",
      "Epoch: 2086 \tTraining Loss: 0.00642274 \tValidation Loss 0.00712868 \tTraining Accuracy 63.433% \tValidation Accuracy 59.198%\n",
      "Epoch: 2087 \tTraining Loss: 0.00641800 \tValidation Loss 0.00716665 \tTraining Accuracy 63.595% \tValidation Accuracy 58.846%\n",
      "Epoch: 2088 \tTraining Loss: 0.00641712 \tValidation Loss 0.00711893 \tTraining Accuracy 63.595% \tValidation Accuracy 59.655%\n",
      "Epoch: 2089 \tTraining Loss: 0.00641968 \tValidation Loss 0.00711524 \tTraining Accuracy 63.450% \tValidation Accuracy 60.077%\n",
      "Epoch: 2090 \tTraining Loss: 0.00641413 \tValidation Loss 0.00713893 \tTraining Accuracy 63.780% \tValidation Accuracy 59.409%\n",
      "Epoch: 2091 \tTraining Loss: 0.00641626 \tValidation Loss 0.00713739 \tTraining Accuracy 63.564% \tValidation Accuracy 58.917%\n",
      "Epoch: 2092 \tTraining Loss: 0.00642216 \tValidation Loss 0.00717363 \tTraining Accuracy 63.355% \tValidation Accuracy 60.007%\n",
      "Epoch: 2093 \tTraining Loss: 0.00642221 \tValidation Loss 0.00714417 \tTraining Accuracy 63.551% \tValidation Accuracy 59.972%\n",
      "Epoch: 2094 \tTraining Loss: 0.00642208 \tValidation Loss 0.00713981 \tTraining Accuracy 63.308% \tValidation Accuracy 58.917%\n",
      "Epoch: 2095 \tTraining Loss: 0.00641905 \tValidation Loss 0.00714633 \tTraining Accuracy 63.433% \tValidation Accuracy 59.163%\n",
      "Epoch: 2096 \tTraining Loss: 0.00641161 \tValidation Loss 0.00715676 \tTraining Accuracy 63.682% \tValidation Accuracy 59.515%\n",
      "Epoch: 2097 \tTraining Loss: 0.00642759 \tValidation Loss 0.00718892 \tTraining Accuracy 63.231% \tValidation Accuracy 58.741%\n",
      "Epoch: 2098 \tTraining Loss: 0.00641564 \tValidation Loss 0.00709411 \tTraining Accuracy 63.453% \tValidation Accuracy 59.093%\n",
      "Epoch: 2099 \tTraining Loss: 0.00640999 \tValidation Loss 0.00711884 \tTraining Accuracy 63.787% \tValidation Accuracy 59.937%\n",
      "Epoch: 2100 \tTraining Loss: 0.00641645 \tValidation Loss 0.00713078 \tTraining Accuracy 63.564% \tValidation Accuracy 58.741%\n",
      "Epoch: 2101 \tTraining Loss: 0.00641995 \tValidation Loss 0.00712295 \tTraining Accuracy 63.477% \tValidation Accuracy 59.374%\n",
      "Epoch: 2102 \tTraining Loss: 0.00641921 \tValidation Loss 0.00714114 \tTraining Accuracy 63.571% \tValidation Accuracy 58.143%\n",
      "Epoch: 2103 \tTraining Loss: 0.00641297 \tValidation Loss 0.00711823 \tTraining Accuracy 63.605% \tValidation Accuracy 59.620%\n",
      "Epoch: 2104 \tTraining Loss: 0.00640693 \tValidation Loss 0.00712050 \tTraining Accuracy 63.750% \tValidation Accuracy 60.077%\n",
      "Epoch: 2105 \tTraining Loss: 0.00641579 \tValidation Loss 0.00712455 \tTraining Accuracy 63.558% \tValidation Accuracy 59.761%\n",
      "Epoch: 2106 \tTraining Loss: 0.00642337 \tValidation Loss 0.00714098 \tTraining Accuracy 63.315% \tValidation Accuracy 59.339%\n",
      "Epoch: 2107 \tTraining Loss: 0.00641640 \tValidation Loss 0.00709572 \tTraining Accuracy 63.487% \tValidation Accuracy 59.550%\n",
      "Epoch: 2108 \tTraining Loss: 0.00641327 \tValidation Loss 0.00712933 \tTraining Accuracy 63.692% \tValidation Accuracy 59.339%\n",
      "Epoch: 2109 \tTraining Loss: 0.00641374 \tValidation Loss 0.00709924 \tTraining Accuracy 63.517% \tValidation Accuracy 59.409%\n",
      "Epoch: 2110 \tTraining Loss: 0.00641252 \tValidation Loss 0.00712640 \tTraining Accuracy 63.827% \tValidation Accuracy 58.600%\n",
      "Epoch: 2111 \tTraining Loss: 0.00640853 \tValidation Loss 0.00719401 \tTraining Accuracy 63.878% \tValidation Accuracy 58.741%\n",
      "Epoch: 2112 \tTraining Loss: 0.00641397 \tValidation Loss 0.00716582 \tTraining Accuracy 63.612% \tValidation Accuracy 59.409%\n",
      "Epoch: 2113 \tTraining Loss: 0.00641214 \tValidation Loss 0.00709796 \tTraining Accuracy 63.729% \tValidation Accuracy 58.776%\n",
      "Epoch: 2114 \tTraining Loss: 0.00641161 \tValidation Loss 0.00706443 \tTraining Accuracy 63.767% \tValidation Accuracy 60.324%\n",
      "Epoch: 2115 \tTraining Loss: 0.00640488 \tValidation Loss 0.00711579 \tTraining Accuracy 63.871% \tValidation Accuracy 60.253%\n",
      "Epoch: 2116 \tTraining Loss: 0.00640416 \tValidation Loss 0.00709254 \tTraining Accuracy 64.043% \tValidation Accuracy 59.304%\n",
      "Epoch: 2117 \tTraining Loss: 0.00640867 \tValidation Loss 0.00710211 \tTraining Accuracy 63.763% \tValidation Accuracy 60.183%\n",
      "Epoch: 2118 \tTraining Loss: 0.00640412 \tValidation Loss 0.00716369 \tTraining Accuracy 63.854% \tValidation Accuracy 59.479%\n",
      "Epoch: 2119 \tTraining Loss: 0.00641707 \tValidation Loss 0.00711833 \tTraining Accuracy 63.628% \tValidation Accuracy 59.198%\n",
      "Epoch: 2120 \tTraining Loss: 0.00640045 \tValidation Loss 0.00716878 \tTraining Accuracy 64.026% \tValidation Accuracy 59.972%\n",
      "Epoch: 2121 \tTraining Loss: 0.00640566 \tValidation Loss 0.00716304 \tTraining Accuracy 63.841% \tValidation Accuracy 59.550%\n",
      "Epoch: 2122 \tTraining Loss: 0.00640710 \tValidation Loss 0.00717099 \tTraining Accuracy 63.975% \tValidation Accuracy 59.374%\n",
      "Epoch: 2123 \tTraining Loss: 0.00640937 \tValidation Loss 0.00711742 \tTraining Accuracy 63.760% \tValidation Accuracy 58.635%\n",
      "Epoch: 2124 \tTraining Loss: 0.00640102 \tValidation Loss 0.00715187 \tTraining Accuracy 64.009% \tValidation Accuracy 59.128%\n",
      "Epoch: 2125 \tTraining Loss: 0.00640491 \tValidation Loss 0.00709215 \tTraining Accuracy 63.834% \tValidation Accuracy 60.007%\n",
      "Epoch: 2126 \tTraining Loss: 0.00640731 \tValidation Loss 0.00715534 \tTraining Accuracy 63.854% \tValidation Accuracy 59.690%\n",
      "Epoch: 2127 \tTraining Loss: 0.00640607 \tValidation Loss 0.00710778 \tTraining Accuracy 63.858% \tValidation Accuracy 59.479%\n",
      "Epoch: 2128 \tTraining Loss: 0.00639919 \tValidation Loss 0.00709225 \tTraining Accuracy 64.073% \tValidation Accuracy 59.444%\n",
      "Epoch: 2129 \tTraining Loss: 0.00641795 \tValidation Loss 0.00714060 \tTraining Accuracy 63.544% \tValidation Accuracy 58.811%\n",
      "Epoch: 2130 \tTraining Loss: 0.00639854 \tValidation Loss 0.00708260 \tTraining Accuracy 64.134% \tValidation Accuracy 60.253%\n",
      "Epoch: 2131 \tTraining Loss: 0.00640022 \tValidation Loss 0.00711980 \tTraining Accuracy 63.871% \tValidation Accuracy 60.535%\n",
      "Epoch: 2132 \tTraining Loss: 0.00640528 \tValidation Loss 0.00714060 \tTraining Accuracy 63.918% \tValidation Accuracy 58.776%\n",
      "Epoch: 2133 \tTraining Loss: 0.00641065 \tValidation Loss 0.00711294 \tTraining Accuracy 63.615% \tValidation Accuracy 59.655%\n",
      "Epoch: 2134 \tTraining Loss: 0.00639475 \tValidation Loss 0.00716581 \tTraining Accuracy 64.188% \tValidation Accuracy 58.354%\n",
      "Epoch: 2135 \tTraining Loss: 0.00640618 \tValidation Loss 0.00710150 \tTraining Accuracy 63.804% \tValidation Accuracy 59.233%\n",
      "Epoch: 2136 \tTraining Loss: 0.00641197 \tValidation Loss 0.00714545 \tTraining Accuracy 63.679% \tValidation Accuracy 59.268%\n",
      "Epoch: 2137 \tTraining Loss: 0.00639977 \tValidation Loss 0.00708724 \tTraining Accuracy 64.009% \tValidation Accuracy 58.917%\n",
      "Epoch: 2138 \tTraining Loss: 0.00640595 \tValidation Loss 0.00713699 \tTraining Accuracy 63.858% \tValidation Accuracy 59.444%\n",
      "Epoch: 2139 \tTraining Loss: 0.00640047 \tValidation Loss 0.00714288 \tTraining Accuracy 63.911% \tValidation Accuracy 59.620%\n",
      "Epoch: 2140 \tTraining Loss: 0.00639781 \tValidation Loss 0.00712737 \tTraining Accuracy 64.070% \tValidation Accuracy 59.515%\n",
      "Epoch: 2141 \tTraining Loss: 0.00639549 \tValidation Loss 0.00715472 \tTraining Accuracy 64.161% \tValidation Accuracy 59.796%\n",
      "Epoch: 2142 \tTraining Loss: 0.00640381 \tValidation Loss 0.00714673 \tTraining Accuracy 63.908% \tValidation Accuracy 59.550%\n",
      "Epoch: 2143 \tTraining Loss: 0.00640128 \tValidation Loss 0.00709744 \tTraining Accuracy 63.992% \tValidation Accuracy 59.761%\n",
      "Epoch: 2144 \tTraining Loss: 0.00640019 \tValidation Loss 0.00707632 \tTraining Accuracy 63.952% \tValidation Accuracy 60.851%\n",
      "Epoch: 2145 \tTraining Loss: 0.00641660 \tValidation Loss 0.00712460 \tTraining Accuracy 63.564% \tValidation Accuracy 59.268%\n",
      "Epoch: 2146 \tTraining Loss: 0.00639702 \tValidation Loss 0.00716758 \tTraining Accuracy 64.151% \tValidation Accuracy 58.706%\n",
      "Epoch: 2147 \tTraining Loss: 0.00639877 \tValidation Loss 0.00713878 \tTraining Accuracy 63.952% \tValidation Accuracy 59.339%\n",
      "Epoch: 2148 \tTraining Loss: 0.00640923 \tValidation Loss 0.00715219 \tTraining Accuracy 63.659% \tValidation Accuracy 59.866%\n",
      "Epoch: 2149 \tTraining Loss: 0.00640307 \tValidation Loss 0.00709157 \tTraining Accuracy 63.854% \tValidation Accuracy 59.304%\n",
      "Epoch: 2150 \tTraining Loss: 0.00640609 \tValidation Loss 0.00713058 \tTraining Accuracy 63.874% \tValidation Accuracy 60.007%\n",
      "Epoch: 2151 \tTraining Loss: 0.00639950 \tValidation Loss 0.00710792 \tTraining Accuracy 64.023% \tValidation Accuracy 59.374%\n",
      "Epoch: 2152 \tTraining Loss: 0.00639187 \tValidation Loss 0.00719149 \tTraining Accuracy 64.255% \tValidation Accuracy 59.655%\n",
      "Epoch: 2153 \tTraining Loss: 0.00639152 \tValidation Loss 0.00714712 \tTraining Accuracy 64.259% \tValidation Accuracy 60.007%\n",
      "Epoch: 2154 \tTraining Loss: 0.00638997 \tValidation Loss 0.00709348 \tTraining Accuracy 64.289% \tValidation Accuracy 59.339%\n",
      "Epoch: 2155 \tTraining Loss: 0.00639622 \tValidation Loss 0.00715337 \tTraining Accuracy 64.039% \tValidation Accuracy 59.339%\n",
      "Epoch: 2156 \tTraining Loss: 0.00639817 \tValidation Loss 0.00711853 \tTraining Accuracy 64.019% \tValidation Accuracy 60.570%\n",
      "Epoch: 2157 \tTraining Loss: 0.00639108 \tValidation Loss 0.00710793 \tTraining Accuracy 64.272% \tValidation Accuracy 59.937%\n",
      "Epoch: 2158 \tTraining Loss: 0.00639001 \tValidation Loss 0.00715248 \tTraining Accuracy 64.312% \tValidation Accuracy 59.585%\n",
      "Epoch: 2159 \tTraining Loss: 0.00639203 \tValidation Loss 0.00705778 \tTraining Accuracy 64.215% \tValidation Accuracy 60.394%\n",
      "Epoch: 2160 \tTraining Loss: 0.00639225 \tValidation Loss 0.00714508 \tTraining Accuracy 64.208% \tValidation Accuracy 59.304%\n",
      "Epoch: 2161 \tTraining Loss: 0.00639377 \tValidation Loss 0.00710479 \tTraining Accuracy 64.336% \tValidation Accuracy 59.374%\n",
      "Epoch: 2162 \tTraining Loss: 0.00640640 \tValidation Loss 0.00715982 \tTraining Accuracy 63.689% \tValidation Accuracy 59.409%\n",
      "Epoch: 2163 \tTraining Loss: 0.00639114 \tValidation Loss 0.00712621 \tTraining Accuracy 64.279% \tValidation Accuracy 59.690%\n",
      "Epoch: 2164 \tTraining Loss: 0.00638761 \tValidation Loss 0.00713333 \tTraining Accuracy 64.356% \tValidation Accuracy 58.811%\n",
      "Epoch: 2165 \tTraining Loss: 0.00639150 \tValidation Loss 0.00715148 \tTraining Accuracy 64.272% \tValidation Accuracy 59.128%\n",
      "Epoch: 2166 \tTraining Loss: 0.00639627 \tValidation Loss 0.00710215 \tTraining Accuracy 64.141% \tValidation Accuracy 60.394%\n",
      "Epoch: 2167 \tTraining Loss: 0.00639172 \tValidation Loss 0.00715533 \tTraining Accuracy 64.188% \tValidation Accuracy 58.635%\n",
      "Epoch: 2168 \tTraining Loss: 0.00638351 \tValidation Loss 0.00705931 \tTraining Accuracy 64.504% \tValidation Accuracy 60.183%\n",
      "Epoch: 2169 \tTraining Loss: 0.00638543 \tValidation Loss 0.00708682 \tTraining Accuracy 64.461% \tValidation Accuracy 59.479%\n",
      "Epoch: 2170 \tTraining Loss: 0.00639859 \tValidation Loss 0.00709177 \tTraining Accuracy 63.851% \tValidation Accuracy 60.218%\n",
      "Epoch: 2171 \tTraining Loss: 0.00638256 \tValidation Loss 0.00706515 \tTraining Accuracy 64.484% \tValidation Accuracy 60.113%\n",
      "Epoch: 2172 \tTraining Loss: 0.00638367 \tValidation Loss 0.00719137 \tTraining Accuracy 64.528% \tValidation Accuracy 59.233%\n",
      "Epoch: 2173 \tTraining Loss: 0.00639202 \tValidation Loss 0.00710037 \tTraining Accuracy 64.198% \tValidation Accuracy 59.796%\n",
      "Epoch: 2174 \tTraining Loss: 0.00639529 \tValidation Loss 0.00714734 \tTraining Accuracy 64.026% \tValidation Accuracy 59.726%\n",
      "Epoch: 2175 \tTraining Loss: 0.00638738 \tValidation Loss 0.00708879 \tTraining Accuracy 64.272% \tValidation Accuracy 60.148%\n",
      "Epoch: 2176 \tTraining Loss: 0.00638651 \tValidation Loss 0.00709644 \tTraining Accuracy 64.285% \tValidation Accuracy 59.409%\n",
      "Epoch: 2177 \tTraining Loss: 0.00638802 \tValidation Loss 0.00709407 \tTraining Accuracy 64.221% \tValidation Accuracy 58.706%\n",
      "Epoch: 2178 \tTraining Loss: 0.00638760 \tValidation Loss 0.00711119 \tTraining Accuracy 64.272% \tValidation Accuracy 59.902%\n",
      "Epoch: 2179 \tTraining Loss: 0.00638526 \tValidation Loss 0.00714072 \tTraining Accuracy 64.319% \tValidation Accuracy 59.620%\n",
      "Epoch: 2180 \tTraining Loss: 0.00639215 \tValidation Loss 0.00715091 \tTraining Accuracy 64.151% \tValidation Accuracy 59.690%\n",
      "Epoch: 2181 \tTraining Loss: 0.00639633 \tValidation Loss 0.00713035 \tTraining Accuracy 64.093% \tValidation Accuracy 59.972%\n",
      "Epoch: 2182 \tTraining Loss: 0.00637921 \tValidation Loss 0.00713315 \tTraining Accuracy 64.686% \tValidation Accuracy 59.902%\n",
      "Epoch: 2183 \tTraining Loss: 0.00638506 \tValidation Loss 0.00707919 \tTraining Accuracy 64.339% \tValidation Accuracy 59.866%\n",
      "Epoch: 2184 \tTraining Loss: 0.00639063 \tValidation Loss 0.00707870 \tTraining Accuracy 64.194% \tValidation Accuracy 60.218%\n",
      "Epoch: 2185 \tTraining Loss: 0.00639100 \tValidation Loss 0.00714383 \tTraining Accuracy 64.228% \tValidation Accuracy 59.515%\n",
      "Epoch: 2186 \tTraining Loss: 0.00638083 \tValidation Loss 0.00714215 \tTraining Accuracy 64.494% \tValidation Accuracy 59.796%\n",
      "Epoch: 2187 \tTraining Loss: 0.00637819 \tValidation Loss 0.00711952 \tTraining Accuracy 64.622% \tValidation Accuracy 59.198%\n",
      "Epoch: 2188 \tTraining Loss: 0.00638936 \tValidation Loss 0.00706262 \tTraining Accuracy 64.403% \tValidation Accuracy 60.535%\n",
      "Epoch: 2189 \tTraining Loss: 0.00638871 \tValidation Loss 0.00712333 \tTraining Accuracy 64.184% \tValidation Accuracy 59.233%\n",
      "Epoch: 2190 \tTraining Loss: 0.00638738 \tValidation Loss 0.00712473 \tTraining Accuracy 64.302% \tValidation Accuracy 59.902%\n",
      "Epoch: 2191 \tTraining Loss: 0.00638564 \tValidation Loss 0.00711354 \tTraining Accuracy 64.494% \tValidation Accuracy 59.374%\n",
      "Epoch: 2192 \tTraining Loss: 0.00638778 \tValidation Loss 0.00711915 \tTraining Accuracy 64.339% \tValidation Accuracy 60.253%\n",
      "Epoch: 2193 \tTraining Loss: 0.00638562 \tValidation Loss 0.00713173 \tTraining Accuracy 64.326% \tValidation Accuracy 58.670%\n",
      "Epoch: 2194 \tTraining Loss: 0.00638555 \tValidation Loss 0.00711016 \tTraining Accuracy 64.498% \tValidation Accuracy 59.655%\n",
      "Epoch: 2195 \tTraining Loss: 0.00638229 \tValidation Loss 0.00712357 \tTraining Accuracy 64.531% \tValidation Accuracy 58.600%\n",
      "Epoch: 2196 \tTraining Loss: 0.00637762 \tValidation Loss 0.00711517 \tTraining Accuracy 64.592% \tValidation Accuracy 60.183%\n",
      "Epoch: 2197 \tTraining Loss: 0.00639024 \tValidation Loss 0.00708937 \tTraining Accuracy 64.316% \tValidation Accuracy 60.288%\n",
      "Epoch: 2198 \tTraining Loss: 0.00637855 \tValidation Loss 0.00714353 \tTraining Accuracy 64.552% \tValidation Accuracy 58.459%\n",
      "Epoch: 2199 \tTraining Loss: 0.00638299 \tValidation Loss 0.00713462 \tTraining Accuracy 64.488% \tValidation Accuracy 59.515%\n",
      "Epoch: 2200 \tTraining Loss: 0.00638106 \tValidation Loss 0.00710679 \tTraining Accuracy 64.525% \tValidation Accuracy 59.620%\n",
      "Epoch: 2201 \tTraining Loss: 0.00637689 \tValidation Loss 0.00710509 \tTraining Accuracy 64.639% \tValidation Accuracy 60.570%\n",
      "Epoch: 2202 \tTraining Loss: 0.00638473 \tValidation Loss 0.00718106 \tTraining Accuracy 64.383% \tValidation Accuracy 59.093%\n",
      "Epoch: 2203 \tTraining Loss: 0.00637269 \tValidation Loss 0.00709809 \tTraining Accuracy 64.882% \tValidation Accuracy 60.570%\n",
      "Epoch: 2204 \tTraining Loss: 0.00638766 \tValidation Loss 0.00708805 \tTraining Accuracy 64.221% \tValidation Accuracy 58.881%\n",
      "Epoch: 2205 \tTraining Loss: 0.00638132 \tValidation Loss 0.00706109 \tTraining Accuracy 64.319% \tValidation Accuracy 60.535%\n",
      "Epoch: 2206 \tTraining Loss: 0.00638656 \tValidation Loss 0.00711875 \tTraining Accuracy 64.316% \tValidation Accuracy 59.902%\n",
      "Epoch: 2207 \tTraining Loss: 0.00637606 \tValidation Loss 0.00715750 \tTraining Accuracy 64.619% \tValidation Accuracy 59.550%\n",
      "Epoch: 2208 \tTraining Loss: 0.00637423 \tValidation Loss 0.00710819 \tTraining Accuracy 64.724% \tValidation Accuracy 60.113%\n",
      "Epoch: 2209 \tTraining Loss: 0.00637615 \tValidation Loss 0.00714162 \tTraining Accuracy 64.649% \tValidation Accuracy 59.550%\n",
      "Epoch: 2210 \tTraining Loss: 0.00637072 \tValidation Loss 0.00712066 \tTraining Accuracy 64.845% \tValidation Accuracy 59.515%\n",
      "Epoch: 2211 \tTraining Loss: 0.00637925 \tValidation Loss 0.00712454 \tTraining Accuracy 64.387% \tValidation Accuracy 59.550%\n",
      "Epoch: 2212 \tTraining Loss: 0.00638071 \tValidation Loss 0.00708422 \tTraining Accuracy 64.491% \tValidation Accuracy 59.620%\n",
      "Epoch: 2213 \tTraining Loss: 0.00637439 \tValidation Loss 0.00712070 \tTraining Accuracy 64.747% \tValidation Accuracy 59.304%\n",
      "Epoch: 2214 \tTraining Loss: 0.00637153 \tValidation Loss 0.00713861 \tTraining Accuracy 64.643% \tValidation Accuracy 60.007%\n",
      "Epoch: 2215 \tTraining Loss: 0.00637122 \tValidation Loss 0.00711649 \tTraining Accuracy 64.831% \tValidation Accuracy 60.113%\n",
      "Epoch: 2216 \tTraining Loss: 0.00637632 \tValidation Loss 0.00706009 \tTraining Accuracy 64.582% \tValidation Accuracy 60.640%\n",
      "Epoch: 2217 \tTraining Loss: 0.00637345 \tValidation Loss 0.00715649 \tTraining Accuracy 64.700% \tValidation Accuracy 59.233%\n",
      "Epoch: 2218 \tTraining Loss: 0.00638066 \tValidation Loss 0.00710833 \tTraining Accuracy 64.504% \tValidation Accuracy 60.148%\n",
      "Epoch: 2219 \tTraining Loss: 0.00637416 \tValidation Loss 0.00710795 \tTraining Accuracy 64.676% \tValidation Accuracy 59.585%\n",
      "Epoch: 2220 \tTraining Loss: 0.00636867 \tValidation Loss 0.00713807 \tTraining Accuracy 64.943% \tValidation Accuracy 60.253%\n",
      "Epoch: 2221 \tTraining Loss: 0.00636437 \tValidation Loss 0.00707216 \tTraining Accuracy 64.865% \tValidation Accuracy 60.992%\n",
      "Epoch: 2222 \tTraining Loss: 0.00636841 \tValidation Loss 0.00716298 \tTraining Accuracy 64.767% \tValidation Accuracy 58.881%\n",
      "Epoch: 2223 \tTraining Loss: 0.00637772 \tValidation Loss 0.00712888 \tTraining Accuracy 64.629% \tValidation Accuracy 60.253%\n",
      "Epoch: 2224 \tTraining Loss: 0.00637418 \tValidation Loss 0.00708702 \tTraining Accuracy 64.771% \tValidation Accuracy 59.620%\n",
      "Epoch: 2225 \tTraining Loss: 0.00637122 \tValidation Loss 0.00710216 \tTraining Accuracy 64.794% \tValidation Accuracy 59.655%\n",
      "Epoch: 2226 \tTraining Loss: 0.00637048 \tValidation Loss 0.00714659 \tTraining Accuracy 64.781% \tValidation Accuracy 58.952%\n",
      "Epoch: 2227 \tTraining Loss: 0.00637492 \tValidation Loss 0.00707720 \tTraining Accuracy 64.646% \tValidation Accuracy 58.987%\n",
      "Epoch: 2228 \tTraining Loss: 0.00636790 \tValidation Loss 0.00713085 \tTraining Accuracy 64.767% \tValidation Accuracy 61.168%\n",
      "Epoch: 2229 \tTraining Loss: 0.00637291 \tValidation Loss 0.00711934 \tTraining Accuracy 64.774% \tValidation Accuracy 60.042%\n",
      "Epoch: 2230 \tTraining Loss: 0.00637975 \tValidation Loss 0.00711739 \tTraining Accuracy 64.478% \tValidation Accuracy 59.550%\n",
      "Epoch: 2231 \tTraining Loss: 0.00637868 \tValidation Loss 0.00707092 \tTraining Accuracy 64.478% \tValidation Accuracy 60.464%\n",
      "Epoch: 2232 \tTraining Loss: 0.00636592 \tValidation Loss 0.00712705 \tTraining Accuracy 64.959% \tValidation Accuracy 59.515%\n",
      "Epoch: 2233 \tTraining Loss: 0.00637139 \tValidation Loss 0.00713502 \tTraining Accuracy 64.693% \tValidation Accuracy 59.304%\n",
      "Epoch: 2234 \tTraining Loss: 0.00636957 \tValidation Loss 0.00713051 \tTraining Accuracy 64.798% \tValidation Accuracy 59.374%\n",
      "Epoch: 2235 \tTraining Loss: 0.00637170 \tValidation Loss 0.00710803 \tTraining Accuracy 64.666% \tValidation Accuracy 60.042%\n",
      "Epoch: 2236 \tTraining Loss: 0.00635957 \tValidation Loss 0.00716654 \tTraining Accuracy 65.182% \tValidation Accuracy 59.479%\n",
      "Epoch: 2237 \tTraining Loss: 0.00636533 \tValidation Loss 0.00706469 \tTraining Accuracy 64.916% \tValidation Accuracy 59.866%\n",
      "Epoch: 2238 \tTraining Loss: 0.00636427 \tValidation Loss 0.00706047 \tTraining Accuracy 65.098% \tValidation Accuracy 60.851%\n",
      "Epoch: 2239 \tTraining Loss: 0.00636384 \tValidation Loss 0.00710799 \tTraining Accuracy 65.020% \tValidation Accuracy 60.218%\n",
      "Epoch: 2240 \tTraining Loss: 0.00636345 \tValidation Loss 0.00714487 \tTraining Accuracy 65.118% \tValidation Accuracy 59.550%\n",
      "Epoch: 2241 \tTraining Loss: 0.00636885 \tValidation Loss 0.00713118 \tTraining Accuracy 64.791% \tValidation Accuracy 60.113%\n",
      "Epoch: 2242 \tTraining Loss: 0.00636728 \tValidation Loss 0.00710191 \tTraining Accuracy 64.673% \tValidation Accuracy 60.746%\n",
      "Epoch: 2243 \tTraining Loss: 0.00636848 \tValidation Loss 0.00709237 \tTraining Accuracy 64.902% \tValidation Accuracy 59.866%\n",
      "Epoch: 2244 \tTraining Loss: 0.00636569 \tValidation Loss 0.00708288 \tTraining Accuracy 64.939% \tValidation Accuracy 60.394%\n",
      "Epoch: 2245 \tTraining Loss: 0.00636461 \tValidation Loss 0.00705698 \tTraining Accuracy 65.071% \tValidation Accuracy 60.464%\n",
      "Epoch: 2246 \tTraining Loss: 0.00636263 \tValidation Loss 0.00715350 \tTraining Accuracy 65.098% \tValidation Accuracy 59.057%\n",
      "Epoch: 2247 \tTraining Loss: 0.00636711 \tValidation Loss 0.00708133 \tTraining Accuracy 64.936% \tValidation Accuracy 59.831%\n",
      "Epoch: 2248 \tTraining Loss: 0.00636775 \tValidation Loss 0.00711205 \tTraining Accuracy 64.801% \tValidation Accuracy 59.057%\n",
      "Epoch: 2249 \tTraining Loss: 0.00636272 \tValidation Loss 0.00712011 \tTraining Accuracy 64.983% \tValidation Accuracy 59.304%\n",
      "Epoch: 2250 \tTraining Loss: 0.00636865 \tValidation Loss 0.00710085 \tTraining Accuracy 64.815% \tValidation Accuracy 60.007%\n",
      "Epoch: 2251 \tTraining Loss: 0.00636268 \tValidation Loss 0.00709196 \tTraining Accuracy 65.007% \tValidation Accuracy 59.620%\n",
      "Epoch: 2252 \tTraining Loss: 0.00636705 \tValidation Loss 0.00703535 \tTraining Accuracy 64.905% \tValidation Accuracy 60.218%\n",
      "Epoch: 2253 \tTraining Loss: 0.00636024 \tValidation Loss 0.00712231 \tTraining Accuracy 64.970% \tValidation Accuracy 59.761%\n",
      "Epoch: 2254 \tTraining Loss: 0.00636092 \tValidation Loss 0.00710558 \tTraining Accuracy 65.071% \tValidation Accuracy 59.620%\n",
      "Epoch: 2255 \tTraining Loss: 0.00636240 \tValidation Loss 0.00704640 \tTraining Accuracy 64.986% \tValidation Accuracy 60.605%\n",
      "Epoch: 2256 \tTraining Loss: 0.00636097 \tValidation Loss 0.00714878 \tTraining Accuracy 64.885% \tValidation Accuracy 59.374%\n",
      "Epoch: 2257 \tTraining Loss: 0.00636615 \tValidation Loss 0.00713867 \tTraining Accuracy 64.865% \tValidation Accuracy 60.148%\n",
      "Epoch: 2258 \tTraining Loss: 0.00636285 \tValidation Loss 0.00707677 \tTraining Accuracy 64.956% \tValidation Accuracy 58.741%\n",
      "Epoch: 2259 \tTraining Loss: 0.00635498 \tValidation Loss 0.00712156 \tTraining Accuracy 65.317% \tValidation Accuracy 59.515%\n",
      "Epoch: 2260 \tTraining Loss: 0.00635864 \tValidation Loss 0.00708162 \tTraining Accuracy 65.168% \tValidation Accuracy 60.464%\n",
      "Epoch: 2261 \tTraining Loss: 0.00635428 \tValidation Loss 0.00710633 \tTraining Accuracy 65.222% \tValidation Accuracy 59.690%\n",
      "Epoch: 2262 \tTraining Loss: 0.00636074 \tValidation Loss 0.00712124 \tTraining Accuracy 65.263% \tValidation Accuracy 60.148%\n",
      "Epoch: 2263 \tTraining Loss: 0.00636204 \tValidation Loss 0.00704937 \tTraining Accuracy 64.956% \tValidation Accuracy 59.866%\n",
      "Epoch: 2264 \tTraining Loss: 0.00635911 \tValidation Loss 0.00710715 \tTraining Accuracy 65.131% \tValidation Accuracy 60.253%\n",
      "Epoch: 2265 \tTraining Loss: 0.00636637 \tValidation Loss 0.00713669 \tTraining Accuracy 64.949% \tValidation Accuracy 59.726%\n",
      "Epoch: 2266 \tTraining Loss: 0.00636001 \tValidation Loss 0.00712464 \tTraining Accuracy 65.064% \tValidation Accuracy 59.726%\n",
      "Epoch: 2267 \tTraining Loss: 0.00635953 \tValidation Loss 0.00707726 \tTraining Accuracy 65.017% \tValidation Accuracy 60.851%\n",
      "Epoch: 2268 \tTraining Loss: 0.00635925 \tValidation Loss 0.00707930 \tTraining Accuracy 65.074% \tValidation Accuracy 59.726%\n",
      "Epoch: 2269 \tTraining Loss: 0.00635979 \tValidation Loss 0.00712992 \tTraining Accuracy 65.064% \tValidation Accuracy 59.515%\n",
      "Epoch: 2270 \tTraining Loss: 0.00635797 \tValidation Loss 0.00712055 \tTraining Accuracy 65.074% \tValidation Accuracy 58.811%\n",
      "Epoch: 2271 \tTraining Loss: 0.00635955 \tValidation Loss 0.00705815 \tTraining Accuracy 65.034% \tValidation Accuracy 61.660%\n",
      "Epoch: 2272 \tTraining Loss: 0.00636391 \tValidation Loss 0.00713977 \tTraining Accuracy 64.976% \tValidation Accuracy 58.600%\n",
      "Epoch: 2273 \tTraining Loss: 0.00636135 \tValidation Loss 0.00711639 \tTraining Accuracy 65.121% \tValidation Accuracy 59.268%\n",
      "Epoch: 2274 \tTraining Loss: 0.00634979 \tValidation Loss 0.00705555 \tTraining Accuracy 65.404% \tValidation Accuracy 61.062%\n",
      "Epoch: 2275 \tTraining Loss: 0.00635978 \tValidation Loss 0.00712064 \tTraining Accuracy 65.074% \tValidation Accuracy 60.675%\n",
      "Epoch: 2276 \tTraining Loss: 0.00635461 \tValidation Loss 0.00715179 \tTraining Accuracy 65.232% \tValidation Accuracy 59.374%\n",
      "Epoch: 2277 \tTraining Loss: 0.00635318 \tValidation Loss 0.00705495 \tTraining Accuracy 65.303% \tValidation Accuracy 60.957%\n",
      "Epoch: 2278 \tTraining Loss: 0.00635379 \tValidation Loss 0.00716725 \tTraining Accuracy 65.148% \tValidation Accuracy 59.198%\n",
      "Epoch: 2279 \tTraining Loss: 0.00635299 \tValidation Loss 0.00707979 \tTraining Accuracy 65.178% \tValidation Accuracy 61.097%\n",
      "Epoch: 2280 \tTraining Loss: 0.00635072 \tValidation Loss 0.00706753 \tTraining Accuracy 65.317% \tValidation Accuracy 59.866%\n",
      "Epoch: 2281 \tTraining Loss: 0.00636508 \tValidation Loss 0.00710152 \tTraining Accuracy 64.922% \tValidation Accuracy 60.816%\n",
      "Epoch: 2282 \tTraining Loss: 0.00635000 \tValidation Loss 0.00709273 \tTraining Accuracy 65.249% \tValidation Accuracy 58.776%\n",
      "Epoch: 2283 \tTraining Loss: 0.00635754 \tValidation Loss 0.00711506 \tTraining Accuracy 65.054% \tValidation Accuracy 60.499%\n",
      "Epoch: 2284 \tTraining Loss: 0.00634786 \tValidation Loss 0.00712645 \tTraining Accuracy 65.408% \tValidation Accuracy 60.042%\n",
      "Epoch: 2285 \tTraining Loss: 0.00635561 \tValidation Loss 0.00710012 \tTraining Accuracy 65.091% \tValidation Accuracy 59.585%\n",
      "Epoch: 2286 \tTraining Loss: 0.00634709 \tValidation Loss 0.00703050 \tTraining Accuracy 65.435% \tValidation Accuracy 60.359%\n",
      "Epoch: 2287 \tTraining Loss: 0.00634821 \tValidation Loss 0.00710925 \tTraining Accuracy 65.435% \tValidation Accuracy 59.163%\n",
      "Epoch: 2288 \tTraining Loss: 0.00634906 \tValidation Loss 0.00708257 \tTraining Accuracy 65.455% \tValidation Accuracy 60.359%\n",
      "Epoch: 2289 \tTraining Loss: 0.00636182 \tValidation Loss 0.00711304 \tTraining Accuracy 64.845% \tValidation Accuracy 60.042%\n",
      "Epoch: 2290 \tTraining Loss: 0.00635583 \tValidation Loss 0.00710334 \tTraining Accuracy 65.182% \tValidation Accuracy 60.359%\n",
      "Epoch: 2291 \tTraining Loss: 0.00634048 \tValidation Loss 0.00710033 \tTraining Accuracy 65.563% \tValidation Accuracy 60.007%\n",
      "Epoch: 2292 \tTraining Loss: 0.00635136 \tValidation Loss 0.00708598 \tTraining Accuracy 65.246% \tValidation Accuracy 60.113%\n",
      "Epoch: 2293 \tTraining Loss: 0.00635220 \tValidation Loss 0.00708226 \tTraining Accuracy 65.209% \tValidation Accuracy 60.605%\n",
      "Epoch: 2294 \tTraining Loss: 0.00635048 \tValidation Loss 0.00710526 \tTraining Accuracy 65.259% \tValidation Accuracy 59.937%\n",
      "Epoch: 2295 \tTraining Loss: 0.00635524 \tValidation Loss 0.00704227 \tTraining Accuracy 65.151% \tValidation Accuracy 60.886%\n",
      "Epoch: 2296 \tTraining Loss: 0.00635165 \tValidation Loss 0.00706837 \tTraining Accuracy 65.280% \tValidation Accuracy 60.218%\n",
      "Epoch: 2297 \tTraining Loss: 0.00634207 \tValidation Loss 0.00709403 \tTraining Accuracy 65.424% \tValidation Accuracy 60.148%\n",
      "Epoch: 2298 \tTraining Loss: 0.00634373 \tValidation Loss 0.00709467 \tTraining Accuracy 65.428% \tValidation Accuracy 60.042%\n",
      "Epoch: 2299 \tTraining Loss: 0.00634731 \tValidation Loss 0.00707986 \tTraining Accuracy 65.499% \tValidation Accuracy 60.781%\n",
      "Epoch: 2300 \tTraining Loss: 0.00634506 \tValidation Loss 0.00708072 \tTraining Accuracy 65.381% \tValidation Accuracy 60.570%\n",
      "Epoch: 2301 \tTraining Loss: 0.00634587 \tValidation Loss 0.00707597 \tTraining Accuracy 65.256% \tValidation Accuracy 59.515%\n",
      "Epoch: 2302 \tTraining Loss: 0.00634021 \tValidation Loss 0.00706090 \tTraining Accuracy 65.647% \tValidation Accuracy 60.605%\n",
      "Epoch: 2303 \tTraining Loss: 0.00634217 \tValidation Loss 0.00710727 \tTraining Accuracy 65.448% \tValidation Accuracy 60.077%\n",
      "Epoch: 2304 \tTraining Loss: 0.00633975 \tValidation Loss 0.00711777 \tTraining Accuracy 65.573% \tValidation Accuracy 60.922%\n",
      "Epoch: 2305 \tTraining Loss: 0.00635414 \tValidation Loss 0.00706491 \tTraining Accuracy 65.128% \tValidation Accuracy 60.324%\n",
      "Epoch: 2306 \tTraining Loss: 0.00634402 \tValidation Loss 0.00708950 \tTraining Accuracy 65.482% \tValidation Accuracy 60.077%\n",
      "Epoch: 2307 \tTraining Loss: 0.00634469 \tValidation Loss 0.00706300 \tTraining Accuracy 65.499% \tValidation Accuracy 60.394%\n",
      "Epoch: 2308 \tTraining Loss: 0.00634670 \tValidation Loss 0.00710295 \tTraining Accuracy 65.381% \tValidation Accuracy 60.148%\n",
      "Epoch: 2309 \tTraining Loss: 0.00633898 \tValidation Loss 0.00710401 \tTraining Accuracy 65.680% \tValidation Accuracy 60.535%\n",
      "Epoch: 2310 \tTraining Loss: 0.00633542 \tValidation Loss 0.00715426 \tTraining Accuracy 65.792% \tValidation Accuracy 59.937%\n",
      "Epoch: 2311 \tTraining Loss: 0.00634492 \tValidation Loss 0.00704338 \tTraining Accuracy 65.421% \tValidation Accuracy 61.308%\n",
      "Epoch: 2312 \tTraining Loss: 0.00634101 \tValidation Loss 0.00711483 \tTraining Accuracy 65.435% \tValidation Accuracy 59.268%\n",
      "Epoch: 2313 \tTraining Loss: 0.00634451 \tValidation Loss 0.00707394 \tTraining Accuracy 65.455% \tValidation Accuracy 60.429%\n",
      "Epoch: 2314 \tTraining Loss: 0.00634303 \tValidation Loss 0.00711132 \tTraining Accuracy 65.552% \tValidation Accuracy 59.726%\n",
      "Epoch: 2315 \tTraining Loss: 0.00634049 \tValidation Loss 0.00708940 \tTraining Accuracy 65.549% \tValidation Accuracy 61.977%\n",
      "Epoch: 2316 \tTraining Loss: 0.00634398 \tValidation Loss 0.00710427 \tTraining Accuracy 65.519% \tValidation Accuracy 59.304%\n",
      "Epoch: 2317 \tTraining Loss: 0.00634241 \tValidation Loss 0.00713804 \tTraining Accuracy 65.687% \tValidation Accuracy 59.339%\n",
      "Epoch: 2318 \tTraining Loss: 0.00633515 \tValidation Loss 0.00709693 \tTraining Accuracy 65.771% \tValidation Accuracy 59.444%\n",
      "Epoch: 2319 \tTraining Loss: 0.00633495 \tValidation Loss 0.00706657 \tTraining Accuracy 65.728% \tValidation Accuracy 60.464%\n",
      "Epoch: 2320 \tTraining Loss: 0.00634166 \tValidation Loss 0.00707900 \tTraining Accuracy 65.590% \tValidation Accuracy 60.113%\n",
      "Epoch: 2321 \tTraining Loss: 0.00633960 \tValidation Loss 0.00709350 \tTraining Accuracy 65.488% \tValidation Accuracy 60.851%\n",
      "Epoch: 2322 \tTraining Loss: 0.00633484 \tValidation Loss 0.00710712 \tTraining Accuracy 65.775% \tValidation Accuracy 59.866%\n",
      "Epoch: 2323 \tTraining Loss: 0.00633851 \tValidation Loss 0.00711439 \tTraining Accuracy 65.731% \tValidation Accuracy 58.881%\n",
      "Epoch: 2324 \tTraining Loss: 0.00633871 \tValidation Loss 0.00712252 \tTraining Accuracy 65.600% \tValidation Accuracy 59.163%\n",
      "Epoch: 2325 \tTraining Loss: 0.00634496 \tValidation Loss 0.00703885 \tTraining Accuracy 65.475% \tValidation Accuracy 61.133%\n",
      "Epoch: 2326 \tTraining Loss: 0.00634458 \tValidation Loss 0.00711565 \tTraining Accuracy 65.515% \tValidation Accuracy 59.902%\n",
      "Epoch: 2327 \tTraining Loss: 0.00634237 \tValidation Loss 0.00708371 \tTraining Accuracy 65.536% \tValidation Accuracy 59.585%\n",
      "Epoch: 2328 \tTraining Loss: 0.00633636 \tValidation Loss 0.00707475 \tTraining Accuracy 65.660% \tValidation Accuracy 60.148%\n",
      "Epoch: 2329 \tTraining Loss: 0.00633607 \tValidation Loss 0.00710038 \tTraining Accuracy 65.761% \tValidation Accuracy 60.007%\n",
      "Epoch: 2330 \tTraining Loss: 0.00634322 \tValidation Loss 0.00709104 \tTraining Accuracy 65.465% \tValidation Accuracy 60.077%\n",
      "Epoch: 2331 \tTraining Loss: 0.00633647 \tValidation Loss 0.00711955 \tTraining Accuracy 65.738% \tValidation Accuracy 60.324%\n",
      "Epoch: 2332 \tTraining Loss: 0.00633682 \tValidation Loss 0.00708781 \tTraining Accuracy 65.684% \tValidation Accuracy 59.831%\n",
      "Epoch: 2333 \tTraining Loss: 0.00633686 \tValidation Loss 0.00712627 \tTraining Accuracy 65.738% \tValidation Accuracy 60.570%\n",
      "Epoch: 2334 \tTraining Loss: 0.00633986 \tValidation Loss 0.00706672 \tTraining Accuracy 65.623% \tValidation Accuracy 60.429%\n",
      "Epoch: 2335 \tTraining Loss: 0.00633471 \tValidation Loss 0.00707322 \tTraining Accuracy 65.771% \tValidation Accuracy 60.324%\n",
      "Epoch: 2336 \tTraining Loss: 0.00633903 \tValidation Loss 0.00704571 \tTraining Accuracy 65.590% \tValidation Accuracy 60.288%\n",
      "Epoch: 2337 \tTraining Loss: 0.00634420 \tValidation Loss 0.00705154 \tTraining Accuracy 65.404% \tValidation Accuracy 60.464%\n",
      "Epoch: 2338 \tTraining Loss: 0.00633872 \tValidation Loss 0.00706330 \tTraining Accuracy 65.748% \tValidation Accuracy 60.851%\n",
      "Epoch: 2339 \tTraining Loss: 0.00633850 \tValidation Loss 0.00716435 \tTraining Accuracy 65.600% \tValidation Accuracy 59.831%\n",
      "Epoch: 2340 \tTraining Loss: 0.00633580 \tValidation Loss 0.00710011 \tTraining Accuracy 65.785% \tValidation Accuracy 59.409%\n",
      "Epoch: 2341 \tTraining Loss: 0.00634088 \tValidation Loss 0.00712551 \tTraining Accuracy 65.600% \tValidation Accuracy 59.761%\n",
      "Epoch: 2342 \tTraining Loss: 0.00632921 \tValidation Loss 0.00709724 \tTraining Accuracy 65.866% \tValidation Accuracy 59.339%\n",
      "Epoch: 2343 \tTraining Loss: 0.00634076 \tValidation Loss 0.00710416 \tTraining Accuracy 65.482% \tValidation Accuracy 58.987%\n",
      "Epoch: 2344 \tTraining Loss: 0.00633301 \tValidation Loss 0.00713442 \tTraining Accuracy 65.637% \tValidation Accuracy 60.148%\n",
      "Epoch: 2345 \tTraining Loss: 0.00633802 \tValidation Loss 0.00707960 \tTraining Accuracy 65.478% \tValidation Accuracy 60.042%\n",
      "Epoch: 2346 \tTraining Loss: 0.00633564 \tValidation Loss 0.00709005 \tTraining Accuracy 65.684% \tValidation Accuracy 60.077%\n",
      "Epoch: 2347 \tTraining Loss: 0.00632633 \tValidation Loss 0.00707202 \tTraining Accuracy 65.990% \tValidation Accuracy 60.535%\n",
      "Epoch: 2348 \tTraining Loss: 0.00633796 \tValidation Loss 0.00711880 \tTraining Accuracy 65.549% \tValidation Accuracy 59.444%\n",
      "Epoch: 2349 \tTraining Loss: 0.00633666 \tValidation Loss 0.00709107 \tTraining Accuracy 65.792% \tValidation Accuracy 60.288%\n",
      "Epoch: 2350 \tTraining Loss: 0.00633473 \tValidation Loss 0.00708533 \tTraining Accuracy 65.606% \tValidation Accuracy 59.690%\n",
      "Epoch: 2351 \tTraining Loss: 0.00633102 \tValidation Loss 0.00711817 \tTraining Accuracy 65.839% \tValidation Accuracy 59.057%\n",
      "Epoch: 2352 \tTraining Loss: 0.00633056 \tValidation Loss 0.00712801 \tTraining Accuracy 65.906% \tValidation Accuracy 59.409%\n",
      "Epoch: 2353 \tTraining Loss: 0.00633118 \tValidation Loss 0.00704849 \tTraining Accuracy 65.852% \tValidation Accuracy 60.359%\n",
      "Epoch: 2354 \tTraining Loss: 0.00632627 \tValidation Loss 0.00709460 \tTraining Accuracy 65.822% \tValidation Accuracy 60.148%\n",
      "Epoch: 2355 \tTraining Loss: 0.00633309 \tValidation Loss 0.00708250 \tTraining Accuracy 65.714% \tValidation Accuracy 60.394%\n",
      "Epoch: 2356 \tTraining Loss: 0.00633453 \tValidation Loss 0.00708129 \tTraining Accuracy 65.606% \tValidation Accuracy 60.640%\n",
      "Epoch: 2357 \tTraining Loss: 0.00633231 \tValidation Loss 0.00709703 \tTraining Accuracy 65.765% \tValidation Accuracy 60.077%\n",
      "Epoch: 2358 \tTraining Loss: 0.00633672 \tValidation Loss 0.00704595 \tTraining Accuracy 65.721% \tValidation Accuracy 59.409%\n",
      "Epoch: 2359 \tTraining Loss: 0.00633198 \tValidation Loss 0.00716193 \tTraining Accuracy 65.883% \tValidation Accuracy 58.741%\n",
      "Epoch: 2360 \tTraining Loss: 0.00633561 \tValidation Loss 0.00709429 \tTraining Accuracy 65.549% \tValidation Accuracy 60.113%\n",
      "Epoch: 2361 \tTraining Loss: 0.00633353 \tValidation Loss 0.00703294 \tTraining Accuracy 65.647% \tValidation Accuracy 60.711%\n",
      "Epoch: 2362 \tTraining Loss: 0.00632487 \tValidation Loss 0.00715858 \tTraining Accuracy 66.038% \tValidation Accuracy 59.515%\n",
      "Epoch: 2363 \tTraining Loss: 0.00632902 \tValidation Loss 0.00705758 \tTraining Accuracy 65.866% \tValidation Accuracy 60.886%\n",
      "Epoch: 2364 \tTraining Loss: 0.00633701 \tValidation Loss 0.00712175 \tTraining Accuracy 65.616% \tValidation Accuracy 59.831%\n",
      "Epoch: 2365 \tTraining Loss: 0.00632864 \tValidation Loss 0.00709222 \tTraining Accuracy 65.825% \tValidation Accuracy 59.866%\n",
      "Epoch: 2366 \tTraining Loss: 0.00632778 \tValidation Loss 0.00708102 \tTraining Accuracy 65.947% \tValidation Accuracy 61.238%\n",
      "Epoch: 2367 \tTraining Loss: 0.00632997 \tValidation Loss 0.00712400 \tTraining Accuracy 65.906% \tValidation Accuracy 59.902%\n",
      "Epoch: 2368 \tTraining Loss: 0.00632505 \tValidation Loss 0.00707598 \tTraining Accuracy 66.038% \tValidation Accuracy 60.183%\n",
      "Epoch: 2369 \tTraining Loss: 0.00632724 \tValidation Loss 0.00710625 \tTraining Accuracy 66.041% \tValidation Accuracy 59.093%\n",
      "Epoch: 2370 \tTraining Loss: 0.00632894 \tValidation Loss 0.00707140 \tTraining Accuracy 65.859% \tValidation Accuracy 59.831%\n",
      "Epoch: 2371 \tTraining Loss: 0.00632319 \tValidation Loss 0.00709015 \tTraining Accuracy 65.987% \tValidation Accuracy 60.042%\n",
      "Epoch: 2372 \tTraining Loss: 0.00632554 \tValidation Loss 0.00712125 \tTraining Accuracy 66.055% \tValidation Accuracy 60.746%\n",
      "Epoch: 2373 \tTraining Loss: 0.00631929 \tValidation Loss 0.00710028 \tTraining Accuracy 66.095% \tValidation Accuracy 60.218%\n",
      "Epoch: 2374 \tTraining Loss: 0.00632160 \tValidation Loss 0.00707164 \tTraining Accuracy 66.031% \tValidation Accuracy 61.203%\n",
      "Epoch: 2375 \tTraining Loss: 0.00633062 \tValidation Loss 0.00708133 \tTraining Accuracy 65.734% \tValidation Accuracy 60.359%\n",
      "Epoch: 2376 \tTraining Loss: 0.00632169 \tValidation Loss 0.00712011 \tTraining Accuracy 66.081% \tValidation Accuracy 60.042%\n",
      "Epoch: 2377 \tTraining Loss: 0.00632806 \tValidation Loss 0.00708913 \tTraining Accuracy 65.714% \tValidation Accuracy 60.711%\n",
      "Epoch: 2378 \tTraining Loss: 0.00634183 \tValidation Loss 0.00710037 \tTraining Accuracy 65.482% \tValidation Accuracy 60.148%\n",
      "Epoch: 2379 \tTraining Loss: 0.00631784 \tValidation Loss 0.00708514 \tTraining Accuracy 66.105% \tValidation Accuracy 60.992%\n",
      "Epoch: 2380 \tTraining Loss: 0.00632303 \tValidation Loss 0.00717570 \tTraining Accuracy 65.960% \tValidation Accuracy 58.952%\n",
      "Epoch: 2381 \tTraining Loss: 0.00632570 \tValidation Loss 0.00711259 \tTraining Accuracy 65.893% \tValidation Accuracy 60.288%\n",
      "Epoch: 2382 \tTraining Loss: 0.00632039 \tValidation Loss 0.00712790 \tTraining Accuracy 66.044% \tValidation Accuracy 60.675%\n",
      "Epoch: 2383 \tTraining Loss: 0.00632409 \tValidation Loss 0.00709437 \tTraining Accuracy 66.017% \tValidation Accuracy 59.585%\n",
      "Epoch: 2384 \tTraining Loss: 0.00632583 \tValidation Loss 0.00714596 \tTraining Accuracy 66.125% \tValidation Accuracy 59.339%\n",
      "Epoch: 2385 \tTraining Loss: 0.00631900 \tValidation Loss 0.00712165 \tTraining Accuracy 66.135% \tValidation Accuracy 59.620%\n",
      "Epoch: 2386 \tTraining Loss: 0.00632394 \tValidation Loss 0.00715494 \tTraining Accuracy 66.014% \tValidation Accuracy 59.831%\n",
      "Epoch: 2387 \tTraining Loss: 0.00632065 \tValidation Loss 0.00713469 \tTraining Accuracy 66.145% \tValidation Accuracy 60.535%\n",
      "Epoch: 2388 \tTraining Loss: 0.00631447 \tValidation Loss 0.00703772 \tTraining Accuracy 66.297% \tValidation Accuracy 60.394%\n",
      "Epoch: 2389 \tTraining Loss: 0.00631504 \tValidation Loss 0.00708207 \tTraining Accuracy 66.317% \tValidation Accuracy 59.902%\n",
      "Epoch: 2390 \tTraining Loss: 0.00631814 \tValidation Loss 0.00708682 \tTraining Accuracy 66.172% \tValidation Accuracy 60.113%\n",
      "Epoch: 2391 \tTraining Loss: 0.00632219 \tValidation Loss 0.00705173 \tTraining Accuracy 66.108% \tValidation Accuracy 60.746%\n",
      "Epoch: 2392 \tTraining Loss: 0.00632764 \tValidation Loss 0.00716954 \tTraining Accuracy 65.842% \tValidation Accuracy 59.585%\n",
      "Epoch: 2393 \tTraining Loss: 0.00631943 \tValidation Loss 0.00708827 \tTraining Accuracy 66.125% \tValidation Accuracy 61.203%\n",
      "Epoch: 2394 \tTraining Loss: 0.00632433 \tValidation Loss 0.00709309 \tTraining Accuracy 66.092% \tValidation Accuracy 60.394%\n",
      "Epoch: 2395 \tTraining Loss: 0.00631369 \tValidation Loss 0.00709103 \tTraining Accuracy 66.354% \tValidation Accuracy 60.218%\n",
      "Epoch: 2396 \tTraining Loss: 0.00631920 \tValidation Loss 0.00704658 \tTraining Accuracy 66.179% \tValidation Accuracy 60.746%\n",
      "Epoch: 2397 \tTraining Loss: 0.00631275 \tValidation Loss 0.00708355 \tTraining Accuracy 66.381% \tValidation Accuracy 59.515%\n",
      "Epoch: 2398 \tTraining Loss: 0.00631422 \tValidation Loss 0.00706128 \tTraining Accuracy 66.290% \tValidation Accuracy 60.570%\n",
      "Epoch: 2399 \tTraining Loss: 0.00632525 \tValidation Loss 0.00718561 \tTraining Accuracy 66.068% \tValidation Accuracy 59.163%\n",
      "Epoch: 2400 \tTraining Loss: 0.00631579 \tValidation Loss 0.00711650 \tTraining Accuracy 66.159% \tValidation Accuracy 60.746%\n",
      "Epoch: 2401 \tTraining Loss: 0.00632191 \tValidation Loss 0.00711420 \tTraining Accuracy 65.987% \tValidation Accuracy 60.570%\n",
      "Epoch: 2402 \tTraining Loss: 0.00630711 \tValidation Loss 0.00710263 \tTraining Accuracy 66.580% \tValidation Accuracy 60.253%\n",
      "Epoch: 2403 \tTraining Loss: 0.00631600 \tValidation Loss 0.00708819 \tTraining Accuracy 66.216% \tValidation Accuracy 59.937%\n",
      "Epoch: 2404 \tTraining Loss: 0.00631543 \tValidation Loss 0.00710999 \tTraining Accuracy 66.132% \tValidation Accuracy 60.394%\n",
      "Epoch: 2405 \tTraining Loss: 0.00631834 \tValidation Loss 0.00711200 \tTraining Accuracy 66.287% \tValidation Accuracy 60.007%\n",
      "Epoch: 2406 \tTraining Loss: 0.00631347 \tValidation Loss 0.00708025 \tTraining Accuracy 66.166% \tValidation Accuracy 60.359%\n",
      "Epoch: 2407 \tTraining Loss: 0.00631865 \tValidation Loss 0.00707157 \tTraining Accuracy 66.179% \tValidation Accuracy 60.535%\n",
      "Epoch: 2408 \tTraining Loss: 0.00631213 \tValidation Loss 0.00709029 \tTraining Accuracy 66.432% \tValidation Accuracy 59.655%\n",
      "Epoch: 2409 \tTraining Loss: 0.00631908 \tValidation Loss 0.00709531 \tTraining Accuracy 66.179% \tValidation Accuracy 60.324%\n",
      "Epoch: 2410 \tTraining Loss: 0.00630972 \tValidation Loss 0.00707170 \tTraining Accuracy 66.327% \tValidation Accuracy 60.746%\n",
      "Epoch: 2411 \tTraining Loss: 0.00631404 \tValidation Loss 0.00710355 \tTraining Accuracy 66.338% \tValidation Accuracy 60.007%\n",
      "Epoch: 2412 \tTraining Loss: 0.00631209 \tValidation Loss 0.00705750 \tTraining Accuracy 66.304% \tValidation Accuracy 61.273%\n",
      "Epoch: 2413 \tTraining Loss: 0.00631159 \tValidation Loss 0.00707933 \tTraining Accuracy 66.365% \tValidation Accuracy 61.097%\n",
      "Epoch: 2414 \tTraining Loss: 0.00632376 \tValidation Loss 0.00706741 \tTraining Accuracy 66.071% \tValidation Accuracy 60.605%\n",
      "Epoch: 2415 \tTraining Loss: 0.00630310 \tValidation Loss 0.00709381 \tTraining Accuracy 66.614% \tValidation Accuracy 60.816%\n",
      "Epoch: 2416 \tTraining Loss: 0.00632059 \tValidation Loss 0.00711861 \tTraining Accuracy 66.085% \tValidation Accuracy 58.987%\n",
      "Epoch: 2417 \tTraining Loss: 0.00631740 \tValidation Loss 0.00710377 \tTraining Accuracy 66.247% \tValidation Accuracy 60.746%\n",
      "Epoch: 2418 \tTraining Loss: 0.00632154 \tValidation Loss 0.00711200 \tTraining Accuracy 66.024% \tValidation Accuracy 59.761%\n",
      "Epoch: 2419 \tTraining Loss: 0.00630111 \tValidation Loss 0.00707459 \tTraining Accuracy 66.675% \tValidation Accuracy 59.831%\n",
      "Epoch: 2420 \tTraining Loss: 0.00631176 \tValidation Loss 0.00712942 \tTraining Accuracy 66.354% \tValidation Accuracy 59.761%\n",
      "Epoch: 2421 \tTraining Loss: 0.00630856 \tValidation Loss 0.00704818 \tTraining Accuracy 66.459% \tValidation Accuracy 60.429%\n",
      "Epoch: 2422 \tTraining Loss: 0.00630759 \tValidation Loss 0.00706605 \tTraining Accuracy 66.439% \tValidation Accuracy 60.288%\n",
      "Epoch: 2423 \tTraining Loss: 0.00630798 \tValidation Loss 0.00709656 \tTraining Accuracy 66.442% \tValidation Accuracy 59.972%\n",
      "Epoch: 2424 \tTraining Loss: 0.00631030 \tValidation Loss 0.00712303 \tTraining Accuracy 66.284% \tValidation Accuracy 60.781%\n",
      "Epoch: 2425 \tTraining Loss: 0.00630717 \tValidation Loss 0.00706286 \tTraining Accuracy 66.614% \tValidation Accuracy 60.816%\n",
      "Epoch: 2426 \tTraining Loss: 0.00630243 \tValidation Loss 0.00711119 \tTraining Accuracy 66.499% \tValidation Accuracy 60.113%\n",
      "Epoch: 2427 \tTraining Loss: 0.00630356 \tValidation Loss 0.00701784 \tTraining Accuracy 66.624% \tValidation Accuracy 60.711%\n",
      "Epoch: 2428 \tTraining Loss: 0.00631240 \tValidation Loss 0.00706955 \tTraining Accuracy 66.496% \tValidation Accuracy 61.027%\n",
      "Epoch: 2429 \tTraining Loss: 0.00631196 \tValidation Loss 0.00712547 \tTraining Accuracy 66.213% \tValidation Accuracy 59.937%\n",
      "Epoch: 2430 \tTraining Loss: 0.00630745 \tValidation Loss 0.00710616 \tTraining Accuracy 66.412% \tValidation Accuracy 59.444%\n",
      "Epoch: 2431 \tTraining Loss: 0.00630995 \tValidation Loss 0.00712958 \tTraining Accuracy 66.388% \tValidation Accuracy 60.007%\n",
      "Epoch: 2432 \tTraining Loss: 0.00630645 \tValidation Loss 0.00709265 \tTraining Accuracy 66.496% \tValidation Accuracy 59.620%\n",
      "Epoch: 2433 \tTraining Loss: 0.00630344 \tValidation Loss 0.00708479 \tTraining Accuracy 66.466% \tValidation Accuracy 60.324%\n",
      "Epoch: 2434 \tTraining Loss: 0.00631208 \tValidation Loss 0.00706931 \tTraining Accuracy 66.327% \tValidation Accuracy 60.218%\n",
      "Epoch: 2435 \tTraining Loss: 0.00630938 \tValidation Loss 0.00711511 \tTraining Accuracy 66.321% \tValidation Accuracy 60.077%\n",
      "Epoch: 2436 \tTraining Loss: 0.00631171 \tValidation Loss 0.00706985 \tTraining Accuracy 66.294% \tValidation Accuracy 60.218%\n",
      "Epoch: 2437 \tTraining Loss: 0.00630514 \tValidation Loss 0.00712412 \tTraining Accuracy 66.472% \tValidation Accuracy 60.253%\n",
      "Epoch: 2438 \tTraining Loss: 0.00631644 \tValidation Loss 0.00708330 \tTraining Accuracy 66.169% \tValidation Accuracy 60.042%\n",
      "Epoch: 2439 \tTraining Loss: 0.00631207 \tValidation Loss 0.00708949 \tTraining Accuracy 66.331% \tValidation Accuracy 60.711%\n",
      "Epoch: 2440 \tTraining Loss: 0.00630133 \tValidation Loss 0.00710915 \tTraining Accuracy 66.587% \tValidation Accuracy 61.168%\n",
      "Epoch: 2441 \tTraining Loss: 0.00630638 \tValidation Loss 0.00710202 \tTraining Accuracy 66.526% \tValidation Accuracy 60.113%\n",
      "Epoch: 2442 \tTraining Loss: 0.00631021 \tValidation Loss 0.00708205 \tTraining Accuracy 66.338% \tValidation Accuracy 60.394%\n",
      "Epoch: 2443 \tTraining Loss: 0.00630268 \tValidation Loss 0.00707497 \tTraining Accuracy 66.607% \tValidation Accuracy 59.690%\n",
      "Epoch: 2444 \tTraining Loss: 0.00630840 \tValidation Loss 0.00709202 \tTraining Accuracy 66.371% \tValidation Accuracy 60.042%\n",
      "Epoch: 2445 \tTraining Loss: 0.00630230 \tValidation Loss 0.00716882 \tTraining Accuracy 66.668% \tValidation Accuracy 59.022%\n",
      "Epoch: 2446 \tTraining Loss: 0.00630927 \tValidation Loss 0.00705159 \tTraining Accuracy 66.358% \tValidation Accuracy 61.133%\n",
      "Epoch: 2447 \tTraining Loss: 0.00630564 \tValidation Loss 0.00711102 \tTraining Accuracy 66.466% \tValidation Accuracy 60.886%\n",
      "Epoch: 2448 \tTraining Loss: 0.00631328 \tValidation Loss 0.00707254 \tTraining Accuracy 66.274% \tValidation Accuracy 60.394%\n",
      "Epoch: 2449 \tTraining Loss: 0.00631247 \tValidation Loss 0.00706074 \tTraining Accuracy 66.156% \tValidation Accuracy 61.238%\n",
      "Epoch: 2450 \tTraining Loss: 0.00630228 \tValidation Loss 0.00705682 \tTraining Accuracy 66.634% \tValidation Accuracy 61.414%\n",
      "Epoch: 2451 \tTraining Loss: 0.00630525 \tValidation Loss 0.00711898 \tTraining Accuracy 66.445% \tValidation Accuracy 59.796%\n",
      "Epoch: 2452 \tTraining Loss: 0.00631408 \tValidation Loss 0.00713906 \tTraining Accuracy 66.301% \tValidation Accuracy 60.499%\n",
      "Epoch: 2453 \tTraining Loss: 0.00631115 \tValidation Loss 0.00702421 \tTraining Accuracy 66.307% \tValidation Accuracy 60.359%\n",
      "Epoch: 2454 \tTraining Loss: 0.00630638 \tValidation Loss 0.00712224 \tTraining Accuracy 66.506% \tValidation Accuracy 60.288%\n",
      "Epoch: 2455 \tTraining Loss: 0.00630019 \tValidation Loss 0.00707847 \tTraining Accuracy 66.557% \tValidation Accuracy 60.499%\n",
      "Epoch: 2456 \tTraining Loss: 0.00628745 \tValidation Loss 0.00714752 \tTraining Accuracy 66.924% \tValidation Accuracy 60.781%\n",
      "Epoch: 2457 \tTraining Loss: 0.00630013 \tValidation Loss 0.00705511 \tTraining Accuracy 66.631% \tValidation Accuracy 60.288%\n",
      "Epoch: 2458 \tTraining Loss: 0.00630558 \tValidation Loss 0.00702877 \tTraining Accuracy 66.530% \tValidation Accuracy 60.464%\n",
      "Epoch: 2459 \tTraining Loss: 0.00630041 \tValidation Loss 0.00709149 \tTraining Accuracy 66.651% \tValidation Accuracy 60.324%\n",
      "Epoch: 2460 \tTraining Loss: 0.00629688 \tValidation Loss 0.00706522 \tTraining Accuracy 66.644% \tValidation Accuracy 60.464%\n",
      "Epoch: 2461 \tTraining Loss: 0.00629299 \tValidation Loss 0.00710458 \tTraining Accuracy 66.833% \tValidation Accuracy 60.675%\n",
      "Epoch: 2462 \tTraining Loss: 0.00628879 \tValidation Loss 0.00707816 \tTraining Accuracy 66.941% \tValidation Accuracy 60.218%\n",
      "Epoch: 2463 \tTraining Loss: 0.00629158 \tValidation Loss 0.00711249 \tTraining Accuracy 66.853% \tValidation Accuracy 60.640%\n",
      "Epoch: 2464 \tTraining Loss: 0.00630159 \tValidation Loss 0.00713440 \tTraining Accuracy 66.580% \tValidation Accuracy 60.007%\n",
      "Epoch: 2465 \tTraining Loss: 0.00629500 \tValidation Loss 0.00703689 \tTraining Accuracy 66.762% \tValidation Accuracy 60.288%\n",
      "Epoch: 2466 \tTraining Loss: 0.00629941 \tValidation Loss 0.00705306 \tTraining Accuracy 66.691% \tValidation Accuracy 60.394%\n",
      "Epoch: 2467 \tTraining Loss: 0.00629837 \tValidation Loss 0.00710840 \tTraining Accuracy 66.590% \tValidation Accuracy 60.394%\n",
      "Epoch: 2468 \tTraining Loss: 0.00630120 \tValidation Loss 0.00710074 \tTraining Accuracy 66.611% \tValidation Accuracy 60.711%\n",
      "Epoch: 2469 \tTraining Loss: 0.00629726 \tValidation Loss 0.00706362 \tTraining Accuracy 66.715% \tValidation Accuracy 61.027%\n",
      "Epoch: 2470 \tTraining Loss: 0.00630382 \tValidation Loss 0.00709900 \tTraining Accuracy 66.536% \tValidation Accuracy 60.605%\n",
      "Epoch: 2471 \tTraining Loss: 0.00629825 \tValidation Loss 0.00703210 \tTraining Accuracy 66.594% \tValidation Accuracy 61.590%\n",
      "Epoch: 2472 \tTraining Loss: 0.00629973 \tValidation Loss 0.00708874 \tTraining Accuracy 66.567% \tValidation Accuracy 60.957%\n",
      "Epoch: 2473 \tTraining Loss: 0.00629388 \tValidation Loss 0.00708677 \tTraining Accuracy 66.883% \tValidation Accuracy 61.133%\n",
      "Epoch: 2474 \tTraining Loss: 0.00629930 \tValidation Loss 0.00713444 \tTraining Accuracy 66.607% \tValidation Accuracy 59.726%\n",
      "Epoch: 2475 \tTraining Loss: 0.00629550 \tValidation Loss 0.00705638 \tTraining Accuracy 66.739% \tValidation Accuracy 60.886%\n",
      "Epoch: 2476 \tTraining Loss: 0.00629505 \tValidation Loss 0.00712940 \tTraining Accuracy 66.830% \tValidation Accuracy 61.062%\n",
      "Epoch: 2477 \tTraining Loss: 0.00630422 \tValidation Loss 0.00710607 \tTraining Accuracy 66.567% \tValidation Accuracy 59.339%\n",
      "Epoch: 2478 \tTraining Loss: 0.00629740 \tValidation Loss 0.00710661 \tTraining Accuracy 66.516% \tValidation Accuracy 60.113%\n",
      "Epoch: 2479 \tTraining Loss: 0.00629060 \tValidation Loss 0.00705346 \tTraining Accuracy 66.944% \tValidation Accuracy 60.992%\n",
      "Epoch: 2480 \tTraining Loss: 0.00629553 \tValidation Loss 0.00707545 \tTraining Accuracy 66.766% \tValidation Accuracy 60.077%\n",
      "Epoch: 2481 \tTraining Loss: 0.00629128 \tValidation Loss 0.00708321 \tTraining Accuracy 66.968% \tValidation Accuracy 59.902%\n",
      "Epoch: 2482 \tTraining Loss: 0.00630385 \tValidation Loss 0.00709010 \tTraining Accuracy 66.604% \tValidation Accuracy 60.464%\n",
      "Epoch: 2483 \tTraining Loss: 0.00629876 \tValidation Loss 0.00708069 \tTraining Accuracy 66.600% \tValidation Accuracy 60.499%\n",
      "Epoch: 2484 \tTraining Loss: 0.00629645 \tValidation Loss 0.00705826 \tTraining Accuracy 66.732% \tValidation Accuracy 61.238%\n",
      "Epoch: 2485 \tTraining Loss: 0.00630295 \tValidation Loss 0.00707390 \tTraining Accuracy 66.631% \tValidation Accuracy 61.027%\n",
      "Epoch: 2486 \tTraining Loss: 0.00628929 \tValidation Loss 0.00706680 \tTraining Accuracy 66.981% \tValidation Accuracy 61.203%\n",
      "Epoch: 2487 \tTraining Loss: 0.00629487 \tValidation Loss 0.00703693 \tTraining Accuracy 66.755% \tValidation Accuracy 60.640%\n",
      "Epoch: 2488 \tTraining Loss: 0.00628562 \tValidation Loss 0.00706878 \tTraining Accuracy 67.059% \tValidation Accuracy 60.218%\n",
      "Epoch: 2489 \tTraining Loss: 0.00629453 \tValidation Loss 0.00703236 \tTraining Accuracy 66.725% \tValidation Accuracy 60.605%\n",
      "Epoch: 2490 \tTraining Loss: 0.00628770 \tValidation Loss 0.00711647 \tTraining Accuracy 66.995% \tValidation Accuracy 59.937%\n",
      "Epoch: 2491 \tTraining Loss: 0.00629675 \tValidation Loss 0.00712055 \tTraining Accuracy 66.671% \tValidation Accuracy 60.535%\n",
      "Epoch: 2492 \tTraining Loss: 0.00628872 \tValidation Loss 0.00702919 \tTraining Accuracy 66.958% \tValidation Accuracy 61.801%\n",
      "Epoch: 2493 \tTraining Loss: 0.00629585 \tValidation Loss 0.00708982 \tTraining Accuracy 66.786% \tValidation Accuracy 60.324%\n",
      "Epoch: 2494 \tTraining Loss: 0.00629262 \tValidation Loss 0.00708357 \tTraining Accuracy 66.890% \tValidation Accuracy 60.077%\n",
      "Epoch: 2495 \tTraining Loss: 0.00629175 \tValidation Loss 0.00713082 \tTraining Accuracy 66.867% \tValidation Accuracy 60.816%\n",
      "Epoch: 2496 \tTraining Loss: 0.00628923 \tValidation Loss 0.00707487 \tTraining Accuracy 66.941% \tValidation Accuracy 60.042%\n",
      "Epoch: 2497 \tTraining Loss: 0.00629900 \tValidation Loss 0.00705831 \tTraining Accuracy 66.563% \tValidation Accuracy 60.781%\n",
      "Epoch: 2498 \tTraining Loss: 0.00628388 \tValidation Loss 0.00707467 \tTraining Accuracy 67.001% \tValidation Accuracy 60.711%\n",
      "Epoch: 2499 \tTraining Loss: 0.00629234 \tValidation Loss 0.00710008 \tTraining Accuracy 66.816% \tValidation Accuracy 59.972%\n",
      "Epoch: 2500 \tTraining Loss: 0.00629098 \tValidation Loss 0.00709197 \tTraining Accuracy 66.826% \tValidation Accuracy 60.640%\n",
      "===================================Training Finished===================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[175], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mTrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptmizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[64], line 27\u001b[0m, in \u001b[0;36mTrain\u001b[0;34m(epochs, train_loader, val_loader, criterion, optmizer, device)\u001b[0m\n\u001b[1;32m     25\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     26\u001b[0m optmizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 27\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m _, preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     29\u001b[0m train_correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(preds \u001b[38;5;241m==\u001b[39m labels\u001b[38;5;241m.\u001b[39mdata)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Train(epochs, train_loader, val_loader, criterion, optmizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe032bec",
   "metadata": {
    "id": "fe032bec"
   },
   "outputs": [],
   "source": [
    "test_dataset= Plain_Dataset(csv_file=\"data2/test.csv\", img_dir = \"data2/test/\", datatype = 'test', transform = transformation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c94ca1",
   "metadata": {
    "id": "b8c94ca1"
   },
   "outputs": [],
   "source": [
    "test_loader=   DataLoader(test_dataset,batch_size=batchsize,shuffle = True,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949eed12",
   "metadata": {
    "id": "949eed12"
   },
   "outputs": [],
   "source": [
    "test_result = []\n",
    "test_loss = 0\n",
    "test_correct = 0\n",
    "for data,labels in test_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            test_outputs = net(data)\n",
    "            #print(val_outputs[0][3])\n",
    "            #print(labels[0])\n",
    "            t_loss = criterion(test_outputs, labels)\n",
    "            test_loss += t_loss.item()\n",
    "            _, test_preds = torch.max(test_outputs,1)\n",
    "            test_result.append(torch.max(test_outputs,1))\n",
    "            test_correct += torch.sum(test_preds == labels.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb5e71c",
   "metadata": {
    "id": "2fb5e71c",
    "outputId": "89a08aae-5ae5-4272-da3e-84ddea96d630"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy on the testing set =  tensor(0.6059, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"Final accuracy on the testing set = \", test_correct/7099)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d609ea",
   "metadata": {
    "id": "55d609ea"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        output = net(inputs) # Feed Network\n",
    "\n",
    "        output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "        y_pred.extend(output) # Save Prediction\n",
    "\n",
    "        labels = labels.data.cpu().numpy()\n",
    "        y_true.extend(labels) # Save Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bb4dad",
   "metadata": {
    "id": "d3bb4dad"
   },
   "outputs": [],
   "source": [
    "test_result = []\n",
    "test_loss = 0\n",
    "test_correct = 0\n",
    "for data,labels in test_loader:\n",
    "\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            test_outputs = net(data)\n",
    "            #print(val_outputs[0][3])\n",
    "            #print(labels[0])\n",
    "            t_loss = criterion(test_outputs, labels)\n",
    "            test_loss += t_loss.item()\n",
    "            _, test_preds = torch.max(test_outputs,1)\n",
    "            test_result.append(torch.max(test_outputs,1))\n",
    "            test_correct += torch.sum(test_preds == labels.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfdaf77",
   "metadata": {
    "id": "bdfdaf77"
   },
   "outputs": [],
   "source": [
    "classes = ('Anger', 'Contempt', 'Disgust', 'Fear', 'Happiness',\n",
    "        'Neutral', 'Sadness', 'Surprise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe675e3",
   "metadata": {
    "id": "0fe675e3",
    "outputId": "77b2d85c-a109-468b-dac5-af713564c07a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index = [i for i in classes],\n",
    "                     columns = [i for i in classes])\n",
    "plt.figure(figsize = (12,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plt.savefig('output.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67f7c7b",
   "metadata": {
    "id": "f67f7c7b"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbdf799",
   "metadata": {
    "id": "5fbdf799",
    "outputId": "fa5403bd-a350-4639-9b1e-05b32bd43f8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5954359768981546\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(y_true, y_pred, average = \"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8a38de",
   "metadata": {
    "id": "3d8a38de",
    "outputId": "3aadbed6-de97-4144-984b-3d709903654d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4326862055572395\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(y_true, y_pred, average = \"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7bff64",
   "metadata": {
    "id": "db7bff64",
    "outputId": "7bc9cfdb-f0e9-4de3-9bb7-a9011dbaa1b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5954359768981546\n"
     ]
    }
   ],
   "source": [
    "print(recall_score(y_true, y_pred, average = \"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056c5e56",
   "metadata": {
    "id": "056c5e56",
    "outputId": "a6ba5c98-8c02-4ff0-bd0f-b5774202171e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5107289367419743\n"
     ]
    }
   ],
   "source": [
    "print(recall_score(y_true, y_pred, average = \"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8a7521",
   "metadata": {
    "id": "0d8a7521"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
